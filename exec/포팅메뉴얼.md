# ğŸ“Œ ê°œë°œ í™˜ê²½

---

Mobile

- Dart SDK `3.7.2`
- Flutter `latest`
- flutter_bloc `8.1.3`
- equatable `2.0.5`
- dartz `0.10.1`
- http `1.1.0`
- dio `5.4.0`
- internet_connection_checker `1.0.0+1`
- shared_preferences `2.2.2`
- flutter_secure_storage `9.2.2`
- go_router `14.6.2`
- freezed_annotation `2.4.1`
- json_annotation `4.8.1`
- build_runner `2.4.6`
- freezed `2.4.7`
- json_serializable `6.7.1`
- get_it `7.6.4`
- cached_network_image `3.4.1`
- youtube_player_flutter `9.0.3`
- cupertino_icons `1.0.8`
- flame `1.20.0`
- flame_forge2d `0.19.0`
- google_sign_in `6.2.1`
- intl `0.19.0`
- logger `2.0.2`
- flutter_dotenv `5.1.0`
- speech_to_text `7.0.0`
- permission_handler `11.0.1`
- flutter_lints `5.0.0`
- bloc_test `9.1.5`
- mockito `5.4.2`
- flutter_launcher_icons `0.13.1`
- flutter_native_splash `2.4.0`

**FrontEnd**

- Node.js `24.9.1`
- TypeScript `5.9.3`
- Vite `7.1.7`
- React `19.1.1`
    - React DOM `19.1.1`
    - React Router DOM `7.9.4`
    - Redux Toolkit `2.9.2`
    - React Redux `9.2.0`
    - Zustand `5.0.8`
    - TanStack React Query `5.90.5`
- Axios `1.13.2`
- Material-UI `7.3.4`
    - @emotion/react `11.14.0`
    - @emotion/styled `11.14.1`
- Tailwind CSS `3.4.18`
- D3 `7.9.0`
- Firebase `12.5.0`
- Yjs `13.6.27`
    - y-websocket `3.0.0`

**BackEnd**

- **Java**
    - Java OpenJDK `21`
    - Gradle `8.10`
- **Spring Boot** `3.4.11`
    - Spring Web (MVC) `6.2.3`
    - Spring WebFlux `6.2.3`
    - Spring WebSocket `6.2.3`
    - Spring Validation `3.4.11`
    - Spring Actuator `3.4.11`
    - Spring Data JPA `3.4.11`
    - Spring Data Redis `3.4.11`
    - Spring Data JDBC `3.4.11`
    - Spring Data MongoDB `4.4.0`
    - Spring Kafka `3.1.3`
    - Spring Cloud Gateway `2024.0.2`
    - Spring Cloud OpenFeign `2024.0.2`
    - Spring Security `6.3.3`
    - Spring Security OAuth2.0 `6.3.3`
    - Lombok `1.18.30`
    - Springdoc OpenAPI (Swagger UI - MVC) `2.7.0`
    - Springdoc OpenAPI (Swagger UI - WebFlux) `2.3.0`
- **Authentication / OAuth2**
    - JWT `0.12.3`
    - google-api-client `2.2.0`
    - google-auth-library-oauth2-http `1.19.0`
- **Database / Storage**
    - PostgreSQL JDBC Driver `42.7.3`
    - MongoDB (Spring Data MongoDB ê¸°ë°˜)
    - AWS S3 `2.25.65`
    - AWS STS `2.25.65`
- **Search / Logging**
    - elasticsearch-java `8.14.0`
    - elasticsearch-rest-client `8.14.0`
- **Messaging**
    - Spring Kafka `3.1.3`
- **HTTP Client**
    - Feign OkHttp `12.5`
- **JSON**
    - Jackson Databind `2.17.2`
    - Jackson JSR310 `2.17.2`
- **AWS SDK BOM**
    - AWS SDK `2.25.65`

- Python
    - PyTorch `2.5.1` (CUDA 12.1)
        - torchvision `0.20.1`
        - torchaudio `2.5.1`
    - transformers `4.57.1`
    - huggingface-hub `0.35.3`
    - accelerate `1.10.1`
    - bitsandbytes `0.48.1`
    - sentencepiece `0.2.1`
    - tokenizers `0.22.1`
    - FastAPI `0.104.0`
    - uvicorn `0.24.0`
    - pydantic `2.0.0`
    - kafka-python `2.0.2`
    - opencv-python `4.8.0`
    - Pillow `12.0.0`
    - numpy `2.3.4`
    - python-dotenv `1.0.0`
    - requests `2.32.5`
    - tqdm `4.67.1`
    - PyYAML `6.0.3`
- Node.js
    - Node.js `20.0`
    - express `4.21.2`
    - ws `8.18.3`
    - y-websocket `1.5.4`
    - yjs `13.6.27`
    - kafkajs `2.2.4`
    - dotenv `16.6.1`
    - uuid `9.0.1`
    

**UI/UX**

- Figma

**IDE**

- IntelliJ `2025.1.7`
- Visual Studuio Code `1.94.1`
- Pycharm `2024-02-03`

**DB**

- PostgreSQL `16.0`
- Redis `8.0.38`
- MongoDB `7.0.14`
- ElasticSearch `8.14.0`
- AWS S3

**Server ë°°í¬ í™˜ê²½**

- AWS EC2Â `ubuntu 22.04.4 LTS`
- EKS Node EC2 `AWS Linux 2023(x86_64) Standard`  intance â†’ t3a.medium
- DockerÂ `28.5.1`
- Docker Compose `2.40.2`
- Elastic Kubernetes Service `1.33`
- AWS Certificate Manager
- AWS Elastic Load Balancer
- S3
- Runpod

**CI/CD** 

- jenkins `2.475`
- Elastic Container Registry
- AWS CloudFront

Message / Log / Search Infra

- **Kafka (KRaft mode)** `4.1.0`
- **Kafka UI** `0.7.2`
- **Log aggregation** (Loki Stack)

Observability / Monitoring

- Prometheus `2.53.0`
- **Grafana** `11.0.0`
- **Loki** `2.9.8`
- **cAdvisor** `0.49.1`
- **Node Exporter** `1.8.1`
- **Kafka Exporter** `1.7.0`
- **Postgres Exporter** `0.15.0`
- **MongoDB Exporter** `0.40.0`
- **Redis Exporter** `1.62.0`

**Collaboration**

 **í˜•ìƒê´€ë¦¬** 

- GitLab

 **ì»¤ë®¤ë‹ˆì¼€ì´ì…˜** 

- Mattermost
- Notion

 **ì´ìŠˆê´€ë¦¬** 

- Jira

# ğŸ“Œ í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

---

### **[FrontEnd]**

> **ğŸ“ƒ .env**
> 

```bash
# Firebase Config
VITE_FIREBASE_API_KEY=AIzaSyD8Np_j39OV2M0Tajo-hYFl4sZaiRDjbBw
VITE_FIREBASE_AUTH_DOMAIN=oooo-748ee.firebaseapp.com
VITE_FIREBASE_PROJECT_ID=oooo-748ee
VITE_FIREBASE_STORAGE_BUCKET=oooo-748ee.firebasestorage.app
VITE_FIREBASE_MESSAGING_SENDER_ID=191516202759
VITE_FIREBASE_APP_ID=1:191516202759:web:736a650d74d598ddd117a2

# Google OAuth
VITE_GOOGLE_CLIENT_ID=191516202759-15156glfdeclp7rkrhabveh1m99fjel0.apps.googleusercontent.com

# API
VITE_API_URL=https://api.o-o.io.kr

# WebSocket (Yjs Collaboration)
VITE_WS_URL=wss://api.o-o.io.kr/mindmap/ws

# Prod Login API
VITE_LOGIN_API_URL=https://api.o-o.io.kr/oauth2/authorization/google?redirect_uri=https://www.o-o.io.kr

# Local Login API
# VITE_LOGIN_API_URL=https://api.o-o.io.kr/oauth2/authorization/google?redirect_uri=http://localhost:5173
```

### [BackEnd]

> **ğŸ“ƒ gateway-service: application.yml**
> 

```yaml
spring:
  application:
    name: gateway-service
  cloud:
    gateway:
      default-filters:
        - DedupeResponseHeader=Access-Control-Allow-Credentials Access-Control-Allow-Origin
      httpclient:
        wiretap: true
      httpserver:
        wiretap: true
      routes:
          # User Service ì •ì  ë¼ìš°íŒ…
          - id: user-service-auth
            uri: ${USER_SERVICE_URL:http://localhost:8081}
            predicates:
              - Path=/auth/**
            filters:
              - PreserveHostHeader
          - id: user-service-oauth2
            uri: ${USER_SERVICE_URL:http://localhost:8081}
            predicates:
              - Path=/oauth2/**
            filters:
              - PreserveHostHeader
          - id: user-service-oauth2-callback
            uri: ${USER_SERVICE_URL:http://localhost:8081}
            predicates:
              - Path=/login/oauth2/**
            filters:
              - PreserveHostHeader
          - id: user-service-users
            uri: ${USER_SERVICE_URL:http://localhost:8081}
            predicates:
              - Path=/users/**
            filters:
              - PreserveHostHeader
          # User Service Swagger API Docs
          - id: user-service-swagger
            uri: ${USER_SERVICE_URL:http://localhost:8081}
            predicates:
              - Path=/user-service/v3/api-docs/**
            filters:
              - StripPrefix=1
          # Workspace Service ì •ì  ë¼ìš°íŒ…
          - id: workspace-service
            uri: ${WORKSPACE_SERVICE_URL:http://localhost:8082}
            predicates:
              - Path=/workspace/**
          # Workspace Service Swagger API Docs
          - id: workspace-service-swagger
            uri: ${WORKSPACE_SERVICE_URL:http://localhost:8082}
            predicates:
              - Path=/workspace-service/v3/api-docs/**
            filters:
              - StripPrefix=1
          # Mindmap WebSocket Service (ì‹¤ì‹œê°„ í˜‘ì—…)
          - id: mindmap-websocket-service
            uri: ${MINDMAP_WEBSOCKET_SERVICE_URL:ws://localhost:8084}
            predicates:
              - Path=/mindmap/ws/**
            filters:
              - PreserveHostHeader
          # Mindmap Voice WebSocket Service (ìŒì„± ì±„íŒ…)
          - id: mindmap-voice-websocket
            uri: ${MINDMAP_WEBSOCKET_SERVICE_URL:ws://localhost:8084}
            predicates:
              - Path=/mindmap/voice/**
            filters:
              - PreserveHostHeader
        # Mindmap Service ì •ì  ë¼ìš°íŒ…
          - id: mindmap-service
            uri: ${MINDMAP_SERVICE_URL:http://localhost:8083}
            predicates:
              - Path=/mindmap/**
        # Mindmap Service Swagger API Docs
          - id: mindmap-service-swagger
            uri: ${MINDMAP_SERVICE_URL:http://localhost:8083}
            predicates:
              - Path=/mindmap-service/v3/api-docs/**
            filters:
              - StripPrefix=1          # Mindmap Service ì •ì  ë¼ìš°íŒ…
          - id: mindmap-service
            uri: ${MINDMAP_SERVICE_URL:http://localhost:8083}
            predicates:
              - Path=/mindmap/**
        # Mindmap Service Swagger API Docs
          - id: mindmap-service-swagger
            uri: ${MINDMAP_SERVICE_URL:http://localhost:8083}
            predicates:
              - Path=/mindmap-service/v3/api-docs/**
            filters:
              - StripPrefix=1
        # Trend Service ì •ì  ë¼ìš°íŒ…
          - id: trend-service
            uri: ${TREND_SERVICE_URL:http://localhost:8085}
            predicates:
              - Path=/trend/**
        # Trend Service Swagger API Docs
          - id: trend-service-swagger
            uri: ${TREND_SERVICE_URL:http://localhost:8085}
            predicates:
              - Path=/trend-service/v3/api-docs/**
            filters:
              - StripPrefix=1

server:
  port: 8080

jwt:
  secret: ${JWT_SECRET}

gateway:
  url: ${GATEWAY_URL:http://localhost:8080}

services:
  ai:
    host: ${AI_SERVICE_HOST:localhost}
    port: ${AI_SERVICE_PORT:8084}

# SpringDoc Swagger ì„¤ì •
springdoc:
  api-docs:
    enabled: true
  swagger-ui:
    enabled: true
    path: /swagger-ui.html
    urls:
      - name: user-service
        url: /user-service/v3/api-docs
      - name: workspace-service
        url: /workspace-service/v3/api-docs
      - name: mindmap-service
        url: /mindmap-service/v3/api-docs
      - name: trend-service
        url: /trend-service/v3/api-docs
    urls-primary-name: user-service

management:
  endpoints:
    web:
      exposure:
        include: health,info   # í•„ìš”í•˜ë©´ '*' (ìš´ì˜ì—ì„  health ì •ë„ ê¶Œì¥)
  endpoint:
    health:
      probes:
        enabled: true          # /actuator/health/liveness, /readiness ìë™ ìƒì„±
      show-details: never      # ìš´ì˜ ê¸°ë³¸ê°’. í•„ìš”ì‹œ when_authorized
```

> **ğŸ“ƒ user-service: application.yml**
> 

```java
spring:
  application:
    name: user-service 

  datasource:
    driver-class-name: org.postgresql.Driver
    url: jdbc:postgresql://${DB_HOST}:${DB_PORT}/${DB_NAME}
    username: ${DB_USERNAME}
    password: ${DB_PASSWORD}

  jpa:
    hibernate:
      ddl-auto: update
    show-sql: false
    properties:
      hibernate:
        format_sql: false
        dialect: org.hibernate.dialect.PostgreSQLDialect
    open-in-view: false

  data:
    redis:
      host: ${REDIS_HOST:localhost}
      port: ${REDIS_PORT:6379}
      password: ${REDIS_PASSWORD}

  security:
    oauth2:
      client:
        registration:
          google:
            client-id: ${GOOGLE_CLIENT_ID}
            client-secret: ${GOOGLE_CLIENT_SECRET}
            scope:
              - email
              - profile
#            redirect-uri: "{baseUrl}/login/oauth2/code/{registrationId}"
            redirect-uri: "${OAUTH2_REDIRECT_URI}"
        provider:
          google:
            authorization-uri: https://accounts.google.com/o/oauth2/v2/auth
            token-uri: https://oauth2.googleapis.com/token
            user-info-uri: https://www.googleapis.com/oauth2/v3/userinfo
            user-name-attribute: sub

jwt:
  secret: ${JWT_SECRET}
  access-token-expiration: 3600000  # 1ì‹œê°„
#  access-token-expiration: 60000  # 60ì´ˆ
  refresh-token-expiration: 604800000  # 7ì¼

google:
  client-id-mobile: ${GOOGLE_CLIENT_ID_MOBILE_MAC}
  client-id-ios: ${GOOGLE_CLIENT_ID_IOS}
  client-id-web: ${GOOGLE_CLIENT_ID}
  client-id-mobile-ssafy: ${GOOGLE_CLIENT_ID_MOBILE_SSAFY}

oauth2:
  redirect:
    frontend-url: ${FRONTEND_REDIRECT_URL}

server:
  port: 8081
  
management:
  endpoints:
    web:
      exposure:
        include: health,info   # í•„ìš”í•˜ë©´ '*' (ìš´ì˜ì—ì„  health ì •ë„ ê¶Œì¥)
  endpoint:
    health:
      probes:
        enabled: true          # /actuator/health/liveness, /readiness ìë™ ìƒì„±
      show-details: never      # ìš´ì˜ ê¸°ë³¸ê°’. í•„ìš”ì‹œ when_authorized
```

> **ğŸ“ƒ mindmap-service: application.yml**
> 

```java
spring:
  application:
    name: mindmap-service
  servlet:
    multipart:
      max-file-size: 10MB      # íŒŒì¼ í•˜ë‚˜ ìµœëŒ€ í¬ê¸°
      max-request-size: 20MB  # ìš”ì²­ ì „ì²´ í¬ê¸° (ì—¬ëŸ¬ íŒŒíŠ¸ í•©)

  # MongoDB ì„¤ì •
  data:
    mongodb:
      uri: ${MONGODB_URI:mongodb://localhost:27017}
      database: mindmap
      auto-index-creation: true

  # Kafka ì„¤ì •
  kafka:
    bootstrap-servers: ${KAFKA_BROKERS:localhost:9092}
    consumer:
      group-id: mindmap-service-consumer
      auto-offset-reset: latest # ìµœì‹  ë©”ì‹œì§€ë¶€í„° ì½ê¸°
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      enable-auto-commit: true
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
      acks: all # ëª¨ë“  ë³µì œë³¸ì´ í™•ì¸í•  ë•Œê¹Œì§€ ëŒ€ê¸°
      retries: 3

server:
  port: 8082

management:
  endpoints:
    web:
      exposure:
        include: health,info
  endpoint:
    health:
      probes:
        enabled: true
      show-details: never

# Kafka í† í”½ ì„¤ì •
kafka:
  topics:
    node-events: ${KAFKA_TOPIC_NODE_EVENTS:mindmap.node.events} # ë²Œí¬ CRUD
    node-update: ${KAFKA_TOPIC_NODE_UPDATE:mindmap.node.update} # AI ë¶„ì„ ê²°ê³¼ì— ë”°ë¥¸ ë…¸ë“œ ì—…ë°ì´íŠ¸ë¥¼ ì•Œë¦¬ëŠ” í† í”½
    ai-analysis-request: ${KAFKA_TOPIC_AI_REQUEST:ai.analysis.request} # AI ë¶„ì„ ìš”ì²­ í† í”½
    ai-suggestion: ${KAFKA_TOPIC_SUGGESTION_REQUEST:mindmap.ai.suggestion}
    ai-analysis-result: ${KAFKA_TOPIC_AI_RESULT:ai.analysis.result} # AI ë¶„ì„ ê²°ê³¼ í† í”½

# ë¡œê¹… ì„¤ì •
logging:
  level:
    root: INFO
    com.ssafy.mindmapservice: DEBUG
    org.springframework.data.mongodb: DEBUG
    org.springframework.kafka: INFO

# Workspace Service ì—°ë™
workspace:
  service:
    url: ${WORKSPACE_SERVICE_URL:http://localhost:8082}

elasticsearch:
  host: ${ELASTICSEARCH_URL}

feign:
  client:
    config:
      gmsOpenAiClient:
        connectTimeout: 5000
        readTimeout: 150000
  httpclient:
    enabled: false
  okhttp:
    enabled: true

cloud:
  aws:
    s3:
      region: ap-northeast-2
      thumbnail-bucket: o-o-bucket
      thumbnail-prefix: mindmap/image

gms:
  base-url: https://gms.ssafy.io/gmsapi
  api-key: ${GMS_KEY}

service:
  trend:
    url: ${TREND_SERVICE_URL:http://trend-svc:8085}
```

> **ğŸ“ƒ trend-service: application.yml**
> 

```java
spring:
  application:
    name: trend-service
  data:
    redis:
      host: ${REDIS_HOST}
      port: ${REDIS_PORT}
      password: ${REDIS_PASSWORD}
      lettuce:
        pool:
          max-active: 20
          max-idle: 10
          min-idle: 5
          max-wait: 2000ms
        shutdown-timeout: 200ms
  kafka:
    bootstrap-servers: ${KAFKA_HOST}
    consumer:
      group-id: trend-service-group
      auto-offset-reset: earliest
      enable-auto-commit: false
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.springframework.kafka.support.serializer.JsonDeserializer
      properties:
        spring.json.trusted.packages: "*"
        max.poll.records: 500
        max.poll.interval.ms: 300000
    listener:
      ack-mode: manual
      concurrency: 3

  datasource:
    url: jdbc:postgresql://${DB_HOST}:${DB_PORT}/${DB_NAME}
    username: ${DB_USERNAME}
    password: ${DB_PASSWORD}
    driver-class-name: org.postgresql.Driver
    hikari:
      maximum-pool-size: 20
      minimum-idle: 5
      connection-timeout: 20000
      idle-timeout: 300000
      max-lifetime: 1200000
      pool-name: TrendHikariPool

management:
  endpoints:
    web:
      exposure:
        include: health,info
  endpoint:
    health:
      probes:
        enabled: true
      show-details: never

trend:
  kafka:
    topic: mindmap.relation.events

  redis:
    ttl:
      daily-hash: 691200  # 8 days in seconds
      realtime-bucket: 7200  # 2 hours in seconds
      zset-cache: 600  # 10 minutes in seconds

  batch:
    # Redis -> DB ì§‘ê³„ ì£¼ê¸° (cron)
    aggregation-cron: "0 */10 * * * *"  # ë§¤ 10ë¶„ë§ˆë‹¤
    # ZSET ìºì‹œ ë¦¬ë¹Œë“œ ì£¼ê¸°
    cache-rebuild-cron: "0 */5 * * * *"  # ë§¤ 5ë¶„ë§ˆë‹¤
    # ë°°ì¹˜ ì²˜ë¦¬ ì‹œ í•œ ë²ˆì— ê°€ì ¸ì˜¬ í‚¤ ê°œìˆ˜
    scan-count: 100
    # ë¶„ì‚° ë½ íƒ€ì„ì•„ì›ƒ (ì´ˆ)
    lock-timeout: 300

  query:
    # ê¸°ë³¸ ì¡°íšŒ limit
    default-limit: 5
    max-limit: 100

# Logging
logging:
  level:
    root: INFO
    com.ssafy.trendservice: DEBUG
    org.springframework.kafka: WARN
    org.springframework.data.redis: WARN
  pattern:
    console: "%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n"

server:
  port: 8085
  shutdown: graceful

mindmap:
  service:
    url: http://mindmap-svc:8082

elasticsearch:
  host: ${ELASTICSEARCH_URL:http://k13d202.p.ssafy.io:9200}
```

> **ğŸ“ƒ mindmap-websocket-service: .env**
> 

```java
# Server Configuration
PORT=8084
NODE_ENV=development

# MongoDB Configuration (í•„ìš”ì‹œ)
MONGODB_URI=mongodb://k13d202.p.ssafy.io:27017

# Kafka Configuration
KAFKA_BROKERS=k13d202.p.ssafy.io:9092
KAFKA_CLIENT_ID=mindmap-websocket-service

# Kafka Topics
KAFKA_TOPIC_NODE_EVENTS=mindmap.node.events
KAFKA_TOPIC_NODE_UPDATE=mindmap.node.update
KAFKA_TOPIC_AI_REQUEST=ai.analysis.request
KAFKA_TOPIC_AI_RESULT=ai.analysis.result

# Kafka Consumer
KAFKA_CONSUMER_GROUP=mindmap-websocket-consumer

# Y.js Configuration
YDOC_GC_ENABLED=true
YDOC_PERSISTENCE_INTERVAL=5000

# Logging
LOG_LEVEL=debug

# Workspace Service
WORKSPACE_SERVICE_URL=http://workspace-svc:8083

#GMS_KEY
GMS_KEY=S13P32D202-9142ee31-e6c0-48b0-993a-230977adb8ef
GPT_MODEL=gpt-5-mini
```

> **ğŸ“ƒ runpod ai-service: .env (fastAPI)**
> 

```yaml
# HuggingFace Token (í•„ìˆ˜)
# https://huggingface.co/settings/tokens ì—ì„œ í† í° ìƒì„±
HUGGINGFACE_TOKEN=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

# API ì„œë²„ ì„¤ì •
PORT=8000

# HuggingFace Transfer ì„¤ì • (ì„ íƒ)
HF_HUB_ENABLE_HF_TRANSFER=0

# ngrok ìë§‰ ì„œë²„ URL (í•„ìˆ˜)
# ë¡œì»¬ ì»´í“¨í„°ì—ì„œ ì‹¤í–‰ ì¤‘ì¸ ìë§‰ ì„œë²„ì˜ ngrok URL
NGROK_SUBTITLE_SERVER_URL=https://vanesa-unconversant-noncuriously.ngrok-free.dev/

# Kafka ì„¤ì •
KAFKA_BOOTSTRAP_SERVERS=k13d202.p.ssafy.io:9092
KAFKA_REQUEST_TOPIC=ai.analysis.request
KAFKA_RESPONSE_TOPIC=ai.analysis.result
KAFKA_ORGANIZE_REQUEST_TOPIC=ai.organize.request
KAFKA_ORGANIZE_RESULT_TOPIC=ai.organize.result
KAFKA_GROUP_ID=ai-analysis-consumer

```

# ğŸ“Œ ë°°í¬ í™˜ê²½ ì„¤ì •

---

## 0. ì´ˆê¸° ì„¸íŒ…

### 1. Docker ì„¤ì¹˜

https://docs.docker.com/engine/install/ubuntu/ ê³µì‹ë¬¸ì„œ ì°¸ê³ 

1. Set up Docker'sÂ `apt`Â repository.

```bash
# Add Docker's official GPG key:
sudo apt-get update
sudo apt-get install ca-certificates curl
sudo install -m 0755 -d /etc/apt/keyrings
sudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc
sudo chmod a+r /etc/apt/keyrings/docker.asc

# Add the repository to Apt sources:
echo \
  "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \
  $(. /etc/os-release && echo "${UBUNTU_CODENAME:-$VERSION_CODENAME}") stable" | \
  sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
sudo apt-get update
```

1. Install the Docker packages.

```bash
sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin
```

## 1. Docker ì»¨í…Œì´ë„ˆ ìƒì„±

**: Jenkins, PostgreSQL, Redis, Mongo, Kafka, Elastic Search, ë¡œê·¸, ìƒíƒœ ìˆ˜ì§‘ì„ ìœ„í•œ ê°ì¢… Exporter, Grafana, Loki, Prometheus, ê°ì¢… GUI íˆ´ â†’ Pgadmin, Mongo Express,RedisInsight, cadvisor, kibana)**

- `docker ps` ê²°ê³¼

![image.png](attachment:8ba15a4b-92ad-42ed-881d-36a4680515b6:image.png)

**ğŸ“„docker-compose.yml**

```yaml
networks:
  backend:
    driver: bridge
  observability:
    driver: bridge

volumes:
  jenkins_data:
  grafana_data:
  prometheus_data:
  loki_data:
  pg1_data:
  pg2_data:
  pg3_data:
  pg4_data:
  mongo_data:
  redis_data:
  pgadmin_data:
  redisinsight_data:
  kafka_data:
  redis_trend_data:
  pg5_data:

services:
  # ========== CI ==========
  jenkins:
    build:
      context: ./jenkins
    container_name: jenkins
    user: "0:0"                       # ìµœì´ˆ ê¶Œí•œ ì •ë¦¬ë¥¼ ìœ„í•´ root, ì´í›„ 1000 ê¶Œì¥
    ports:
      - "8080:8080"                   # í•„ìš”ì‹œ SGë¡œ ì œí•œ
      - "50000:50000"
    environment:
      JAVA_OPTS: "-Xms512m -Xmx2048m -Duser.timezone=Asia/Seoul"
      # JENKINS_UC: https://updates.jenkins.io      # ë¯¸ëŸ¬ í•„ìš”ì‹œ ë³€ê²½
      # JENKINS_UC_DOWNLOAD: https://updates.jenkins.io
      # JENKINS_PLUGIN_MIRROR: https://your-mirror/jenkins/plugins
    volumes:
      - /home/ubuntu/jenkins-data:/var/jenkins_home
      - /var/run/docker.sock:/var/run/docker.sock  # Jenkinsì—ì„œ Docker ë¹Œë“œ í•„ìš” ì‹œ
      # - ./jenkins/init.groovy.d:/usr/share/jenkins/ref/init.groovy.d:ro
      # - ./jenkins/casc:/var/jenkins_home/casc:ro
    restart: unless-stopped
    networks: [backend]

  # ========== Databases ==========
  pg1:
    image: postgres:16
    container_name: user_db
    environment:
      POSTGRES_DB: user_db
      POSTGRES_USER: user_db_app
      POSTGRES_PASSWORD: ${your_password}
    volumes:
      - pg1_data:/var/lib/postgresql/data
    ports:
      - "5433:5432"       # í•„ìš” ì‹œ ì™¸ë¶€ ì ‘ì†, ì•„ë‹ˆë©´ ì£¼ì„ ì²˜ë¦¬
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U user_db_app"]
      interval: 10s
      timeout: 3s
      retries: 10
    restart: unless-stopped
    networks: [backend]

  pg2:
    image: postgres:16
    container_name: workspace_db
    environment:
      POSTGRES_DB: workspace_db
      POSTGRES_USER: workspace_db_app
      POSTGRES_PASSWORD: ${your_password}
    volumes:
      - pg2_data:/var/lib/postgresql/data
    ports:
      - "5434:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U workspace_db_app"]
      interval: 10s
      timeout: 3s
      retries: 10
    restart: unless-stopped
    networks: [backend]

  pg3:
    image: postgres:16
    container_name: mindmap_db
    environment:
      POSTGRES_DB: mindmap_db
      POSTGRES_USER: mindmap_db_app
      POSTGRES_PASSWORD: ${your_password}
    volumes:
      - pg3_data:/var/lib/postgresql/data
    ports:
      - "5435:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U mindmap_db_app"]
      interval: 10s
      timeout: 3s
      retries: 10
    restart: unless-stopped
    networks: [backend]

  pg4:
    image: postgres:16
    container_name: voice_db
    environment:
      POSTGRES_DB: voice_db
      POSTGRES_USER: voice_db_app
      POSTGRES_PASSWORD: ${your_password}
    volumes:
      - pg4_data:/var/lib/postgresql/data
    ports:
      - "5436:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U voice_db_app"]
      interval: 10s
      timeout: 3s
      retries: 10
    restart: unless-stopped
    networks: [backend]

  mongo:
    image: mongo:7
    container_name: mongo_db
    command: ["--wiredTigerCacheSizeGB", "1.0"]
    volumes:
      - mongo_data:/data/db
    ports:
      - "27017:27017"      # í•„ìš” ì‹œë§Œ ê°œë°©
    restart: unless-stopped
    networks: [backend]

  redis:
    image: redis:7
    container_name: redis_db
    command: ["redis-server", "--appendonly", "yes", "--requirepass", "${your_password}"]
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"        # í•„ìš” ì‹œë§Œ ê°œë°©
    restart: unless-stopped
    networks: [backend]

  # â”€â”€â”€â”€â”€â”€â”€â”€â”€ ê´€ì¸¡ìš© Exporters â”€â”€â”€â”€â”€â”€â”€â”€â”€
  node_exporter:
    image: prom/node-exporter:v1.8.1
    container_name: node_exporter
    # í˜¸ìŠ¤íŠ¸ ë¦¬ì†ŒìŠ¤ë¥¼ ê·¸ëŒ€ë¡œ ì½ìœ¼ë ¤ë©´ host ëª¨ë“œê°€ ì œì¼ ì •í™•
    network_mode: host
    pid: host
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - '--path.procfs=/host/proc'
      - '--path.sysfs=/host/sys'
      - '--path.rootfs=/rootfs'
    restart: unless-stopped

  cadvisor:
    image: gcr.io/cadvisor/cadvisor:v0.49.1
    container_name: cadvisor
    ports: ["8081:8080"]                 # ë‚´ë¶€ ì ‘ê·¼ë§Œ í•„ìš”í•˜ë©´ ports ì œê±°
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
    restart: unless-stopped
    networks: [observability]

  # Postgres 4ê°œëŠ” exporterë¥¼ ê° ì¸ìŠ¤í„´ìŠ¤ì— 1:1ë¡œ ë¶™ì´ëŠ” ê²Œ ê°€ì¥ ê°„ë‹¨
  user_pg_exporter:
    image: quay.io/prometheuscommunity/postgres-exporter:v0.15.0
    container_name: user_pg_exporter
    environment:
      DATA_SOURCE_NAME: "postgresql://user_db_app:1oo4!@user_db:5432/user_db?sslmode=disable"
    depends_on: [pg1]
    restart: unless-stopped
    networks: [backend, observability]

  workspace_pg_exporter:
    image: quay.io/prometheuscommunity/postgres-exporter:v0.15.0
    container_name: workspace_pg_exporter
    environment:
      DATA_SOURCE_NAME: "postgresql://workspace_db_app:1oo4!@workspace_db:5432/workspace_db?sslmode=disable"
    depends_on: [pg2]
    restart: unless-stopped
    networks: [backend, observability]

  mindmap_pg_exporter:
    image: quay.io/prometheuscommunity/postgres-exporter:v0.15.0
    container_name: mindmap_pg_exporter
    environment:
      DATA_SOURCE_NAME: "postgresql://mindmap_db_app:1oo4!@mindmap_db:5432/mindmap_db?sslmode=disable"
    depends_on: [pg3]
    restart: unless-stopped
    networks: [backend, observability]

  voice_pg_exporter:
    image: quay.io/prometheuscommunity/postgres-exporter:v0.15.0
    container_name: voice_pg_exporter
    environment:
      DATA_SOURCE_NAME: "postgresql://voice_db_app:1oo4!@voice_db:5432/voice_db?sslmode=disable"
    depends_on: [pg4]
    restart: unless-stopped
    networks: [backend, observability]

  redis_exporter:
    image: oliver006/redis_exporter:v1.62.0
    container_name: redis_exporter
    environment:
      REDIS_ADDR: "redis://redis_db:6379"
      # REDIS_PASSWORD: "ìˆìœ¼ë©´ ì¶”ê°€"
    depends_on: [redis]
    restart: unless-stopped
    networks: [backend, observability]

  mongodb_exporter:
    image: percona/mongodb_exporter:0.40.0
    container_name: mongodb_exporter
    command: ["--mongodb.uri=mongodb://mongo_db:27017"]
    depends_on: [mongo]
    restart: unless-stopped
    networks: [backend, observability]

  # ========== Observability ==========
  prometheus:
    image: prom/prometheus:v2.53.0
    container_name: prometheus
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    ports:
      - "9090:9090"        # EKSì˜ remote_writeê°€ ì°ì„ ëŒ€ìƒ (ë³´ì•ˆê·¸ë£¹ìœ¼ë¡œ EKS CIDRë§Œ í—ˆìš©)
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
      - "--storage.tsdb.retention.time=15d"
      - "--web.enable-remote-write-receiver"
    restart: unless-stopped
    networks: [observability]

  loki:
    image: grafana/loki:2.9.8
    container_name: loki
    ports:
      - "3100:3100"        # EKS promtailì´ pushí•  ì—”ë“œí¬ì¸íŠ¸
    command: ["-config.file=/etc/loki/local-config.yaml"]
    volumes:
      - ./loki/local-config.yaml:/etc/loki/local-config.yaml:ro
      - loki_data:/loki
    restart: unless-stopped
    networks: [observability]

  grafana:
    image: grafana/grafana:11.0.0
    container_name: grafana
    environment:
      GF_SECURITY_ADMIN_PASSWORD: ${your_password}   # ìš´ì˜ì—ì„  ë³€ê²½/ë¹„ë°€ê´€ë¦¬
      GF_SERVER_DOMAIN: "grafana.local"
      GF_SERVER_ROOT_URL: "%(protocol)s://%(domain)s/"
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/provisioning/datasources:/etc/grafana/provisioning/datasources:ro
    ports:
      - "3000:3000"
    depends_on:
      - prometheus
      - loki
    restart: unless-stopped
    networks: [observability]
  # =================db GUI===================
  pgadmin:
    image: dpage/pgadmin4:latest
    container_name: pgadmin
    environment:
      PGADMIN_DEFAULT_EMAIL: "rkddkwl059@yu.ac.kr"     # ë°”ê¿”
      PGADMIN_DEFAULT_PASSWORD: ${your_password}          # ë°”ê¿”
      PGADMIN_LISTEN_PORT: "80"
    volumes:
      - pgadmin_data:/var/lib/pgadmin
      # (ì„ íƒ) ì„œë²„ ìë™ ë“±ë¡í•˜ê³  ì‹¶ìœ¼ë©´ ì•„ë˜ ì£¼ì„ í•´ì œ í›„ servers.json ì¶”ê°€
      - ./pgadmin/servers.json:/pgadmin4/servers.json:ro
    ports:
      - "5050:80"     # ë³´ì•ˆê·¸ë£¹ìœ¼ë¡œ ë³¸ì¸ IPë§Œ í—ˆìš© ê¶Œì¥
    depends_on:
      - pg1
      - pg2
      - pg3
      - pg4
    restart: unless-stopped
    networks: [backend]

  redisinsight:
    image: redis/redisinsight:latest
    container_name: redisinsight
    ports:
      - "5540:5540"       # ê¸°ë³¸ í¬íŠ¸. ë³´ì•ˆê·¸ë£¹ìœ¼ë¡œ ì ‘ê·¼ ì œí•œ ê¶Œì¥
    volumes:
      - redisinsight_data:/data
    depends_on:
      - redis          # ë„¤ redis ì»¨í…Œì´ë„ˆ ì´ë¦„
    restart: unless-stopped
    networks: [backend]

  mongo_express:
    image: mongo-express:latest
    container_name: mongo_express
    environment:
      ME_CONFIG_MONGODB_SERVER: mongo_db
      ME_CONFIG_MONGODB_PORT: 27017
      ME_CONFIG_MONGODB_ENABLE_ADMIN: "true"
      # ë² ì´ì§ ì¸ì¦ ì¼œê¸°(í•„ìˆ˜ ê¶Œì¥)
      ME_CONFIG_BASICAUTH_USERNAME: "admin"
      ME_CONFIG_BASICAUTH_PASSWORD: ${your_password}
      # (ëª½ê³  ê³„ì • ì“°ë©´ ì—¬ê¸°ì— ìœ ì €/ë¹„ë²ˆ ì„¤ì •)
      ME_CONFIG_MONGODB_ADMINUSERNAME: "oo"
      ME_CONFIG_MONGODB_ADMINPASSWORD: ${your_password}
    ports:
      - "8083:8081"      # ë³´ì•ˆê·¸ë£¹ìœ¼ë¡œ ì œí•œ ê¶Œì¥
    depends_on: [mongo]
    restart: unless-stopped
    networks: [backend]

  kafka:
    image: apache/kafka:4.1.0
    container_name: kafka
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: controller,broker
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093
      KAFKA_LISTENERS: PLAINTEXT://:29092,EXTERNAL://:9092,CONTROLLER://:9093
  # 2) ê´‘ê³  ì£¼ì†Œ ë¶„ë¦¬: ë‚´ë¶€ëŠ” ì»¨í…Œì´ë„ˆDNS, ì™¸ë¶€ëŠ” ë„ë©”ì¸
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,EXTERNAL://k13d202.p.ssafy.io:9092
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT,CONTROLLER:PLAINTEXT
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: "1"          # offsets.topic.replication.factor
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: "1"  # transaction.state.log.replication.factor
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: "1"             # transar
      KAFKA_SHARE_COORDINATOR_STATE_TOPIC_REPLICATION_FACTOR: "1"  # share.coordinator.state.topic.replication.factor
      KAFKA_SHARE_COORDINATOR_STATE_TOPIC_MIN_ISR: "1"             # share.coordinator.state.topic.min.isr
      # í”„ë¡œë•ì…˜ì´ë¼ë©´ ì•„ë˜ ì„±ëŠ¥/ë³´ì•ˆ ì˜µì…˜ì„ ê°œë³„ íŠœë‹ ì¶”ì²œ
      # KAFKA_CFG_NUM_PARTITIONS: 3
      # KAFKA_CFG_DEFAULT_REPLICATION_FACTOR: 1
      # KAFKA_CFG_LOG_RETENTION_HOURS: 168
      KAFKA_LOG_DIRS: /var/lib/kafka/data
      KAFKA_HEAP_OPTS: "-Xms512m -Xmx512m"
    volumes:
      - kafka_data:/var/lib/kafka/data
    ports:
      - "9092:9092"    # ë‚´ë¶€/ê°œë°œìš©. ì™¸ë¶€ VPCì—ì„œ ì ‘ê·¼ì‹œí‚¤ì§€ ì•Šìœ¼ë©´ ìƒëµ ê¶Œì¥
      - "29092:29092"
    restart: unless-stopped
    networks: [backend]

  # Kafka Exporter (Prometheus)
  kafka_exporter:
    image: danielqsj/kafka-exporter:v1.7.0
    container_name: kafka_exporter
    command:
      - "--kafka.server=kafka:29092"
    depends_on: [kafka]
    ports:
      - "9308:9308"   # /metrics
    restart: unless-stopped
    networks: [observability, backend]

  # (ì˜µì…˜) Kafka UI - ë¸Œë¡œì»¤/í† í”½ ìƒíƒœ ëˆˆìœ¼ë¡œ ë³´ê¸° ì¢‹ìŒ
  kafka_ui:
    image: provectuslabs/kafka-ui:v0.7.2
    container_name: kafka_ui
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:29092
    depends_on: [kafka]
    ports:
      - "8082:8080"     # http://localhost:8082
    restart: unless-stopped
    networks: [backend]

  redis_trend:
    image: redis:7
    container_name: redis_trend_db
    command: ["redis-server", "--appendonly", "yes",  "--requirepass", "${your_password}"]
    volumes:
      - redis_trend_data:/data
    ports:
      - "6380:6379"        # í•„ìš” ì‹œë§Œ ê°œë°©
    restart: unless-stopped
    networks: [backend]

  pg5:
    image: postgres:16
    container_name: trend_db
    environment:
      POSTGRES_DB: trend_db
      POSTGRES_USER: trend_db_app
      POSTGRES_PASSWORD: ${your_password}
    volumes:
      - pg5_data:/var/lib/postgresql/data
    ports:
      - "5437:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U trend_db_app"]
      interval: 10s
      timeout: 3s
      retries: 10
    restart: unless-stopped
    networks: [backend]

```

- ì‹¤í–‰
    
    $ `docker compose up -d`
    
- ì»¨í…Œì´ë„ˆ ì ‘ì†
    
    $ `sudo docker exec -it [ì»¨í…Œì´ë„ˆ ì´ë¦„] bash`
    

```yaml
# prometheus/prometheus.yml

global:
  scrape_interval: 15s
  scrape_timeout: 10s
  evaluation_interval: 15s
external_labels:
  env: prod
  site: ec2-main

scrape_configs:
  # ìê¸° ìì‹ 
  - job_name: prometheus
    static_configs:
      - targets: ['prometheus:9090']
        labels: { service: prometheus }

  # â”€â”€ í˜¸ìŠ¤íŠ¸/ì»¨í…Œì´ë„ˆ ë¦¬ì†ŒìŠ¤ â”€â”€
  - job_name: node_exporter
    static_configs:
      # node_exporterë¥¼ host ë„¤íŠ¸ì›Œí¬ë¡œ ë„ì› ìœ¼ë‹ˆ localhost:9100
      - targets: ['localhost:9100']
        labels: { service: node }

  - job_name: cadvisor
    static_configs:
      - targets: ['cadvisor:8080']
        labels: { service: cadvisor }

  # â”€â”€ Postgres 4ê°œ â”€â”€
  - job_name: postgres_user
    static_configs:
      - targets: ['user_pg_exporter:9187']
        labels: { service: postgres, db: user_db, instance: pg1 }

  - job_name: postgres_workspace
    static_configs:
      - targets: ['workspace_pg_exporter:9187']
        labels: { service: postgres, db: workspace_db, instance: pg2 }

  - job_name: postgres_mindmap
    static_configs:
      - targets: ['mindmap_pg_exporter:9187']
        labels: { service: postgres, db: mindmap_db, instance: pg3 }

  - job_name: postgres_voice
    static_configs:
      - targets: ['voice_pg_exporter:9187']
        labels: { service: postgres, db: voice_db, instance: pg4 }

  # â”€â”€ Redis / Mongo â”€â”€
  - job_name: redis
    static_configs:
      - targets: ['redis_exporter:9121']
        labels: { service: redis }

  - job_name: mongo
    static_configs:
      - targets: ['mongodb_exporter:9216']
        labels: { service: mongo }

  # â”€â”€ Loki / Grafana â”€â”€
  - job_name: loki
    metrics_path: /metrics
    static_configs:
      - targets: ['loki:3100']
        labels: { service: loki }

  - job_name: grafana
    metrics_path: /metrics
    static_configs:
      - targets: ['grafana:3000']
        labels: { service: grafana }
    # grafanaì— metrics ê¸°ë³¸ auth ê±¸ì—ˆìœ¼ë©´ ì—¬ê¸° basic_auth ì¶”ê°€

  # â”€â”€ Jenkins (/prometheus) â”€â”€
  - job_name: jenkins
    metrics_path: /prometheus
    static_configs:
      - targets: ['jenkins:8080']
        labels: { service: jenkins }
    # Jenkinsì— ë¡œê·¸ì¸ í•„ìš”í•˜ë©´:
    # basic_auth:
    #   username: <user>
    #   password: <api-token>

```

```yaml
# loki/local-config.yaml
server:
  http_listen_port: 3100
  grpc_listen_port: 9096

auth_enabled: false

# ë‹¨ì¼ í”„ë¡œì„¸ìŠ¤ ê¸°ë³¸ ê²½ë¡œ/ì €ì¥ì†Œ
common:
  path_prefix: /loki
  storage:
    filesystem:
      chunks_directory: /loki/chunks
      rules_directory: /loki/rules
  compactor_address: 127.0.0.1

# ì¸ë±ìŠ¤/ì²­í¬ ìŠ¤í‚¤ë§ˆ
schema_config:
  configs:
    - from: 2024-01-01
      store: boltdb-shipper
      object_store: filesystem
      schema: v13
      index:
        prefix: index_
        period: 24h

# (ì¼ë¶€ ë²„ì „ì—ì„œ í•„ìš”) storage_config ë³‘í–‰ ì„ ì–¸
storage_config:
  filesystem:
    directory: /loki/chunks

chunk_store_config:
  max_look_back_period: 0s

table_manager:
  retention_deletes_enabled: true
  retention_period: 168h  # 7ì¼

```

```yaml
# grafana/provisioning/datasources/datasources.yml
apiVersion: 1
datasources:
  - name: Prometheus
    type: prometheus
    access: proxy
    url: http://prometheus:9090
    isDefault: true
  - name: Loki
    type: loki
    access: proxy
    url: http://loki:3100

```

```yaml
# jenkins/Dockerfile

USER root

# ê¸°ë³¸ ìœ í‹¸
RUN apt-get update && apt-get install -y \
    curl unzip tar gnupg git jq \
    && rm -rf /var/lib/apt/lists/*

# AWS CLI v2
RUN curl -fsSL "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o /tmp/awscliv2.zip \
 && unzip /tmp/awscliv2.zip -d /tmp \
 && /tmp/aws/install \
 && rm -rf /tmp/aws /tmp/awscliv2.zip

# kubectl
ARG KUBECTL_VERSION=v1.30.3
RUN curl -fsSL -o /usr/local/bin/kubectl \
  https://storage.googleapis.com/kubernetes-release/release/${KUBECTL_VERSION}/bin/linux/amd64/kubectl \
  && chmod +x /usr/local/bin/kubectl

# helm
ARG HELM_VERSION=v3.15.3
RUN curl -fsSL https://get.helm.sh/helm-${HELM_VERSION}-linux-amd64.tar.gz -o /tmp/helm.tgz \
 && tar -xzf /tmp/helm.tgz -C /tmp \
 && mv /tmp/linux-amd64/helm /usr/local/bin/helm \
 && chmod +x /usr/local/bin/helm \
 && rm -rf /tmp/helm.tgz /tmp/linux-amd64

# (ì„ íƒ) Node.js - í”„ë¡ íŠ¸ ë¹Œë“œ í•„ìš” ì‹œ
RUN curl -fsSL https://deb.nodesource.com/setup_20.x | bash - \
 && apt-get install -y nodejs \
 && npm i -g pnpm

USER jenkins

```

## 2. FrontEnd ë°°í¬

## S3

S3 ë²„í‚· ì‘ì„±ì¼ì(2025.11.03) ê¸°ì¤€ìœ¼ë¡œ ê¸°ë³¸ ìƒì„±

## AWS Certificate Manager

- í¼ë¸”ë¦­ ì¸ì¦ì„œ ìš”ì²­
- ë°›ì„ ë„ë©”ì¸ ì‘ì„±(ë£¨íŠ¸, www ë“± â†’ *.ë£¨íŠ¸ ì´ë©´ í•˜ìœ„ ì„œë¸Œ ë„ë©”ì¸ê¹Œì§€ ì „ë¶€)
- DNS ê²€ì¦
- ìš”ì²­ í›„ ë‚˜ì˜¤ëŠ” ê²°ê³¼ì— ë§ê²Œ DNS ì‚¬ì´íŠ¸ë“¤ì— ì…ë ¥ í•´ì„œ ê²€ì¦

## AWS Cloudfront

- UIê°€ ë§ì´ ë°”ë€Œì—ˆìŒ
- Single website or app
- Origin domain : ìƒì„±í•œ S3 ë²„í‚· ì„ íƒ
- ì›ë³¸ ì—‘ì„¸ìŠ¤ ì„¤ì • OAC â†’ ì˜ì–´ ë¬¸êµ¬ë¡œ ë³€ê²½
- ëŒ€ì²´ ë„ë©”ì¸ ì„¤ì • â†’ www.ë£¨íŠ¸
- SSL ì¸ì¦ì„œ ì—°ê²°
- SPA í”„ë¡œì íŠ¸ì¸ ê²½ìš° 403/404 â†’ index.htmlë¡œ ì—°ê²°
- ê¸°ë³¸ index.htmlë¡œ ì—°ê²°

## AWS

- jenkins-deploy
- IAM ì •ì±… ì„¤ì •

```bash
// jenkins-s3-cloudfront-policy
{
  "Version": "2012-10-17",
  "Statement": [
    {"Effect":"Allow","Action":["s3:ListBucket"],"Resource":"arn:aws:s3:::<S3_BUCKET>"},
    {"Effect":"Allow","Action":["s3:PutObject","s3:DeleteObject","s3:PutObjectAcl"],"Resource":"arn:aws:s3:::<S3_BUCKET>/*"},
    {"Effect":"Allow","Action":["cloudfront:CreateInvalidation"],"Resource":"*"}
  ]
}

```

- **AWS IAM AccessKey** ë°œê¸‰ í›„ Jenkins-credentialì— ë„£ê¸°

## 3. Jenkins ì„¤ì •

### ğŸ“ƒ ì  í‚¨ìŠ¤ íŒŒì´í”„ë¼ì¸ ìŠ¤í¬ë¦½íŠ¸

: **Gitlab access token** ë°œê¸‰ í›„ Jenkins-credentialì— ë„£ê¸°

- NodeJS Plugin ì‚¬ìš©í• ë ¤ê³  í–ˆì§€ë§Œ ì ìš©ì´ ë˜ì§€ ì•Šì•„ Jenkins ì»¨í…Œì´ë„ˆ ì•ˆì— nodejs ì„¤ì¹˜

```yaml
pipeline {
  agent any
  options {
    timestamps()
    gitLabConnection('o-o') // Jenkins > Configure System > GitLab ì—°ê²° ì´ë¦„
  }

  environment {
    AWS_REGION   = 'ap-northeast-2'
    S3_BUCKET    = 'o-o-frontend'
    CF_DIST_ID   = '{Your ID}'
    BUILD_DIR    = 'dist'
    NODE_OPTIONS = '--max-old-space-size=2048'
  }

  stages {

    stage('1) Checkout') {
      steps {
        gitlabCommitStatus(name: '1) Checkout') {
          checkout scm
          sh 'echo "Branch: ${BRANCH_NAME}"'
        }
      }
    }

    stage('2) Install & Build') {
      steps {
        gitlabCommitStatus(name: '2) Install & Build') {
          withCredentials([
            string(credentialsId: 'fb-api-key', variable: 'FB_API_KEY'),
            string(credentialsId: 'fb-auth-domain', variable: 'FB_AUTH_DOMAIN'),
            string(credentialsId: 'fb-project-id', variable: 'FB_PROJECT_ID'),
            string(credentialsId: 'fb-storage-bucket', variable: 'FB_STORAGE_BUCKET'),
            string(credentialsId: 'fb-msg-sender', variable: 'FB_MESSAGING_SENDER_ID'),
            string(credentialsId: 'fb-app-id', variable: 'FB_APP_ID'),
            string(credentialsId: 'gg-client-id', variable: 'GG_CLIENT_ID'),
            string(credentialsId: 'vite-api-url', variable: 'VITE_API_URL'),
            string(credentialsId: 'ws_url', variable: 'VITE_WS_URL'),
            string(credentialsId: 'login-api-url', variable: 'VITE_LOGIN_API_URL')
          ]) {
            dir('front/o-o') {
              sh '''
                echo "=== Write .env.production ==="
                cat > .env.production <<EOF
VITE_FIREBASE_API_KEY=${FB_API_KEY}
VITE_FIREBASE_AUTH_DOMAIN=${FB_AUTH_DOMAIN}
VITE_FIREBASE_PROJECT_ID=${FB_PROJECT_ID}
VITE_FIREBASE_STORAGE_BUCKET=${FB_STORAGE_BUCKET}
VITE_FIREBASE_MESSAGING_SENDER_ID=${FB_MESSAGING_SENDER_ID}
VITE_FIREBASE_APP_ID=${FB_APP_ID}
VITE_GOOGLE_CLIENT_ID=${GG_CLIENT_ID}
VITE_API_URL=${VITE_API_URL}
VITE_WS_URL=${VITE_WS_URL}
VITE_LOGIN_API_URL=${VITE_LOGIN_API_URL}
EOF

                node -v && npm -v
                [ -f package-lock.json ] && npm ci || npm install
                npm i -D @rollup/rollup-linux-x64-gnu
                npm run build

                echo "=== Build output check ==="
                ls -lah ${BUILD_DIR} || { echo "âŒ ${BUILD_DIR} not found"; exit 1; }
              '''
            }
          }
        }
      }
    }

    stage('3) Upload to S3') {
      steps {
        gitlabCommitStatus(name: '3) Upload to S3') {
          sh 'test -d front/o-o/${BUILD_DIR} || { echo "${BUILD_DIR} not found"; ls -R front/o-o; exit 1; }'
          dir('front/o-o') {
            withAWS(credentials: 'aws-frontend-deploy', region: "${AWS_REGION}") {
              sh """
                echo "=== Upload static assets to S3 ==="
                aws s3 sync ${BUILD_DIR} s3://${S3_BUCKET} \
                  --delete \
                  --exclude "index.html" \
                  --cache-control "public,max-age=31536000,immutable"

                echo "=== Upload index.html (no-cache) ==="
                aws s3 cp ${BUILD_DIR}/index.html s3://${S3_BUCKET}/index.html \
                  --cache-control "no-cache,no-store,must-revalidate" \
                  --metadata-directive REPLACE \
                  --content-type "text/html; charset=utf-8"
              """
            }
          }
        }
      }
    }

    stage('4) CloudFront Invalidation') {
      steps {
        gitlabCommitStatus(name: '4) CloudFront Invalidation') {
          withAWS(credentials: 'aws-frontend-deploy', region: "${AWS_REGION}") {
            sh '''
              echo "=== Invalidate CloudFront Cache ==="
              aws cloudfront create-invalidation \
                --distribution-id ${CF_DIST_ID} \
                --paths "/*"
            '''
          }
        }
      }
    }
  }

  post {
    success {
      echo 'âœ… Deploy done: S3 upload + CloudFront invalidation completed.'
      updateGitlabCommitStatus name: 'frontend-deploy', state: 'success'
    }
    failure {
      echo 'âŒ Deploy failed. Check console log.'
      updateGitlabCommitStatus name: 'frontend-deploy', state: 'failed'
    }
    always {
      cleanWs(deleteDirs: true, notFailBuild: true)
    }
  }
}

```

### **ğŸ”‘ Credential ê´€ë¦¬**

![image.png](attachment:0c758383-1b8b-4a3a-a3dd-58a30887cbb4:image.png)

## 4. Backend ë°°í¬

### 1. IAM ì—­í•  êµ¬ì„±

- í´ëŸ¬ìŠ¤í„° ì œì–´ìš© IAM ì—­í•  ìƒì„± (EKS Cluster Role)
- ë…¸ë“œ ê·¸ë£¹ìš© IAM ì—­í•  ìƒì„± (EC2 ì‹¤í–‰ ë° ECR Pull ê¶Œí•œ í¬í•¨)
- Jenkins ECR Pushìš© IAM User ìƒì„± (Access Key ë°©ì‹ ì¸ì¦)

â€» JenkinsëŠ” Instance Roleì´ ì•„ë‹ˆë¼ Access Key ê¸°ë°˜ ì¸ì¦ ì‚¬ìš©

---

### 2. Kubernetes í´ëŸ¬ìŠ¤í„° ìƒì„± ì„¤ì •

- Kubernetes Version: 1.33
- ì¸ì¦ ë°©ì‹: Access Entry ê¸°ë°˜ (ê¸°ì¡´ aws-auth ConfigMap ë¯¸ì‚¬ìš©)
- ARC í™œì„±í™” ì„ íƒ
    
    â†’ ì™¸ë¶€ë§ ë¬¸ì œê°€ ìˆì–´ë„ ë‚´ë¶€ í†µì‹  ìœ ì§€ ê°€ëŠ¥í•œ ì¸í”„ë¼ êµ¬ì¡° ì ìš©
    

---

### 3. ë„¤íŠ¸ì›Œí¬ êµ¬ì„±

- CIDR: 10.0.0.0/16
- Public Subnet 2ê°œ(ì„œë¡œ ë‹¤ë¥¸ AZë¡œ êµ¬ì„±)
- DNS ì˜µì…˜ í™œì„±í™”

ìˆ˜í–‰ ì¤‘ í•´ê²°í•œ ë¬¸ì œ

- NodeGroup ìƒì„± ì‹œ Public IP ìë™í• ë‹¹ ë¹„í™œì„±í™” ê²½ê³  ë°œìƒ
- Subnet ì„¤ì •ì—ì„œ Auto-assign IPv4 Address í™œì„±í™”ë¡œ ìˆ˜ì •
- NodeGroup ì¬ìƒì„±í•˜ì—¬ ì •ìƒ ë™ì‘ í™•ì¸

---

### 4. Node Group êµ¬ì„±

- ì¸ìŠ¤í„´ìŠ¤: t3a.medium * 2 ì„ íƒ (ê°€ì„±ë¹„ ê³ ë ¤)
- Public Subnetì— ë°°í¬
- Public IPv4 ìë™ í• ë‹¹ í™œì„±í™” ì™„ë£Œ

---

### 5. AWS Load Balancer Controller ì„¤ì¹˜ ì ˆì°¨

1. Kubeconfig ì—…ë°ì´íŠ¸ ë° ë³€ìˆ˜ í™•ì¸

```bash
aws eks update-kubeconfig --region <REGION> --name <CLUSTER>

ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)

VPC_ID=$(aws eks describe-cluster --name <CLUSTER> --region <REGION> \
  --query "cluster.resourcesVpcConfig.vpcId" --output text)

```

1. OIDC ì—°ë™

```bash
eksctl utils associate-iam-oidc-provider \
  --cluster <CLUSTER> --region <REGION> --approve

```

1. IAM Policy ìƒì„±

```bash
aws iam create-policy \
  --policy-name AWSLoadBalancerControllerIAMPolicy \
  --policy-document file://iam-policy.json

```

1. ServiceAccountê³¼ IAM Role ì—°ê²° (IRSA ì ìš©)

```bash
eksctl create iamserviceaccount \
  --cluster <CLUSTER> \
  --region <REGION> \
  --namespace kube-system \
  --name aws-load-balancer-controller \
  --attach-policy-arn arn:aws:iam::$ACCOUNT_ID:policy/AWSLoadBalancerControllerIAMPolicy \
  --override-existing-serviceaccounts \
  --approve

```

1. Helmìœ¼ë¡œ AWS Load Balancer Controller ì„¤ì¹˜

```bash
helm repo add eks https://aws.github.io/eks-charts
helm repo update

helm upgrade --install aws-load-balancer-controller eks/aws-load-balancer-controller \
  -n kube-system \
  --set clusterName=<CLUSTER> \
  --set region=<REGION> \
  --set vpcId=$VPC_ID \
  --set serviceAccount.create=false \
  --set serviceAccount.name=aws-load-balancer-controller

```

ì„¤ì¹˜ í™•ì¸

```bash
kubectl -n kube-system get deploy aws-load-balancer-controller

```

---

### 6. ECR + Jenkins ì—°ë™ êµ¬ì„±

- Docker ì„¤ì¹˜ë¥¼ Jenkins ì»¨í…Œì´ë„ˆ ë‚´ë¶€ì—ì„œ ì§ì ‘ ìˆ˜í–‰

```bash
curl -fsSL https://get.docker.com | bash

```

- AWS Access Keyë¡œ Jenkins ì¸ì¦
    
    (aws sts get-caller-identity ë¡œ í™•ì¸)
    
- Jenkinsì—ì„œ ECR ë¡œê·¸ì¸ ëª…ë ¹ì–´ ì‚¬ìš©

```bash
aws ecr get-login-password --region <REGION> \
 | docker login --username AWS \
   --password-stdin $ACCOUNT_ID.dkr.ecr.<REGION>.amazonaws.com

```

- Docker HubëŠ” ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë©°
    
    ëª¨ë“  ì´ë¯¸ì§€ PushëŠ” Amazon ECRë¡œë§Œ ìˆ˜í–‰
    

## 5. Jenkins ì„¤ì •

```yaml
pipeline {
  agent any
  options {
    timestamps()
    // Manage Jenkins > Configure System > GitLab ì—ì„œ ë§Œë“  ì—°ê²° ì´ë¦„
    gitLabConnection('o-o')
  }

  environment {
    AWS_REGION      = 'ap-northeast-2'
    CLUSTER         = 'o-o-cluster'
    ECR_REPO        = 'o-o-backend'
    NAMESPACE       = 'prod'
    PARALLEL_BUILD  = 'true'
    // ì „ì²´ íŒŒì´í”„ë¼ì¸ ìƒíƒœ ë¼ë²¨
    GITLAB_STAGE    = 'backend-deploy'
  }

  stages {

    stage('Checkout') {
      steps {
        gitlabCommitStatus(name: '1) Checkout') {
          checkout scm
        }
      }
    }

    stage('ECR Login & Ensure Repo') {
      steps {
        gitlabCommitStatus(name: '2) ECR Login & Ensure Repo') {
          withCredentials([usernamePassword(credentialsId: 'aws-creds-b',
                                            usernameVariable: 'AWS_ACCESS_KEY_ID',
                                            passwordVariable: 'AWS_SECRET_ACCESS_KEY')]) {
            sh '''
              set -e
              export AWS_DEFAULT_REGION=${AWS_REGION}
              export AWS_EC2_METADATA_DISABLED=true

              ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
              echo "[whoami] $ACCOUNT_ID"

              aws ecr describe-repositories --repository-names ${ECR_REPO} >/dev/null 2>&1 || \
                aws ecr create-repository --repository-name ${ECR_REPO} --image-scanning-configuration scanOnPush=true

              aws ecr get-login-password --region ${AWS_REGION} \
                | docker login --username AWS --password-stdin ${ACCOUNT_ID}.dkr.ecr.${AWS_REGION}.amazonaws.com

              echo $ACCOUNT_ID > .b_account_id
            '''
          }
        }
      }
    }

    stage('Detect Services to Build') {
      steps {
        gitlabCommitStatus(name: '3) Detect Services') {
          sh '''
            set -e
            SERVICES=$(ls -d backend/*-service 2>/dev/null | xargs -n1 basename || true)
            [ -z "$SERVICES" ] && { echo "No backend/*-service found"; exit 1; }

            CHANGED=""
            if git rev-parse --verify -q "$GIT_PREVIOUS_SUCCESSFUL_COMMIT" >/dev/null 2>&1; then
              DIFF_FILES=$(git diff --name-only "$GIT_PREVIOUS_SUCCESSFUL_COMMIT" "$GIT_COMMIT" || true)
              for SVC in $SERVICES; do
                echo "$DIFF_FILES" | grep -q "^backend/${SVC}/" && CHANGED="$CHANGED $SVC"
              done
            fi

            [ -z "$CHANGED" ] && CHANGED="$SERVICES"
            echo "$CHANGED" | xargs -n1 > .services_to_build
            echo "[plan] will build:"; cat .services_to_build
          '''
        }
      }
    }

    stage('Build & Push (parallel)') {
      steps {
        gitlabCommitStatus(name: '4) Build & Push') {
          script {
            def tasks = [:]
            def accountId = sh(returnStdout: true, script: "cat .b_account_id").trim()
            def services   = readFile('.services_to_build').split("\\r?\\n").findAll { it?.trim() }
            def failed     = []

            services.each { svc ->
              tasks[svc] = {
                try {
                  sh '''#!/usr/bin/env bash
set -euo pipefail
TAG="''' + svc + '''-''' + env.BUILD_NUMBER + '''"
LATEST_TAG="''' + svc + '''-latest"
ACCOUNT_ID=$(cat .b_account_id)
URI="${ACCOUNT_ID}.dkr.ecr.${AWS_REGION}.amazonaws.com/${ECR_REPO}:${TAG}"
LATEST_URI="${ACCOUNT_ID}.dkr.ecr.${AWS_REGION}.amazonaws.com/${ECR_REPO}:${LATEST_TAG}"

docker build -t ${ECR_REPO}:${TAG} ./backend/''' + svc + '''
docker tag ${ECR_REPO}:${TAG} ${URI}
docker tag ${ECR_REPO}:${TAG} ${LATEST_URI}
docker push ${URI}
docker push ${LATEST_URI}
echo "''' + svc + ''' ${URI}" > .img_''' + svc + '''
'''
                } catch (e) {
                  echo "[FAIL] ${svc}: ${e}"
                  failed << svc
                }
              }
            }

            parallel tasks

            sh 'rm -f .pushed_images || true; cat .img_* > .pushed_images || true'

            if (failed) {
              echo "[WARN] Failed services: ${failed.join(', ')}"
            }

            def pushed = sh(returnStdout:true, script: "test -s .pushed_images && wc -l < .pushed_images || echo 0").trim()
            if (pushed == "0") {
              error("No images pushed. Failing the build.")
            }
          }
        }
      }
    }

    stage('Kubeconfig') {
      steps {
        gitlabCommitStatus(name: '5) Kubeconfig') {
          withCredentials([usernamePassword(credentialsId: 'aws-creds-b',
                                            usernameVariable: 'AWS_ACCESS_KEY_ID',
                                            passwordVariable: 'AWS_SECRET_ACCESS_KEY')]) {
            sh '''
              set -e
              export AWS_DEFAULT_REGION=${AWS_REGION}
              export AWS_EC2_METADATA_DISABLED=true
              aws eks update-kubeconfig --region ${AWS_REGION} --name ${CLUSTER}
            '''
          }
        }
      }
    }

    stage('Apply K8s Manifests (always)') {
      steps {
        gitlabCommitStatus(name: '6) Apply Manifests') {
          withCredentials([usernamePassword(credentialsId: 'aws-creds-b',
                                            usernameVariable: 'AWS_ACCESS_KEY_ID',
                                            passwordVariable: 'AWS_SECRET_ACCESS_KEY')]) {
            sh '''
              set -e
              export AWS_DEFAULT_REGION=${AWS_REGION}
              export AWS_EC2_METADATA_DISABLED=true
              kubectl apply -f backend/k8s/base/namespace.yaml
              kubectl -n ${NAMESPACE} apply -f backend/k8s/apps/
              kubectl -n ${NAMESPACE} apply -f backend/k8s/base/ingress-alb.yaml
            '''
          }
        }
      }
    }

    stage('Rolling Update') {
      steps {
        gitlabCommitStatus(name: '7) Rolling Update') {
          withCredentials([usernamePassword(credentialsId: 'aws-creds-b',
                                            usernameVariable: 'AWS_ACCESS_KEY_ID',
                                            passwordVariable: 'AWS_SECRET_ACCESS_KEY')]) {
            sh '''
              set -e
              export AWS_DEFAULT_REGION=${AWS_REGION}
              export AWS_EC2_METADATA_DISABLED=true

              while read line; do
                SVC=$(echo $line | awk '{print $1}')
                IMG=$(echo $line | awk '{print $2}')
                BASE=${SVC%-service}
                DEPLOY="${BASE}-deploy"
                CONTAINER="${BASE}"
                if kubectl -n ${NAMESPACE} get deploy/${DEPLOY} >/dev/null 2>&1; then
                  kubectl -n ${NAMESPACE} set image deploy/${DEPLOY} ${CONTAINER}=${IMG}
                else
                  echo "[skip] ${DEPLOY} not found"
                fi
              done < .pushed_images

              while read line; do
                SVC=$(echo $line | awk '{print $1}')
                BASE=${SVC%-service}
                DEPLOY="${BASE}-deploy"
                kubectl -n ${NAMESPACE} get deploy/${DEPLOY} >/dev/null 2>&1 && \
                  kubectl -n ${NAMESPACE} rollout status deploy/${DEPLOY} || true
              done < .pushed_images
            '''
          }
        }
      }
    }
  }

  post {
    always {
      sh 'rm -f .b_account_id .services_to_build .pushed_images .img_* || true'
    }
    success {
      updateGitlabCommitStatus name: "${GITLAB_STAGE}", state: 'success'
    }
    failure {
      updateGitlabCommitStatus name: "${GITLAB_STAGE}", state: 'failed'
    }
  }
}

```

### **ğŸ”‘ Credential ê´€ë¦¬**

![image.png](attachment:0c758383-1b8b-4a3a-a3dd-58a30887cbb4:image.png)

## 6. ë°°í¬ ìœ„í•œ íŒŒì¼ ìƒì„±

### [Backend - Spring]

1. **SpringBoot Dockerfile ìƒì„±**
    
    **ğŸ“ƒ Dockerfile**
    
    ```docker
    # ===== BUILD =====
    FROM gradle:8.10.2-jdk21 AS build
    WORKDIR /workspace
    
    # wrapper/ìŠ¤í¬ë¦½íŠ¸ ë¨¼ì € ë³µì‚¬ (ìºì‹œ ìµœì í™” & ê¶Œí•œ ë³´ì •)
    COPY gradlew ./
    COPY gradle/wrapper/ ./gradle/wrapper/
    COPY build.gradle settings.gradle ./
    RUN chmod +x gradlew
    
    # ì†ŒìŠ¤ ë³µì‚¬
    COPY src ./src
    
    # Gradle ìºì‹œ ì‚¬ìš© (gradle ì´ë¯¸ì§€ì˜ ê¸°ë³¸ í™ˆì„ ë”°ë¼ê°)
    RUN --mount=type=cache,target=/home/gradle/.gradle \
        ./gradlew clean bootJar -x test --no-daemon
    
    # ì‚°ì¶œë¬¼ ë³µì‚¬
    RUN JAR_PATH=$(ls build/libs/*SNAPSHOT.jar 2>/dev/null || ls build/libs/*.jar | grep -v plain | head -n1) \
     && cp "$JAR_PATH" /app.jar
    
    # ===== RUNTIME =====
    FROM eclipse-temurin:21-jre-alpine
    ENV TZ=Asia/Seoul \
        JAVA_OPTS="-XX:+UseG1GC -XX:MaxRAMPercentage=75.0 -XX:InitialRAMPercentage=50.0"
    WORKDIR /app
    
    # í—¬ìŠ¤ì²´í¬ì— curl/wget í•„ìš”í•˜ë©´ í•˜ë‚˜ ì„¤ì¹˜
    RUN apk add --no-cache curl
    
    COPY --from=build /app.jar /app/app.jar
    
    # ì•± í¬íŠ¸ì— ë§ì¶° í†µì¼ (8081ì„ ì“¸ê±°ë©´ ì•„ë˜ ë‘˜ ë‹¤ 8081ë¡œ)
    EXPOSE 8082
    HEALTHCHECK --interval=15s --timeout=3s --retries=10 \
      CMD curl -fsS http://127.0.0.1:8082/actuator/health || exit 1
    
    ENTRYPOINT ["sh","-c","java $JAVA_OPTS -jar /app/app.jar"]
    
    ```
    
- ì„œë²„ë³„ í¬íŠ¸ë¡œ ë°”ê¿”ì„œ ì´ë¯¸ì§€ ìƒì„±

### [Backend - NodeJS

Y.js + WebRTC ì„œë²„

1. **ğŸ“ƒ Dockerfile**
    
    ```docker
    # Multi-stage build for Node.js Mindmap WebSocket Service
    
    # Stage 1: Build
    FROM node:20-alpine AS builder
    
    WORKDIR /app
    
    # Copy package files
    COPY package*.json ./
    
    # Install dependencies
    RUN npm ci --only=production
    
    # Copy source code
    COPY . .
    
    # Stage 2: Production
    FROM node:20-alpine
    
    # Add labels for maintainability
    LABEL maintainer="o-O Team"
    LABEL service="mindmap-websocket-service"
    LABEL description="Real-time collaboration server for o-O mindmap using Y.js"
    
    WORKDIR /app
    
    # Create non-root user
    RUN addgroup -g 1001 -S nodejs && \
        adduser -S nodejs -u 1001
    
    # Copy dependencies and source from builder
    COPY --from=builder --chown=nodejs:nodejs /app/node_modules ./node_modules
    COPY --from=builder --chown=nodejs:nodejs /app/src ./src
    COPY --from=builder --chown=nodejs:nodejs /app/package.json ./
    
    # Switch to non-root user
    USER nodejs
    
    # Expose port
    EXPOSE 8084
    
    # Health check
    HEALTHCHECK --interval=30s --timeout=3s --start-period=10s --retries=3 \
        CMD node -e "require('http').get('http://localhost:8084/health', (r) => {process.exit(r.statusCode === 200 ? 0 : 1)})"
    
    # Start the server
    CMD ["node", "src/server.js"]
    
    ```
    

### [Backend - fastAPI]

- Llama Model
- Runpodì— ë°°í¬
- ìˆ˜ë™ ë°°í¬ / í¬íŠ¸ ì—´ì–´ì„œ ì™¸ë¶€ì—ì„œ ì ‘ê·¼

### [EKS]

- **Elastic Kubernetes Service**
1. **ğŸ“ƒ deploy**
    
    ```yaml
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: gateway-deploy
      namespace: prod
    spec:
      replicas: 1
      strategy:
        type: RollingUpdate
        rollingUpdate:
          maxSurge: 1
          maxUnavailable: 0
      selector: { matchLabels: { app: gateway } }
      template:
        metadata: { labels: { app: gateway } }
        spec:
          containers:
            - name: gateway
              image: "559543475782.dkr.ecr.ap-northeast-2.amazonaws.com/o-o-backend:gateway-service-latest"
              imagePullPolicy: Always
              ports: [{ containerPort: 8080 }]
              resources:
                requests: { cpu: "150m", memory: "256Mi" }
                limits:   { cpu: "500m", memory: "512Mi" }
              readinessProbe:
                httpGet: { path: /actuator/health/readiness, port: 8080 }
                initialDelaySeconds: 10
                periodSeconds: 5
              livenessProbe:
                httpGet: { path: /actuator/health/liveness, port: 8080 }
                initialDelaySeconds: 20
                periodSeconds: 10
              envFrom:
                - configMapRef:
                    name: gateway-config
                - secretRef:
                    name: gateway-secret
    ---
    apiVersion: v1
    kind: Service
    metadata:
      name: gateway-svc
      namespace: prod
    spec:
      type: NodePort
      selector: { app: gateway }
      ports:
        - name: http
          port: 80
          targetPort: 8080
    ---
    apiVersion: autoscaling/v2
    kind: HorizontalPodAutoscaler
    metadata:
      name: gateway-hpa
      namespace: prod
    spec:
      scaleTargetRef:
        apiVersion: apps/v1
        kind: Deployment
        name: gateway-deploy
      minReplicas: 1
      maxReplicas: 2
      metrics:
        - type: Resource
          resource:
            name: cpu
            target:
              type: Utilization
              averageUtilization: 70
      behavior:
        scaleUp:
          stabilizationWindowSeconds: 0
          policies:
            - type: Percent
              value: 100
              periodSeconds: 60
        scaleDown:
          stabilizationWindowSeconds: 180
          policies:
            - type: Percent
              value: 50
              periodSeconds: 60
    ```
    
2. **ğŸ“ƒ ConfigMap, Secret**
    
    ```yaml
    apiVersion: v1
    kind: ConfigMap
    metadata:
      name: gateway-config
      namespace: prod
    data:
      USER_SERVICE_URL: ${Your Value}
      WORKSPACE_SERVICE_URL: "${Your Value}
      MINDMAP_SERVICE_URL: ${Your Value}
      MINDMAP_WEBSOCKET_SERVICE_URL: ${Your Value}
      TREND_SERVICE_URL: ${Your Value}
    ---
    apiVersion: v1
    kind: Secret
    metadata:
      name: gateway-secret
      namespace: prod
    type: Opaque
    stringData:
      JWT_SECRET: ${Your Value}
    ```
    
- ê°ê°ì˜ ì„œë¹„ìŠ¤ ë§ˆë‹¤ ë§ê²Œ í¬íŠ¸, ë³€ìˆ˜, ê°’ ë“±ë§Œ ë³€ê²½

## 5. ì°¸ê³ : EC2ë‚´ íŒŒì¼êµ¬ì¡°

```bash
/opt/infra
â”œâ”€â”€ prometheus/
â”‚   â””â”€â”€ prometheus.yml
â”œâ”€â”€ loki/
â”‚   â””â”€â”€ local-config.yaml
â”œâ”€â”€ grafana/
â”‚   â””â”€â”€ provisioning/
â”‚       â””â”€â”€ datasources/
â”‚           â””â”€â”€ datasources.yml
â””â”€â”€ jenkins/
    â””â”€â”€ Dockerfile
```