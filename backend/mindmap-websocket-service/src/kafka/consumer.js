/**
 * Kafka Consumer Service - AI ë¶„ì„ ì™„ë£Œ ì•Œë¦¼ ìˆ˜ì‹ 
 *
 * ì™œ í•„ìš”í•œê°€?
 * - Spring Mindmap Serviceê°€ RunPodì—ì„œ AI ë¶„ì„ì„ ì™„ë£Œí•˜ë©´
 * - Kafka í† í”½(mindmap.node.update)ìœ¼ë¡œ ê²°ê³¼ë¥¼ ë°œí–‰
 * - Node.jsê°€ ì´ë¥¼ ìˆ˜ì‹ í•˜ì—¬ Y.Docì— ì—…ë°ì´íŠ¸
 * - ëª¨ë“  ì—°ê²°ëœ í´ë¼ì´ì–¸íŠ¸ì—ê²Œ ì‹¤ì‹œê°„ ì „íŒŒ
 *
 * í”Œë¡œìš°:
 * 1. ì´ë¯¸ì§€/ì˜ìƒ ë…¸ë“œ ì¶”ê°€ â†’ Y.js ë™ê¸°í™”
 * 2. Kafka (mindmap.node.events) â†’ Spring
 * 3. Spring â†’ RunPod AI ë¶„ì„ ìš”ì²­
 * 4. AI ì™„ë£Œ â†’ Spring â†’ Kafka (mindmap.node.update)
 * 5. Node.js Consumer ìˆ˜ì‹  â†’ Y.Doc ì—…ë°ì´íŠ¸
 * 6. ëª¨ë“  í´ë¼ì´ì–¸íŠ¸ ìë™ ë™ê¸°í™”
 */

import { Kafka } from 'kafkajs';
import { logger } from '../utils/logger.js';
import { ydocManager } from '../yjs/ydoc-manager.js';

class KafkaConsumerService {
  constructor() {
    this.kafka = null;          // Kafka í´ë¼ì´ì–¸íŠ¸ ì¸ìŠ¤í„´ìŠ¤
    this.consumer = null;        // Kafka Consumer ì¸ìŠ¤í„´ìŠ¤
    this.isEnabled = false;      // Kafka ì‚¬ìš© ì—¬ë¶€ (í™˜ê²½ë³€ìˆ˜ë¡œ ì œì–´)
    this.isConnected = false;    // Kafka ì—°ê²° ìƒíƒœ
    this.onInitialCreateDone = null;  // ì´ˆê¸° ë…¸ë“œ ìƒì„± ì™„ë£Œ ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬
    this.nodeUpdateTopic = process.env.KAFKA_TOPIC_NODE_UPDATE || 'mindmap.node.update';
    this.aiSuggestionTopic = process.env.KAFKA_TOPIC_AI_SUGGESTION || 'mindmap.ai.suggestion';
    this.onAiSuggestion = null;
  }

  /**
   * ì´ˆê¸° ë…¸ë“œ ìƒì„± ì™„ë£Œ ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ë“±ë¡
   * @param {function} handler - workspaceIdë¥¼ ë°›ëŠ” ì½œë°± í•¨ìˆ˜
   */
  setInitialCreateDoneHandler(handler) {
    this.onInitialCreateDone = handler;
    logger.info('Initial create done handler registered');
  }

  setAiSuggestionHandler(handler) {
      this.onAiSuggestion = handler;
      logger.info('AI suggestion handler registered');
  }

  /**
   * Kafka Consumer ì´ˆê¸°í™” ë° ì—°ê²°
   * í™˜ê²½ë³€ìˆ˜ KAFKA_BROKERSê°€ ì„¤ì •ë˜ì–´ ìˆìœ¼ë©´ ì‹¤ì œ Kafkaì— ì—°ê²°
   * ì—†ìœ¼ë©´ ë¹„í™œì„±í™” (stub mode)
   */
  async initialize() {
    try {
      const brokers = process.env.KAFKA_BROKERS;  // ì˜ˆ: "localhost:9092,localhost:9093"

      // Kafka ë¸Œë¡œì»¤ ì£¼ì†Œê°€ ì—†ìœ¼ë©´ ë¹„í™œì„±í™”
      if (!brokers) {
        logger.warn('KAFKA_BROKERS not set. Kafka consumer disabled');
        this.isEnabled = false;
        return;
      }

      // Kafka í´ë¼ì´ì–¸íŠ¸ ìƒì„±
      this.kafka = new Kafka({
        clientId: process.env.KAFKA_CLIENT_ID || 'mindmap-websocket-service',  // í´ë¼ì´ì–¸íŠ¸ ì‹ë³„ì
        brokers: brokers.split(','),  // ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ë¸Œë¡œì»¤ ì£¼ì†Œ ë°°ì—´ë¡œ ë³€í™˜
      });

      // Consumer ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
      this.consumer = this.kafka.consumer({
        groupId: process.env.KAFKA_CONSUMER_GROUP || 'mindmap-websocket-consumer',
      });

      // Kafka ë¸Œë¡œì»¤ì— ì—°ê²° ì‹œë„
      await this.consumer.connect();
      this.isConnected = true;
      this.isEnabled = true;

      await this.consumer.subscribe({
          topic: this.nodeUpdateTopic,
          fromBeginning: false,
      });

      await this.consumer.subscribe({
          topic: this.aiSuggestionTopic,
          fromBeginning: false,
      });


      logger.info(`Kafka consumer subscribed to topics: [${this.nodeUpdateTopic}, ${this.aiSuggestionTopic}]`, { brokers });
    } catch (error) {
      // ì—°ê²° ì‹¤íŒ¨ ì‹œ ë¹„í™œì„±í™” (ì„œë¹„ìŠ¤ ì¤‘ë‹¨ ë°©ì§€)
      logger.error('Failed to initialize Kafka consumer', {
        error: error.message,
        stack: error.stack,
      });
      this.isEnabled = false;
    }
  }

  /**
   * Consumer ì‹œì‘: ë©”ì‹œì§€ ìˆ˜ì‹  ëŒ€ê¸°
   * ë©”ì‹œì§€ê°€ ë„ì°©í•˜ë©´ eachMessage ì½œë°± ì‹¤í–‰
   */
  async start() {
      if (!this.consumer || !this.isConnected) {
          logger.debug('Kafka consumer not enabled, skipping start');
          return;
      }

      try {
          await this.consumer.run({
              eachMessage: async ({ topic, partition, message }) => {
                  try {
                      const data = JSON.parse(message.value.toString());

                      logger.debug('Received Kafka message', {
                          topic,
                          partition,
                          offset: message.offset,
                          key: message.key?.toString(),
                      });

                      // ğŸ”¸ í† í”½ì— ë”°ë¼ ì²˜ë¦¬ ë¶„ê¸°
                      if (topic === this.nodeUpdateTopic) {
                          this.handleNodeUpdate(data);
                      } else if (topic === this.aiSuggestionTopic) {
                          this.handleAiSuggestion(data);
                      } else {
                          logger.warn('Received message from unknown topic', { topic, data });
                      }
                  } catch (error) {
                      logger.error('Failed to process Kafka message', {
                          error: error.message,
                          messageValue: message.value?.toString(),
                      });
                  }
              },
          });

          logger.info('Kafka consumer started and listening for messages');
      } catch (error) {
          logger.error('Failed to start Kafka consumer', {
              error: error.message,
          });
      }
  }


  /**
   * Springì´ ë³´ë‚¸ ë…¸ë“œ ì—…ë°ì´íŠ¸ë¥¼ ì²˜ë¦¬
   *
   * ë©”ì‹œì§€ í˜•ì‹ ì˜ˆì‹œ (ê¸°ì¡´ ë°©ì‹ - nodeId, updates í¬í•¨):
   * {
   *   workspaceId: 123,
   *   nodeId: 'n5',
   *   updates: {
   *     aiSummary: 'ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼: íšŒì˜ì‹¤ ì‚¬ì§„...',
   *     analysisStatus: 'DONE',
   *     contentType: 'image',
   *     updatedAt: '2025-11-06T12:00:00Z'
   *   }
   * }
   *
   * ë©”ì‹œì§€ í˜•ì‹ ì˜ˆì‹œ (ì´ˆê¸° ë…¸ë“œ ìƒì„± ì™„ë£Œ):
   * {
   *   message: 'ë…¸ë“œ ë¶„ì„ í›„ ì—…ë°ì´íŠ¸ë¥¼ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤.',
   *   workspaceId: 197
   * }
   *
   * ë©”ì‹œì§€ í˜•ì‹ ì˜ˆì‹œ (ì•„ì´ë””ì–´ ì¶”ê°€ë¡œ ë…¸ë“œ ìƒì„±):
   * {
   *   message: 'ìƒˆë¡œìš´ ë…¸ë“œê°€ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.',
   *   workspaceId: 123,
   *   nodes: [
   *     { nodeId: 10, parentId: 3, keyword: 'ë§›ì§‘ ê²€ìƒ‰', memo: '...', type: 'text', color: '#FFE5E5', x: null, y: null },
   *     { nodeId: 11, parentId: 3, keyword: 'ë¦¬ë·° ì‹œìŠ¤í…œ', memo: '...', type: 'text', color: '#E5F5FF', x: null, y: null }
   *   ],
   *   nodeCount: 2
   * }
   *
   * @param {object} data - Kafka ë©”ì‹œì§€ ë°ì´í„°
   */
  handleNodeUpdate(data) {
    const { workspaceId, nodeId, updates, message, nodes, nodeCount } = data;

    // í•„ìˆ˜ í•„ë“œ ê²€ì¦: workspaceIdëŠ” í•­ìƒ í•„ìš”
    if (!workspaceId) {
      logger.warn('Invalid node update message: missing workspaceId', { data });
      return;
    }

    // ì•„ì´ë””ì–´ ì¶”ê°€ë¡œ ë…¸ë“œê°€ ìƒì„±ëœ ê²½ìš° (nodes ë°°ì—´ í¬í•¨)
    if (message && nodes && Array.isArray(nodes)) {
      logger.info(`Received nodes created message from Kafka`, {
        workspaceId,
        message,
        nodeCount,
        nodeKeywords: nodes.map(n => n.keyword),
      });

      // ë“±ë¡ëœ í•¸ë“¤ëŸ¬ í˜¸ì¶œ (ìƒì„±ëœ ë…¸ë“œ ì „ì²´ ì •ë³´ í¬í•¨)
      if (this.onInitialCreateDone) {
        this.onInitialCreateDone(workspaceId, nodes);
      } else {
        logger.warn('No initial create done handler registered');
      }
      return;
    }

    // ì´ˆê¸° ë…¸ë“œ ìƒì„± ì™„ë£Œ ë©”ì‹œì§€ ì²˜ë¦¬ (message í•„ë“œê°€ ìˆê³  nodeIdê°€ ì—†ëŠ” ê²½ìš°)
    if (message && !nodeId) {
      logger.info(`Received initial create done message from Kafka`, {
        workspaceId,
        message,
      });

      // ë“±ë¡ëœ í•¸ë“¤ëŸ¬ í˜¸ì¶œ
      if (this.onInitialCreateDone) {
        this.onInitialCreateDone(workspaceId);
      } else {
        logger.warn('No initial create done handler registered');
      }
      return;
    }

    // ê¸°ì¡´ ë…¸ë“œ ì—…ë°ì´íŠ¸ ë¡œì§ (nodeIdì™€ updatesê°€ ìˆëŠ” ê²½ìš°)
    if (!nodeId || !updates) {
      logger.warn('Invalid node update message: missing nodeId or updates', { data });
      return;
    }

    logger.info(`Received node update from Kafka`, {
      workspaceId,
      nodeId,
      updateFields: Object.keys(updates),
    });

    // Y.Doc ê°€ì ¸ì˜¤ê¸° (ì´ë¯¸ ë©”ëª¨ë¦¬ì— ìˆëŠ” ê²½ìš°ë§Œ)
    const ydoc = ydocManager.docs.get(workspaceId.toString());

    if (!ydoc) {
      logger.debug(`Workspace ${workspaceId} not in memory, skipping update`);
      // í•´ë‹¹ ì›Œí¬ìŠ¤í˜ì´ìŠ¤ì— ì ‘ì†í•œ í´ë¼ì´ì–¸íŠ¸ê°€ ì—†ìœ¼ë©´ ì—…ë°ì´íŠ¸ ë¶ˆí•„ìš”
      // ë‹¤ìŒì— í´ë¼ì´ì–¸íŠ¸ê°€ ì ‘ì†í•˜ë©´ HTTPë¡œ ìµœì‹  ë°ì´í„°ë¥¼ ë°›ì•„ì˜´
      return;
    }

    try {
      // Y.Doc ì—…ë°ì´íŠ¸ â†’ ëª¨ë“  ì—°ê²°ëœ í´ë¼ì´ì–¸íŠ¸ì—ê²Œ ìë™ ì „íŒŒ
      const nodesMap = ydoc.getMap('nodes');
      const currentNode = nodesMap.get(nodeId.toString());

      if (currentNode) {
        // ê¸°ì¡´ ë…¸ë“œ ë°ì´í„°ì™€ ì—…ë°ì´íŠ¸ ë³‘í•©
        nodesMap.set(nodeId.toString(), {
          ...currentNode,
          ...updates
        });

        logger.info(`Successfully updated node ${nodeId} in workspace ${workspaceId}`, {
          updatedFields: Object.keys(updates),
        });
      } else {
        logger.warn(`Node ${nodeId} not found in Y.Doc for workspace ${workspaceId}`);
        // ë…¸ë“œê°€ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±í•  ìˆ˜ë„ ìˆì§€ë§Œ, ì¼ë‹¨ ê²½ê³ ë§Œ ì¶œë ¥
        // í´ë¼ì´ì–¸íŠ¸ê°€ ë‹¤ì‹œ ì ‘ì†í•˜ë©´ HTTPë¡œ ì „ì²´ ë°ì´í„°ë¥¼ ë°›ì•„ì˜´
      }
    } catch (error) {
      logger.error(`Failed to update Y.Doc for workspace ${workspaceId}`, {
        error: error.message,
        nodeId,
      });
    }
  }

  handleAiSuggestion(data) {
      if (this.onAiSuggestion) {
          this.onAiSuggestion(data);
      } else {
          logger.warn('AI suggestion received but no handler registered', { data });
      }
  }

  /**
   * Kafka consumer ì—°ê²° ì¢…ë£Œ (graceful shutdown)
   * ì„œë²„ ì¢…ë£Œ ì‹œ í˜¸ì¶œë˜ì–´ ì•ˆì „í•˜ê²Œ ì—°ê²°ì„ ëŠìŒ
   */
  async disconnect() {
    if (this.consumer && this.isConnected) {
      try {
        await this.consumer.disconnect();
        this.isConnected = false;
        logger.info('Kafka consumer disconnected');
      } catch (error) {
        logger.error('Failed to disconnect Kafka consumer', {
          error: error.message,
        });
      }
    }
  }

  /**
   * Kafka Consumer ìƒíƒœ ì •ë³´ ë°˜í™˜
   * /health, /stats ì—”ë“œí¬ì¸íŠ¸ì—ì„œ ì‚¬ìš©
   */
  getStatus() {
    return {
      enabled: this.isEnabled,          // Kafka ì‚¬ìš© ì—¬ë¶€
      connected: this.isConnected,      // ì—°ê²° ìƒíƒœ
      topic: process.env.KAFKA_TOPIC_NODE_UPDATE || 'mindmap.node.update',
      consumerGroup: process.env.KAFKA_CONSUMER_GROUP || 'mindmap-websocket-consumer',
    };
  }
}

// Export singleton instance
export const kafkaConsumer = new KafkaConsumerService();
