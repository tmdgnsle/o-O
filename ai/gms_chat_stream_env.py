# filename: gms_chat_stream_env_check.py
import os
import json
import time
import requests
from dotenv import load_dotenv

# 1) .env ë¡œë“œ
load_dotenv()
GMS_KEY = os.getenv("GMS_KEY")
if not GMS_KEY:
    print("âŒ .envì— GMS_KEYê°€ ì—†ìŠµë‹ˆë‹¤. (ì˜ˆ: GMS_KEY=xxxxx)")
    exit(1)

API_URL = "https://gms.ssafy.io/gmsapi/api.openai.com/v1/chat/completions"
HEADERS = {
    "Authorization": f"Bearer {GMS_KEY}",
    "Content-Type": "application/json",
}

messages = [
    {"role": "developer", "content": "Answer in Korean"}
]


def warn_if_not_streaming(resp_headers, first_event_latency_s, event_count, char_count):
    """ìŠ¤íŠ¸ë¦¬ë°ì´ ì•„ë‹ ê°€ëŠ¥ì„±ì„ ì—¬ëŸ¬ ê¸°ì¤€ìœ¼ë¡œ íŒë‹¨í•´ ê²½ê³  ì¶œë ¥"""
    # ê¸°ì¤€ 1: Content-Type
    ct = resp_headers.get("Content-Type", "")
    is_sse = "text/event-stream" in ct

    # ê¸°ì¤€ 2: ì²« í† í° ë„ì°©ê¹Œì§€ ì§€ì—°
    long_first_latency = first_event_latency_s is None or first_event_latency_s > 1.5

    # ê¸°ì¤€ 3: ì´ë²¤íŠ¸ ê°œìˆ˜
    few_events = event_count <= 1

    # ê¸°ì¤€ 4: ê¸€ì ìˆ˜ ëŒ€ë¹„ ì´ë²¤íŠ¸ ìˆ˜ (ë„ˆë¬´ ê¸¸ë©´ ì›ìƒ·ì¼ ê°€ëŠ¥ì„±)
    suspicious_bulk = char_count > 200 and event_count < 3

    if not is_sse or (long_first_latency and (few_events or suspicious_bulk)):
        print("\nâš ï¸ ìŠ¤íŠ¸ë¦¬ë°ì´ ë¹„í™œì„± ìƒíƒœì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        print(f"   - Content-Type: {ct or 'N/A'}")
        if first_event_latency_s is not None:
            print(f"   - ì²« ì´ë²¤íŠ¸ ëŒ€ê¸° ì‹œê°„: {first_event_latency_s:.2f}s")
        else:
            print("   - ì²« ì´ë²¤íŠ¸ ëŒ€ê¸° ì‹œê°„: ì´ë²¤íŠ¸ ë¯¸ìˆ˜ì‹ ")
        print(f"   - ì´ë²¤íŠ¸ ìˆ˜: {event_count}")
        print(f"   - ìˆ˜ì‹  ê¸€ì ìˆ˜: {char_count}")
        print("   - ì›ì¸ ì¶”ì •: í”„ë¡ì‹œê°€ SSEë¥¼ ë³‘í•©í•˜ê±°ë‚˜ ë²„í¼ë§í–ˆì„ ìˆ˜ ìˆìŒ(GMS/ë„¤íŠ¸ì›Œí¬ í™˜ê²½ í™•ì¸).")


print("ğŸš€ GMS Chat Stream ì‹œì‘ (Ctrl+Cë¡œ ì¢…ë£Œ)\n")

while True:
    try:
        user_input = input("ğŸ§‘â€ğŸ’» ì§ˆë¬¸ > ").strip()
        if not user_input:
            continue

        messages.append({"role": "user", "content": user_input})

        payload = {
            "model": "gpt-5-nano",
            "stream": True,
            "messages": messages
        }

        print("ğŸ¤– ë‹µë³€ > ", end="", flush=True)

        t0 = time.time()
        first_event_latency = None
        event_count = 0
        char_count = 0
        full_reply = ""

        with requests.post(API_URL, headers=HEADERS, json=payload, stream=True, timeout=300) as resp:
            # HTTP ì—ëŸ¬ ì¦‰ì‹œ í‘œì‹œ
            if resp.status_code != 200:
                print(f"\nâŒ ì˜¤ë¥˜ {resp.status_code}: {resp.text}")
                continue

            # ìŠ¤íŠ¸ë¦¼ ìˆ˜ì‹  ë£¨í”„
            for line in resp.iter_lines(decode_unicode=True):
                if not line or not line.startswith("data:"):
                    continue

                data = line[len("data:"):].strip()
                if data == "[DONE]":
                    break

                if first_event_latency is None:
                    first_event_latency = time.time() - t0

                try:
                    chunk = json.loads(data)
                    delta = chunk["choices"][0]["delta"]
                    piece = delta.get("content")
                    if piece:
                        print(piece, end="", flush=True)
                        full_reply += piece
                        char_count += len(piece)
                        event_count += 1
                except Exception:
                    # íŒŒì‹± ì‹¤íŒ¨ì‹œ ë¬´ì‹œ (ê°„í—ì  ê°œí–‰/í”„ë¡ì‹œ ì´ìŠˆ ëŒ€ë¹„)
                    continue

        print("\n")
        # ìŠ¤íŠ¸ë¦¬ë° ìƒíƒœ ìë™ ì§„ë‹¨
        warn_if_not_streaming(
            resp.headers, first_event_latency, event_count, char_count)

        # ëŒ€í™” ë§¥ë½ ìœ ì§€
        if full_reply:
            messages.append({"role": "assistant", "content": full_reply})

    except KeyboardInterrupt:
        print("\nğŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        break
    except Exception as e:
        print(f"\nâš ï¸ ì˜ˆì™¸ ë°œìƒ: {e}")
