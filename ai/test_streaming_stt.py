#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° STT (Speech-to-Text)
ë§í•˜ë©´ì„œ ë°”ë¡œë°”ë¡œ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
"""
import os
os.environ['PYTHONIOENCODING'] = 'utf-8'

import sys
import io

# Windowsì—ì„œ UTF-8 ê°•ì œ ì„¤ì •
if sys.platform == 'win32':
    try:
        sys.stdout.reconfigure(encoding='utf-8')
        sys.stderr.reconfigure(encoding='utf-8')
    except:
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
        sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')

import whisper
import sounddevice as sd
import numpy as np
import queue
import threading
from datetime import datetime


class StreamingSTT:
    """ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ìŒì„± ì¸ì‹"""

    def __init__(self, model_name="base", language="ko", chunk_duration=2):
        """
        Args:
            model_name: whisper ëª¨ë¸ (tiny ì¶”ì²œ - ê°€ì¥ ë¹ ë¦„)
            language: ì–¸ì–´ ì½”ë“œ (ko, en, ja, etc.)
            chunk_duration: ìŒì„± ì²­í¬ ê¸¸ì´ (ì´ˆ) - ì§§ì„ìˆ˜ë¡ ë¹ ë¥´ì§€ë§Œ ì •í™•ë„ í•˜ë½
        """
        print(f"ğŸ”„ Whisper ëª¨ë¸ ë¡œë”© ì¤‘... (ëª¨ë¸: {model_name})")
        self.model = whisper.load_model(model_name)
        self.language = language
        self.chunk_duration = chunk_duration
        self.sample_rate = 16000
        self.audio_queue = queue.Queue()
        self.is_running = False

        print(f"âœ… Whisper ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")
        print(f"ğŸ“Š ì²­í¬ ê¸¸ì´: {chunk_duration}ì´ˆ")
        print(f"ğŸ“Š ìƒ˜í”Œë ˆì´íŠ¸: {self.sample_rate}Hz")

    def audio_callback(self, indata, frames, time, status):
        """ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì½œë°±"""
        if status:
            print(f"âš ï¸  ì˜¤ë””ì˜¤ ìƒíƒœ: {status}", file=sys.stderr)

        # ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ íì— ì¶”ê°€
        self.audio_queue.put(indata.copy())

    def process_audio_stream(self):
        """ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ì²˜ë¦¬"""
        buffer = []
        chunk_samples = int(self.chunk_duration * self.sample_rate)

        print("\nğŸ’¬ ì‹¤ì‹œê°„ STT ì‹œì‘! (Ctrl+Cë¡œ ì¢…ë£Œ)")
        print("â”€" * 60)

        while self.is_running:
            try:
                # íì—ì„œ ì˜¤ë””ì˜¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                data = self.audio_queue.get(timeout=0.1)
                buffer.extend(data.flatten())

                # ë²„í¼ê°€ ì²­í¬ í¬ê¸°ì— ë„ë‹¬í•˜ë©´ ì²˜ë¦¬
                if len(buffer) >= chunk_samples:
                    audio_chunk = np.array(buffer[:chunk_samples], dtype=np.float32)
                    buffer = buffer[chunk_samples:]

                    # ìŒì„± í™œë™ ê°ì§€ (VAD) - ì¡°ìš©í•˜ë©´ ê±´ë„ˆë›°ê¸°
                    if np.abs(audio_chunk).max() < 0.01:
                        continue

                    # Whisperë¡œ ì¸ì‹ (í•œê¸€ ê°•ì œ)
                    try:
                        result = self.model.transcribe(
                            audio_chunk,
                            language=self.language,  # 'ko' ê°•ì œ
                            fp16=False,
                            verbose=False,
                            task='transcribe',
                            no_speech_threshold=0.6,  # ìŒì„± ê°ì§€ ì„ê³„ê°’ ìƒí–¥ (ë…¸ì´ì¦ˆ ê°ì†Œ)
                            compression_ratio_threshold=2.4,  # ì••ì¶•ë¥  ì²´í¬
                            temperature=0.0,  # ì˜¨ë„ 0ìœ¼ë¡œ ì„¤ì • (ê°€ì¥ í™•ì‹¤í•œ ê²°ê³¼ë§Œ)
                            beam_size=5,  # ë¹” ì„œì¹˜ í¬ê¸°
                            best_of=5,  # ìµœìƒì˜ ê²°ê³¼ ì„ íƒ
                        )

                        text = result['text'].strip()

                        # í•„í„°ë§: initial_promptì™€ ê°™ê±°ë‚˜ ë„ˆë¬´ ì§§ìœ¼ë©´ ë¬´ì‹œ
                        if text and text != "í•œêµ­ì–´ë¡œ ë§í•˜ê³  ìˆìŠµë‹ˆë‹¤." and len(text) > 1:
                            # í•œê¸€ ë¹„ìœ¨ ì²´í¬ (ìµœì†Œ 50% ì´ìƒ í•œê¸€ì´ì–´ì•¼ í•¨)
                            korean_chars = sum(1 for c in text if 'ê°€' <= c <= 'í£')
                            korean_ratio = korean_chars / len(text.replace(' ', ''))

                            if korean_ratio >= 0.3:  # 30% ì´ìƒ í•œê¸€
                                timestamp = datetime.now().strftime("%H:%M:%S")
                                confidence = result.get('language_probability', 0)
                                print(f"[{timestamp}] {text} (ì‹ ë¢°ë„: {confidence:.2f})")
                                sys.stdout.flush()
                            else:
                                print(f"âš ï¸  í•œê¸€ ë¹„ìœ¨ ë‚®ìŒ ({korean_ratio:.1%}): {text}", file=sys.stderr)

                    except Exception as e:
                        print(f"âš ï¸  ì¸ì‹ ì˜¤ë¥˜: {e}", file=sys.stderr)
                        continue

            except queue.Empty:
                continue
            except KeyboardInterrupt:
                print("\nâš ï¸  Ctrl+C ê°ì§€ë¨, ì¢…ë£Œ ì¤‘...")
                self.is_running = False
                break

    def start_streaming(self):
        """ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘"""
        self.is_running = True

        # í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ ë§ˆì´í¬ ì •ë³´ ì¶œë ¥
        try:
            current_device = sd.query_devices(kind='input')
            print(f"\nğŸ¤ ì‚¬ìš© ì¤‘ì¸ ë§ˆì´í¬:")
            print(f"   ì´ë¦„: {current_device['name']}")
            print(f"   ì±„ë„: {current_device['max_input_channels']}")
            print(f"   ìƒ˜í”Œë ˆì´íŠ¸: {current_device['default_samplerate']} Hz")
            print(f"   ì¥ì¹˜ ì¸ë±ìŠ¤: {current_device['index']}")
        except Exception as e:
            print(f"\nâš ï¸  ë§ˆì´í¬ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")

        # ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ ìŠ¤ë ˆë“œ ì‹œì‘
        process_thread = threading.Thread(target=self.process_audio_stream)
        process_thread.daemon = True
        process_thread.start()

        # ë§ˆì´í¬ ì…ë ¥ ìŠ¤íŠ¸ë¦¼ ì‹œì‘
        try:
            with sd.InputStream(
                samplerate=self.sample_rate,
                channels=1,
                dtype='float32',
                callback=self.audio_callback,
                blocksize=int(self.sample_rate * 0.1)  # 100ms ë¸”ë¡
            ):
                print("\nâœ… ë§ˆì´í¬ ì¤€ë¹„ ì™„ë£Œ! ë…¹ìŒ ì‹œì‘...")
                print("   (Ctrl+Cë¥¼ ëˆŒëŸ¬ ì¢…ë£Œí•˜ì„¸ìš”)\n")

                # KeyboardInterruptë¥¼ ì œëŒ€ë¡œ ë°›ê¸° ìœ„í•´ ë©”ì¸ ìŠ¤ë ˆë“œì—ì„œ ëŒ€ê¸°
                try:
                    while self.is_running:
                        process_thread.join(timeout=0.1)
                        if not process_thread.is_alive():
                            break
                except KeyboardInterrupt:
                    print("\n\nâš ï¸  ì‚¬ìš©ìê°€ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤. ì¢…ë£Œ ì¤‘...")
                    self.is_running = False

        except KeyboardInterrupt:
            print("\n\nâš ï¸  ì¢…ë£Œ ì¤‘...")
            self.is_running = False
        except Exception as e:
            print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
            self.is_running = False
        finally:
            self.is_running = False
            if process_thread.is_alive():
                process_thread.join(timeout=1.0)

    def stop(self):
        """ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì§€"""
        self.is_running = False


def test_streaming_stt(model="tiny", chunk_duration=2):
    """
    ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° STT í…ŒìŠ¤íŠ¸

    Args:
        model: whisper ëª¨ë¸ (tiny ì¶”ì²œ - ì‹¤ì‹œê°„ìš©)
        chunk_duration: ìŒì„± ì²­í¬ ê¸¸ì´ (ì´ˆ)
                       - ì§§ì„ìˆ˜ë¡: ë¹ ë¥¸ ì‘ë‹µ, ë‚®ì€ ì •í™•ë„
                       - ê¸¸ìˆ˜ë¡: ëŠë¦° ì‘ë‹µ, ë†’ì€ ì •í™•ë„
                       - ì¶”ì²œ: 1-3ì´ˆ
    """
    print("\n" + "="*60)
    print("ğŸ¯ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° STT")
    print("="*60)
    print(f"ëª¨ë¸: {model}")
    print(f"ì²­í¬: {chunk_duration}ì´ˆ")
    print(f"ì–¸ì–´: í•œêµ­ì–´")
    print("\nğŸ’¡ TIP:")
    print("  - ë” ë¹ ë¥¸ ì‘ë‹µ: --chunk 1 --model tiny")
    print("  - ë” ë†’ì€ ì •í™•ë„: --chunk 3 --model base")
    print("="*60)

    stt = StreamingSTT(
        model_name=model,
        language="ko",
        chunk_duration=chunk_duration
    )

    try:
        stt.start_streaming()
    except KeyboardInterrupt:
        print("\n\nâœ… ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")


def test_mic_devices():
    """ë§ˆì´í¬ ì¥ì¹˜ í…ŒìŠ¤íŠ¸"""
    print("\n" + "="*60)
    print("ğŸ¤ ì˜¤ë””ì˜¤ ì¥ì¹˜ ëª©ë¡")
    print("="*60)

    devices = sd.query_devices()
    print("\nì‚¬ìš© ê°€ëŠ¥í•œ ì…ë ¥ ì¥ì¹˜:")
    print("-" * 60)

    has_input = False
    for i, device in enumerate(devices):
        if device['max_input_channels'] > 0:
            has_input = True
            is_default = "(ê¸°ë³¸)" if i == sd.default.device[0] else ""
            print(f"[{i}] {device['name']} {is_default}")
            print(f"    ì±„ë„: {device['max_input_channels']}")
            print(f"    ìƒ˜í”Œë ˆì´íŠ¸: {device['default_samplerate']} Hz")
            print()

    if not has_input:
        print("âŒ ì…ë ¥ ì¥ì¹˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
        print("ğŸ’¡ GPU ì„œë²„ì—ëŠ” ë§ˆì´í¬ê°€ ì—†ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    else:
        default_input = sd.query_devices(kind='input')
        print(f"âœ… ê¸°ë³¸ ì…ë ¥ ì¥ì¹˜: {default_input['name']}")


def test_audio_input(duration=3):
    """ì˜¤ë””ì˜¤ ì…ë ¥ í…ŒìŠ¤íŠ¸ (ë…¹ìŒ ë ˆë²¨ í™•ì¸)"""
    print("\n" + "="*60)
    print("ğŸ¤ ì˜¤ë””ì˜¤ ì…ë ¥ í…ŒìŠ¤íŠ¸")
    print("="*60)
    print(f"\n{duration}ì´ˆ ë™ì•ˆ ë§ì”€í•´ë³´ì„¸ìš”...")
    print("(ìŒì„± ë ˆë²¨ì„ í‘œì‹œí•©ë‹ˆë‹¤)")
    print("-" * 60)

    sample_rate = 16000

    try:
        recording = sd.rec(
            int(duration * sample_rate),
            samplerate=sample_rate,
            channels=1,
            dtype='float32'
        )

        # ì‹¤ì‹œê°„ ë ˆë²¨ ëª¨ë‹ˆí„°ë§
        import time
        start_time = time.time()
        while time.time() - start_time < duration:
            time.sleep(0.1)
            current_frame = int((time.time() - start_time) * sample_rate)
            if current_frame < len(recording):
                level = np.abs(recording[max(0, current_frame-1600):current_frame]).max()
                bar_length = int(level * 50)
                bar = "â–ˆ" * bar_length
                print(f"\rğŸ”Š {bar:<50} {level:.3f}", end="", flush=True)

        sd.wait()
        print("\n\nâœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")

        max_level = np.abs(recording).max()
        avg_level = np.abs(recording).mean()

        print(f"\nğŸ“Š í†µê³„:")
        print(f"  ìµœëŒ€ ë ˆë²¨: {max_level:.3f}")
        print(f"  í‰ê·  ë ˆë²¨: {avg_level:.3f}")

        if max_level < 0.01:
            print("\nâš ï¸  ìŒì„± ë ˆë²¨ì´ ë„ˆë¬´ ë‚®ìŠµë‹ˆë‹¤!")
            print("ğŸ’¡ ë§ˆì´í¬ ë³¼ë¥¨ì„ í™•ì¸í•˜ê±°ë‚˜ ë” í¬ê²Œ ë§ì”€í•´ë³´ì„¸ìš”.")
        else:
            print("\nâœ… ìŒì„± ì…ë ¥ì´ ì •ìƒì…ë‹ˆë‹¤!")

    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜: {e}")


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° STT")
    parser.add_argument(
        "--mode",
        choices=["stream", "devices", "test"],
        default="stream",
        help="ëª¨ë“œ ì„ íƒ (stream: ìŠ¤íŠ¸ë¦¬ë°, devices: ì¥ì¹˜ í™•ì¸, test: ì…ë ¥ í…ŒìŠ¤íŠ¸)"
    )
    parser.add_argument(
        "--model",
        choices=["tiny", "base", "small"],
        default="tiny",
        help="Whisper ëª¨ë¸ (ì‹¤ì‹œê°„ìš©ì€ tiny ì¶”ì²œ)"
    )
    parser.add_argument(
        "--chunk",
        type=float,
        default=2.0,
        help="ìŒì„± ì²­í¬ ê¸¸ì´ (ì´ˆ) - 1~3 ì¶”ì²œ"
    )
    parser.add_argument(
        "--duration",
        type=int,
        default=3,
        help="ì…ë ¥ í…ŒìŠ¤íŠ¸ ì‹œê°„ (ì´ˆ)"
    )

    args = parser.parse_args()

    try:
        if args.mode == "devices":
            # ì¥ì¹˜ ëª©ë¡ í™•ì¸
            test_mic_devices()

        elif args.mode == "test":
            # ì˜¤ë””ì˜¤ ì…ë ¥ í…ŒìŠ¤íŠ¸
            test_audio_input(duration=args.duration)

        elif args.mode == "stream":
            # ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° STT
            test_streaming_stt(
                model=args.model,
                chunk_duration=args.chunk
            )

    except KeyboardInterrupt:
        print("\n\nâš ï¸  ì‚¬ìš©ìê°€ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
