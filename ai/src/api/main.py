"""
FastAPI ê¸°ë°˜ YouTube ì˜ìƒ ë¶„ì„ API
- ë¹„ë™ê¸° ì˜ìƒ ë¶„ì„ ì²˜ë¦¬
- ì‘ì—… ìƒíƒœ ì¡°íšŒ
- ê²°ê³¼ ì¡°íšŒ
"""
from fastapi import FastAPI, HTTPException
from fastapi.responses import StreamingResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, HttpUrl
from typing import Optional, Dict, List
import uuid
import os
import logging
from datetime import datetime
from enum import Enum
import json
import asyncio

import sys
from pathlib import Path
import re

logger = logging.getLogger(__name__)

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ PYTHONPATHì— ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent.parent.parent))


def remove_repetitive_sentences(text: str, max_repetition: int = 2) -> str:
    """
    ë°˜ë³µë˜ëŠ” ë¬¸ì¥ì„ ì œê±°í•˜ëŠ” í•¨ìˆ˜

    Args:
        text: ì…ë ¥ í…ìŠ¤íŠ¸
        max_repetition: í—ˆìš©í•  ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜

    Returns:
        ë°˜ë³µì´ ì œê±°ëœ í…ìŠ¤íŠ¸
    """
    if not text:
        return text

    # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„ë¦¬ (ë§ˆì¹¨í‘œ, ëŠë‚Œí‘œ, ë¬¼ìŒí‘œ ê¸°ì¤€)
    sentences = re.split(r'([.!?]\s*)', text)

    # ë¶„ë¦¬ëœ ë¬¸ì¥ì„ ë‹¤ì‹œ í•©ì¹˜ê¸° (êµ¬ë¶„ì í¬í•¨)
    combined = []
    for i in range(0, len(sentences), 2):
        if i + 1 < len(sentences):
            combined.append(sentences[i] + sentences[i + 1])
        else:
            combined.append(sentences[i])

    # ì—°ì†ëœ ì¤‘ë³µ ë¬¸ì¥ ì œê±°
    result = []
    prev_sentence = None
    repeat_count = 0

    for sentence in combined:
        sentence = sentence.strip()
        if not sentence:
            continue

        if sentence == prev_sentence:
            repeat_count += 1
            if repeat_count < max_repetition:
                result.append(sentence)
        else:
            result.append(sentence)
            prev_sentence = sentence
            repeat_count = 0

    return ' '.join(result).strip()

from src.core import (
    FrameExtractor,
    TranscriptExtractor,
    LlamaVisionAnalyzer,
    LlamaTextAnalyzer
)
from src.core.image_analyzer import ImageAnalyzer
from src.api.models import (
    TaskStatus,
    AnalyzeRequest,
    ImageAnalyzeRequest,
    TextAnalyzeRequest,
    TaskResponse,
    AnalysisResult,
    ImageAnalysisResult,
    TextAnalysisResult,
    MindMapNode
)
import torch


# ============================================================================
# ì „ì—­ ìƒíƒœ ì €ì¥ì†Œ (ì‹¤ì œ í”„ë¡œë•ì…˜ì—ì„œëŠ” Redis ë“± ì‚¬ìš©)
# ============================================================================

tasks: Dict[str, AnalysisResult] = {}

# ì „ì—­ ëª¨ë¸ ìºì‹œ (ì„œë²„ ì‹œì‘ ì‹œ í•œ ë²ˆë§Œ ë¡œë“œ)
_vision_analyzer: Optional[LlamaVisionAnalyzer] = None
_text_analyzer: Optional[LlamaTextAnalyzer] = None
_models_loaded = False


# ============================================================================
# FastAPI ì•± ì´ˆê¸°í™”
# ============================================================================

app = FastAPI(
    title="YouTube Video Analysis API",
    description="Llama 3.2 Vision + Llama 3.1ì„ ì‚¬ìš©í•œ YouTube ì˜ìƒ ë¶„ì„ API",
    version="1.0.0"
)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# ============================================================================
# ëª¨ë¸ ë¡œë”© í•¨ìˆ˜
# ============================================================================

def load_models(vision_quantization: str = "int4", text_quantization: str = "int4"):
    """
    ì„œë²„ ì‹œì‘ ì‹œ ëª¨ë¸ì„ í•œ ë²ˆë§Œ ë¡œë“œí•©ë‹ˆë‹¤.

    Args:
        vision_quantization: Vision ëª¨ë¸ ì–‘ìí™” ë°©ì‹ (int4/int8/bfloat16)
        text_quantization: Text ëª¨ë¸ ì–‘ìí™” ë°©ì‹ (int4/int8/fp16)
    """
    global _vision_analyzer, _text_analyzer, _models_loaded

    if _models_loaded:
        logger.info("ëª¨ë¸ì´ ì´ë¯¸ ë¡œë“œë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
        return

    logger.info("=== ëª¨ë¸ ë¡œë”© ì‹œì‘ ===")

    # Vision ëª¨ë¸ ë¡œë“œ
    logger.info(f"Vision ëª¨ë¸ ë¡œë”© ì¤‘... (quantization: {vision_quantization})")
    _vision_analyzer = LlamaVisionAnalyzer(quantization=vision_quantization)
    logger.info("âœ… Vision ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")

    # Text ëª¨ë¸ ë¡œë“œ
    logger.info(f"Text ëª¨ë¸ ë¡œë”© ì¤‘... (quantization: {text_quantization})")
    _text_analyzer = LlamaTextAnalyzer(quantization=text_quantization)
    logger.info("âœ… Text ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")

    _models_loaded = True
    logger.info("=== ëª¨ë“  ëª¨ë¸ ë¡œë”© ì™„ë£Œ ===")


def get_vision_analyzer() -> LlamaVisionAnalyzer:
    """Vision ë¶„ì„ê¸° ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    if not _models_loaded or _vision_analyzer is None:
        raise RuntimeError("ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì„œë²„ ì‹œì‘ ì‹œ ëª¨ë¸ì„ ë¡œë“œí•´ì£¼ì„¸ìš”.")
    return _vision_analyzer


def get_text_analyzer() -> LlamaTextAnalyzer:
    """Text ë¶„ì„ê¸° ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    if not _models_loaded or _text_analyzer is None:
        raise RuntimeError("ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì„œë²„ ì‹œì‘ ì‹œ ëª¨ë¸ì„ ë¡œë“œí•´ì£¼ì„¸ìš”.")
    return _text_analyzer


def create_fallback_mindmap(
    video_title: str,
    frame_analyses: List[str],
    transcript: str
) -> MindMapNode:
    """
    LLM ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ë§ˆì¸ë“œë§µ ìƒì„± (í´ë°±)

    Args:
        video_title: ì˜ìƒ ì œëª©
        frame_analyses: í”„ë ˆì„ ë¶„ì„ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        transcript: ì˜ìƒ ìë§‰

    Returns:
        ê¸°ë³¸ ë§ˆì¸ë“œë§µ ë£¨íŠ¸ ë…¸ë“œ
    """
    # ë£¨íŠ¸ ë…¸ë“œ
    root = MindMapNode(
        keyword=video_title,
        description="ì˜ìƒ ë¶„ì„ ê²°ê³¼",
        children=[]
    )

    # ìë§‰ ë…¸ë“œ
    if transcript and transcript != "[ìë§‰ ì—†ìŒ]":
        transcript_node = MindMapNode(
            keyword="ìŒì„±/ìë§‰ ë‚´ìš©",
            description=transcript[:500] + "..." if len(transcript) > 500 else transcript,
            children=None
        )
        root.children.append(transcript_node)

    # í”„ë ˆì„ ë¶„ì„ ë…¸ë“œ
    frame_children = []
    for i, analysis in enumerate(frame_analyses):
        frame_node = MindMapNode(
            keyword=f"í”„ë ˆì„ {i+1}",
            description=analysis,
            children=None
        )
        frame_children.append(frame_node)

    if frame_children:
        frames_parent = MindMapNode(
            keyword="ì‹œê° ë¶„ì„",
            description=f"ì´ {len(frame_children)}ê°œ í”„ë ˆì„ ë¶„ì„",
            children=frame_children
        )
        root.children.append(frames_parent)

    return root


def create_mindmap_from_image_llm(
    image_url: str,
    image_analysis: str,
    user_query: Optional[str] = None
) -> MindMapNode:
    """
    ì´ë¯¸ì§€ ë¶„ì„ìœ¼ë¡œë¶€í„° LLMì„ ì‚¬ìš©í•˜ì—¬ ë§ˆì¸ë“œë§µ ìƒì„±

    Args:
        image_url: ì´ë¯¸ì§€ URL
        image_analysis: Vision ëª¨ë¸ì˜ ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼
        user_query: ì‚¬ìš©ì ì§ˆë¬¸/í”„ë¡¬í”„íŠ¸

    Returns:
        ë§ˆì¸ë“œë§µ ë£¨íŠ¸ ë…¸ë“œ
    """
    try:
        text_analyzer = get_text_analyzer()

        # ì´ë¯¸ì§€ ë¶„ì„ ê¸°ë°˜ ë§ˆì¸ë“œë§µ ìƒì„± í”„ë¡¬í”„íŠ¸
        if user_query:
            system_prompt = f"""ë‹¹ì‹ ì€ ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ë¥¼ êµ¬ì¡°í™”ëœ ë§ˆì¸ë“œë§µìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì‚¬ìš©ì ì§ˆë¬¸: {user_query}

ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ì ì§ˆë¬¸ì— ì´ˆì ì„ ë§ì¶˜ ë§ˆì¸ë“œë§µì„ ìƒì„±í•˜ì„¸ìš”.
ë§ˆì¸ë“œë§µì€ ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤:

{{
  "keyword": "ì‚¬ìš©ì ì§ˆë¬¸ì˜ í•µì‹¬ ì£¼ì œ",
  "description": "{image_url}",
  "children": [
    {{
      "keyword": "ì£¼ìš” ì¹´í…Œê³ ë¦¬ 1",
      "description": "êµ¬ì²´ì ì¸ ì‚¬ì‹¤, ìˆ«ì, íŠ¹ì§•",
      "children": [
        {{
          "keyword": "ì„¸ë¶€ í•­ëª©",
          "description": "ìƒì„¸ ì„¤ëª…",
          "children": null
        }}
      ]
    }}
  ]
}}

**ì¤‘ìš” ê·œì¹™:**
1. ë°˜ë“œì‹œ "keyword", "description", "children" í‚¤ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”
2. keywordë¥¼ JSON í‚¤ë¡œ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”
3. descriptionì—ëŠ” êµ¬ì²´ì ì¸ ì‚¬ì‹¤, ìˆ«ì, íŠ¹ì§•ì„ í¬í•¨í•˜ì„¸ìš”
4. ì´ë¯¸ì§€ì—ì„œ ê´€ì°°ëœ êµ¬ì²´ì ì¸ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”
5. JSONë§Œ ì¶œë ¥í•˜ê³ , ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡(```)ì€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”
"""
        else:
            system_prompt = f"""ë‹¹ì‹ ì€ ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ë¥¼ êµ¬ì¡°í™”ëœ ë§ˆì¸ë“œë§µìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ í¬ê´„ì ì¸ ë§ˆì¸ë“œë§µì„ ìƒì„±í•˜ì„¸ìš”.
ë§ˆì¸ë“œë§µì€ ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤:

{{
  "keyword": "ì´ë¯¸ì§€ ì£¼ìš” ì£¼ì œ",
  "description": "{image_url}",
  "children": [
    {{
      "keyword": "ì£¼ìš” ì¹´í…Œê³ ë¦¬ 1",
      "description": "êµ¬ì²´ì ì¸ ì‚¬ì‹¤, ìˆ«ì, íŠ¹ì§•",
      "children": [
        {{
          "keyword": "ì„¸ë¶€ í•­ëª©",
          "description": "ìƒì„¸ ì„¤ëª…",
          "children": null
        }}
      ]
    }}
  ]
}}

**ì¤‘ìš” ê·œì¹™:**
1. ë°˜ë“œì‹œ "keyword", "description", "children" í‚¤ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”
2. keywordë¥¼ JSON í‚¤ë¡œ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”
3. descriptionì—ëŠ” êµ¬ì²´ì ì¸ ì‚¬ì‹¤, ìˆ«ì, íŠ¹ì§•ì„ í¬í•¨í•˜ì„¸ìš”
4. ì´ë¯¸ì§€ì—ì„œ ê´€ì°°ëœ ê°ì²´, ìƒ‰ìƒ, êµ¬ì¡°, í…ìŠ¤íŠ¸ ë“±ì„ ì²´ê³„ì ìœ¼ë¡œ ì •ë¦¬í•˜ì„¸ìš”
5. JSONë§Œ ì¶œë ¥í•˜ê³ , ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡(```)ì€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”
"""

        user_prompt_text = f"""ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼:
{image_analysis}

ìœ„ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë§ˆì¸ë“œë§µ JSONì„ ìƒì„±í•´ì£¼ì„¸ìš”."""

        mindmap_json_str = text_analyzer.generate(
            prompt=user_prompt_text,
            system_prompt=system_prompt,
            max_tokens=4096,
            temperature=0.7
        )

        print("=" * 80)
        print("ì´ë¯¸ì§€ ë§ˆì¸ë“œë§µ LLM ìƒì„± ì›ë³¸ ì¶œë ¥:")
        print(mindmap_json_str[:1000])
        print("=" * 80)

        # JSON íŒŒì‹± (ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°)
        mindmap_json_str = mindmap_json_str.strip()
        if mindmap_json_str.startswith('```json'):
            mindmap_json_str = mindmap_json_str[7:]
        if mindmap_json_str.startswith('```'):
            mindmap_json_str = mindmap_json_str[3:]
        if mindmap_json_str.endswith('```'):
            mindmap_json_str = mindmap_json_str[:-3]
        mindmap_json_str = mindmap_json_str.strip()

        # JSONì„ MindMapNodeë¡œ ë³€í™˜
        def json_to_mindmap_node(data: Dict) -> MindMapNode:
            children = None
            if 'children' in data and data['children']:
                children = [json_to_mindmap_node(child) for child in data['children']]

            return MindMapNode(
                keyword=data.get('keyword', ''),
                description=data.get('description', ''),
                children=children
            )

        mindmap_data = json.loads(mindmap_json_str)

        # ì˜ëª»ëœ í˜•ì‹ ìˆ˜ì •
        if 'keyword' not in mindmap_data and 'description' not in mindmap_data:
            first_key = list(mindmap_data.keys())[0]
            first_value = mindmap_data[first_key]
            mindmap_data = {
                'keyword': first_key,
                'description': first_value.get('description', image_url),
                'children': first_value.get('children', None)
            }

        root = json_to_mindmap_node(mindmap_data)

        # ë£¨íŠ¸ ë…¸ë“œ descriptionì„ ì´ë¯¸ì§€ URLë¡œ ì„¤ì •
        root.description = image_url

        print(f"âœ… ì´ë¯¸ì§€ ë§ˆì¸ë“œë§µ ìƒì„±: keyword='{root.keyword}', children={len(root.children) if root.children else 0}")

        return root

    except Exception as e:
        logger.error(f"ì´ë¯¸ì§€ ë§ˆì¸ë“œë§µ ìƒì„± ì‹¤íŒ¨: {e}")
        # í´ë°±: ê°„ë‹¨í•œ ë§ˆì¸ë“œë§µ ìƒì„±
        return MindMapNode(
            keyword="ì´ë¯¸ì§€ ë¶„ì„",
            description=image_url,
            children=[
                MindMapNode(
                    keyword="ë¶„ì„ ê²°ê³¼",
                    description=image_analysis[:500] if len(image_analysis) > 500 else image_analysis,
                    children=None
                )
            ]
        )


def create_mindmap_from_text_llm(
    text_prompt: str,
    detail_level: str = "medium"
) -> MindMapNode:
    """
    í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë¡œë¶€í„° LLMì„ ì‚¬ìš©í•˜ì—¬ ë§ˆì¸ë“œë§µ ìƒì„±

    Args:
        text_prompt: ì‚¬ìš©ì ì…ë ¥ í…ìŠ¤íŠ¸/ì£¼ì œ
        detail_level: ìƒì„¸ ìˆ˜ì¤€ ("simple", "medium", "detailed")

    Returns:
        ë§ˆì¸ë“œë§µ ë£¨íŠ¸ ë…¸ë“œ
    """
    try:
        text_analyzer = get_text_analyzer()

        # ìƒì„¸ ìˆ˜ì¤€ì— ë”°ë¥¸ í† í° ìˆ˜ ë° ì§€ì‹œì‚¬í•­ ì„¤ì •
        if detail_level == "simple":
            max_tokens = 2048
            depth_instruction = "ìµœëŒ€ 2ë‹¨ê³„ ê¹Šì´ë¡œ ê°„ë‹¨í•˜ê²Œ êµ¬ì„±í•˜ì„¸ìš”."
            detail_instruction = "ê° ë…¸ë“œëŠ” í•µì‹¬ í‚¤ì›Œë“œì™€ ì§§ì€ ì„¤ëª…ë§Œ í¬í•¨í•˜ì„¸ìš”."
        elif detail_level == "detailed":
            max_tokens = 6144
            depth_instruction = "ìµœëŒ€ 4-5ë‹¨ê³„ ê¹Šì´ë¡œ ë§¤ìš° ìƒì„¸í•˜ê²Œ êµ¬ì„±í•˜ì„¸ìš”."
            detail_instruction = "ê° ë…¸ë“œì— êµ¬ì²´ì ì¸ ì˜ˆì‹œ, ìˆ˜ì¹˜, ê·¼ê±°ë¥¼ í¬í•¨í•˜ì„¸ìš”."
        else:  # medium
            max_tokens = 4096
            depth_instruction = "ìµœëŒ€ 3-4ë‹¨ê³„ ê¹Šì´ë¡œ ì ì ˆí•˜ê²Œ êµ¬ì„±í•˜ì„¸ìš”."
            detail_instruction = "ê° ë…¸ë“œì— ì¤‘ìš”í•œ ì •ë³´ì™€ ì„¤ëª…ì„ í¬í•¨í•˜ì„¸ìš”."

        system_prompt = f"""ë‹¹ì‹ ì€ í…ìŠ¤íŠ¸ë¥¼ êµ¬ì¡°í™”ëœ ë§ˆì¸ë“œë§µìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì‚¬ìš©ìê°€ ì œê³µí•œ ì£¼ì œë‚˜ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ì²´ê³„ì ì¸ ë§ˆì¸ë“œë§µì„ ìƒì„±í•˜ì„¸ìš”.
ë§ˆì¸ë“œë§µì€ ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤:

{{
  "keyword": "ì£¼ì œì˜ í•µì‹¬ í‚¤ì›Œë“œ",
  "description": "ì£¼ì œì— ëŒ€í•œ ê°„ë‹¨í•œ ì„¤ëª… ë˜ëŠ” ì •ì˜",
  "children": [
    {{
      "keyword": "ì£¼ìš” ì¹´í…Œê³ ë¦¬ 1",
      "description": "êµ¬ì²´ì ì¸ ì„¤ëª…, ì˜ˆì‹œ, íŠ¹ì§•",
      "children": [
        {{
          "keyword": "ì„¸ë¶€ í•­ëª©",
          "description": "ìƒì„¸ ë‚´ìš©",
          "children": null
        }}
      ]
    }},
    {{
      "keyword": "ì£¼ìš” ì¹´í…Œê³ ë¦¬ 2",
      "description": "êµ¬ì²´ì ì¸ ì„¤ëª…",
      "children": null
    }}
  ]
}}

**ì¤‘ìš” ê·œì¹™:**
1. ë°˜ë“œì‹œ "keyword", "description", "children" í‚¤ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”
2. keywordë¥¼ JSON í‚¤ë¡œ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”
3. {depth_instruction}
4. {detail_instruction}
5. ë…¼ë¦¬ì  ê³„ì¸µ êµ¬ì¡°ë¥¼ ë§Œë“œì„¸ìš” (ìƒìœ„ ê°œë… â†’ í•˜ìœ„ ê°œë…)
6. êµ¬ì²´ì ì¸ ì‚¬ì‹¤, ì˜ˆì‹œ, ìˆ˜ì¹˜ë¥¼ í¬í•¨í•˜ì„¸ìš”
7. JSONë§Œ ì¶œë ¥í•˜ê³ , ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡(```)ì€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”

ì£¼ì œ ë¶„ì„ ê°€ì´ë“œ:
- ê°œë…/ìš©ì–´ì¸ ê²½ìš°: ì •ì˜ â†’ íŠ¹ì§• â†’ ìœ í˜• â†’ ì˜ˆì‹œ â†’ ì‘ìš©
- í”„ë¡œì„¸ìŠ¤/ì ˆì°¨ì¸ ê²½ìš°: ë‹¨ê³„ë³„ ë¶„í•´ â†’ ê° ë‹¨ê³„ì˜ ì„¸ë¶€ì‚¬í•­
- ë¹„êµ/ëŒ€ì¡°ì¸ ê²½ìš°: í•­ëª©ë³„ ë¹„êµ â†’ ì°¨ì´ì ê³¼ ê³µí†µì 
- ì—­ì‚¬/ì‹œê°„ìˆœì¸ ê²½ìš°: ì‹œëŒ€ë³„/ë‹¨ê³„ë³„ êµ¬ë¶„ â†’ ì£¼ìš” ì‚¬ê±´/íŠ¹ì§•
- ë¬¸ì œ/í•´ê²°ì¸ ê²½ìš°: ë¬¸ì œ ì •ì˜ â†’ ì›ì¸ â†’ í•´ê²°ë°©ì•ˆ â†’ ê¸°ëŒ€íš¨ê³¼
"""

        user_prompt_text = f"""ì£¼ì œ/í…ìŠ¤íŠ¸: {text_prompt}

ìœ„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì²´ê³„ì ì¸ ë§ˆì¸ë“œë§µ JSONì„ ìƒì„±í•´ì£¼ì„¸ìš”."""

        mindmap_json_str = text_analyzer.generate(
            prompt=user_prompt_text,
            system_prompt=system_prompt,
            max_tokens=max_tokens,
            temperature=0.7
        )

        print("=" * 80)
        print("í…ìŠ¤íŠ¸ ë§ˆì¸ë“œë§µ LLM ìƒì„± ì›ë³¸ ì¶œë ¥:")
        print(mindmap_json_str[:1000])
        print("=" * 80)

        # JSON íŒŒì‹± (ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°)
        mindmap_json_str = mindmap_json_str.strip()
        if mindmap_json_str.startswith('```json'):
            mindmap_json_str = mindmap_json_str[7:]
        if mindmap_json_str.startswith('```'):
            mindmap_json_str = mindmap_json_str[3:]
        if mindmap_json_str.endswith('```'):
            mindmap_json_str = mindmap_json_str[:-3]
        mindmap_json_str = mindmap_json_str.strip()

        # JSONì„ MindMapNodeë¡œ ë³€í™˜
        def json_to_mindmap_node(data: Dict) -> MindMapNode:
            children = None
            if 'children' in data and data['children']:
                children = [json_to_mindmap_node(child) for child in data['children']]

            return MindMapNode(
                keyword=data.get('keyword', ''),
                description=data.get('description', ''),
                children=children
            )

        mindmap_data = json.loads(mindmap_json_str)

        # ì˜ëª»ëœ í˜•ì‹ ìˆ˜ì •
        if 'keyword' not in mindmap_data and 'description' not in mindmap_data:
            first_key = list(mindmap_data.keys())[0]
            first_value = mindmap_data[first_key]
            mindmap_data = {
                'keyword': first_key,
                'description': first_value.get('description', ''),
                'children': first_value.get('children', None)
            }

        root = json_to_mindmap_node(mindmap_data)

        print(f"âœ… í…ìŠ¤íŠ¸ ë§ˆì¸ë“œë§µ ìƒì„±: keyword='{root.keyword}', children={len(root.children) if root.children else 0}")

        return root

    except Exception as e:
        logger.error(f"í…ìŠ¤íŠ¸ ë§ˆì¸ë“œë§µ ìƒì„± ì‹¤íŒ¨: {e}")
        # í´ë°±: ê°„ë‹¨í•œ ë§ˆì¸ë“œë§µ ìƒì„±
        return MindMapNode(
            keyword=text_prompt[:50] if len(text_prompt) <= 50 else text_prompt[:47] + "...",
            description="AIê°€ ìƒì„±í•œ ë§ˆì¸ë“œë§µ",
            children=[
                MindMapNode(
                    keyword="ë¶„ì„ í•„ìš”",
                    description="ì´ ì£¼ì œì— ëŒ€í•œ ìƒì„¸ ë¶„ì„ì´ í•„ìš”í•©ë‹ˆë‹¤.",
                    children=None
                )
            ]
        )


def create_mindmap_from_llm(
    video_title: str,
    frame_analyses: List[str],
    transcript: str,
    user_query: Optional[str] = None,
    youtube_url: Optional[str] = None
) -> MindMapNode:
    """
    LLMì„ ì‚¬ìš©í•˜ì—¬ ë§ˆì¸ë“œë§µ ë°ì´í„° ìƒì„± (í´ë°± ë³´ì¥)

    Args:
        video_title: ì˜ìƒ ì œëª©
        frame_analyses: í”„ë ˆì„ ë¶„ì„ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        transcript: ì˜ìƒ ìë§‰
        user_query: ì‚¬ìš©ì ì§ˆë¬¸/í”„ë¡¬í”„íŠ¸
        youtube_url: YouTube URL

    Returns:
        ë§ˆì¸ë“œë§µ ë£¨íŠ¸ ë…¸ë“œ (í•­ìƒ Noneì´ ì•„ë‹˜)
    """
    try:
        text_analyzer = get_text_analyzer()

        # LLMìœ¼ë¡œ ë§ˆì¸ë“œë§µ JSON ìƒì„±
        mindmap_json_str = text_analyzer.generate_mindmap(
            video_title=video_title,
            frame_analyses=frame_analyses,
            transcript=transcript,
            user_query=user_query,
            max_tokens=4096,
            temperature=0.7
        )

        print("=" * 80)
        print("LLM ë§ˆì¸ë“œë§µ ìƒì„± ì›ë³¸ ì¶œë ¥:")
        print(mindmap_json_str[:1000])  # ì²˜ìŒ 1000ì
        print("=" * 80)

        # JSON íŒŒì‹±
        # LLMì´ ```json ``` ë¡œ ê°ì‹¸ì„œ ë°˜í™˜í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì œê±°
        mindmap_json_str = mindmap_json_str.strip()
        if mindmap_json_str.startswith('```json'):
            mindmap_json_str = mindmap_json_str[7:]
        if mindmap_json_str.startswith('```'):
            mindmap_json_str = mindmap_json_str[3:]
        if mindmap_json_str.endswith('```'):
            mindmap_json_str = mindmap_json_str[:-3]
        mindmap_json_str = mindmap_json_str.strip()

        print("ì •ì œ í›„ JSON:")
        print(mindmap_json_str[:500])
        print("=" * 80)

        # JSONì„ MindMapNodeë¡œ ë³€í™˜
        def json_to_mindmap_node(data: Dict) -> MindMapNode:
            children = None
            if 'children' in data and data['children']:
                children = [json_to_mindmap_node(child) for child in data['children']]

            return MindMapNode(
                keyword=data.get('keyword', ''),
                description=data.get('description', ''),
                children=children
            )

        mindmap_data = json.loads(mindmap_json_str)

        # LLMì´ ì˜ëª»ëœ í˜•ì‹ìœ¼ë¡œ ìƒì„±í•œ ê²½ìš° ìˆ˜ì •
        # {"ì˜ìƒ ì œëª©": {"description": ..., "children": ...}} í˜•ì‹ì„ ê°ì§€
        if 'keyword' not in mindmap_data and 'description' not in mindmap_data:
            # ì²« ë²ˆì§¸ í‚¤ë¥¼ keywordë¡œ ì‚¬ìš©
            first_key = list(mindmap_data.keys())[0]
            first_value = mindmap_data[first_key]

            print(f"âš ï¸  ì˜ëª»ëœ JSON í˜•ì‹ ê°ì§€! ìë™ ìˆ˜ì • ì¤‘...")
            print(f"   í‚¤ì›Œë“œ: {first_key}")

            # ì˜¬ë°”ë¥¸ í˜•ì‹ìœ¼ë¡œ ì¬êµ¬ì„±
            mindmap_data = {
                'keyword': first_key,
                'description': first_value.get('description', ''),
                'children': first_value.get('children', None)
            }

        root = json_to_mindmap_node(mindmap_data)

        print(f"ìƒì„±ëœ ë§ˆì¸ë“œë§µ ë£¨íŠ¸: keyword='{root.keyword}', children={len(root.children) if root.children else 0}")
        print("=" * 80)

        # ìœ íš¨ì„± ê²€ì¦
        if not root.keyword or not root.children:
            logger.warning(f"LLM ìƒì„± ë§ˆì¸ë“œë§µì´ ë¶ˆì™„ì „í•¨. keyword={root.keyword}, children={root.children}")
            logger.warning("í´ë°± ë§ˆì¸ë“œë§µ ì‚¬ìš©.")
            return create_fallback_mindmap(video_title, frame_analyses, transcript)

        # ë£¨íŠ¸ ë…¸ë“œ ê°•ì œ ì„¤ì •: keyword=ì˜ìƒ ì œëª©, description=YouTube URL
        root.keyword = video_title
        root.description = youtube_url if youtube_url else root.description

        print(f"âœ… ë£¨íŠ¸ ë…¸ë“œ ì„¤ì •: keyword='{root.keyword}', description='{root.description[:50]}...'")

        return root

    except json.JSONDecodeError as e:
        logger.error(f"ë§ˆì¸ë“œë§µ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
        logger.error(f"LLM ì¶œë ¥: {mindmap_json_str[:500] if 'mindmap_json_str' in locals() else 'N/A'}")
        logger.info("í´ë°± ë§ˆì¸ë“œë§µ ìƒì„± ì¤‘...")
        return create_fallback_mindmap(video_title, frame_analyses, transcript)
    except Exception as e:
        logger.error(f"ë§ˆì¸ë“œë§µ ìƒì„± ì‹¤íŒ¨: {e}")
        logger.info("í´ë°± ë§ˆì¸ë“œë§µ ìƒì„± ì¤‘...")
        return create_fallback_mindmap(video_title, frame_analyses, transcript)


@app.on_event("startup")
async def startup_event():
    """ì„œë²„ ì‹œì‘ ì‹œ ëª¨ë¸ ë¡œë“œ"""
    # í™˜ê²½ ë³€ìˆ˜ë¡œ ì–‘ìí™” ë°©ì‹ ì„¤ì • ê°€ëŠ¥
    vision_quant = os.getenv("VISION_QUANTIZATION", "int4")
    text_quant = os.getenv("TEXT_QUANTIZATION", "int4")

    load_models(vision_quantization=vision_quant, text_quantization=text_quant)


# ============================================================================
# ë¶„ì„ í•¨ìˆ˜
# ============================================================================

def analyze_video_sync(
    youtube_url: str,
    max_frames: Optional[int],
    proxy: Optional[str],
    user_prompt: Optional[str] = None
) -> AnalysisResult:
    """
    ì˜ìƒ ë¶„ì„ì„ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    task_id = str(uuid.uuid4())
    output_dir = f"temp_analysis_{task_id}"

    # ì´ˆê¸° ê²°ê³¼ ê°ì²´ ìƒì„±
    result = AnalysisResult(
        task_id=task_id,
        status=TaskStatus.DOWNLOADING,
        youtube_url=youtube_url,
        created_at=datetime.now().isoformat()
    )

    try:

        # 1. ì˜ìƒ ë‹¤ìš´ë¡œë“œ ë° í”„ë ˆì„ ì¶”ì¶œ
        os.makedirs(output_dir, exist_ok=True)
        frame_extractor = FrameExtractor(output_dir=output_dir)

        download_result = frame_extractor.download_video(youtube_url)
        if not download_result['success']:
            raise Exception(f"ì˜ìƒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {download_result['error']}")

        video_path = download_result['path']
        video_duration = download_result['duration']
        result.video_info = {
            "title": download_result['title'],
            "duration": video_duration,
            "channel": download_result.get('channel', 'Unknown')
        }

        # ë™ì ìœ¼ë¡œ ìµœì  í”„ë ˆì„ ìˆ˜ ê³„ì‚° (max_framesê°€ Noneì´ë©´ ìë™ ê³„ì‚°)
        if max_frames is None:
            optimal_frames = FrameExtractor.calculate_optimal_frames(video_duration)
        else:
            optimal_frames = max_frames
            logger.info(f"ğŸ“Œ ì‚¬ìš©ì ì§€ì • í”„ë ˆì„ ìˆ˜: {optimal_frames}")

        # í”„ë ˆì„ ì¶”ì¶œ
        result.status = TaskStatus.EXTRACTING_FRAMES
        frames_result = frame_extractor.extract_frames_scene_detect(
            video_path,
            max_frames=optimal_frames
        )

        if not frames_result['success']:
            raise Exception(f"í”„ë ˆì„ ì¶”ì¶œ ì‹¤íŒ¨: {frames_result['error']}")

        frames = [frame['path'] for frame in frames_result['frames']]

        # ì˜ìƒ íŒŒì¼ ì‚­ì œ
        if os.path.exists(video_path):
            os.remove(video_path)

        # 2. ìë§‰ ì¶”ì¶œ
        result.status = TaskStatus.EXTRACTING_TRANSCRIPT
        transcript_result = TranscriptExtractor.get_transcript(
            youtube_url,
            languages=['ko', 'en']
        )

        transcript = transcript_result['full_text'] if transcript_result['success'] else "[ìë§‰ ì—†ìŒ]"
        result.transcript = transcript

        # 3. Vision ë¶„ì„ (ìºì‹±ëœ ëª¨ë¸ ì‚¬ìš©)
        result.status = TaskStatus.ANALYZING_VISION
        vision_analyzer = get_vision_analyzer()

        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        base_prompt = "ì´ í”„ë ˆì„ì—ì„œ ë‹¤ìŒì„ ì„¤ëª…í•˜ì„¸ìš”:\n1. ì£¼ìš” ê°ì²´\n2. ì‚¬ëŒì´ë‚˜ í–‰ë™\n3. í™”ë©´ì— ë³´ì´ëŠ” í…ìŠ¤íŠ¸"

        if user_prompt:
            final_prompt = f"{user_prompt}\n\n{base_prompt}"
        else:
            final_prompt = base_prompt

        # í”„ë ˆì„ ë¶„ì„ (ìˆœì°¨ ì²˜ë¦¬)
        frame_analyses = []
        for i, frame_path in enumerate(frames):
            logger.info(f"ğŸ“¸ í”„ë ˆì„ {i+1}/{len(frames)} ë¶„ì„ ì¤‘...")

            if transcript and transcript != "[ìë§‰ ì—†ìŒ]":
                analysis = vision_analyzer.analyze_with_context(
                    image=frame_path,
                    prompt=final_prompt,
                    context=f"ì˜ìƒ ìë§‰ ì»¨í…ìŠ¤íŠ¸:\n{transcript[:500]}",
                    max_tokens=150,
                    temperature=0.0
                )
            else:
                analysis = vision_analyzer.analyze_image(
                    image=frame_path,
                    prompt=final_prompt,
                    max_tokens=150,
                    temperature=0.0
                )

            # ë°˜ë³µ ë¬¸ì¥ ì œê±°
            cleaned_analysis = remove_repetitive_sentences(analysis, max_repetition=1)
            frame_analyses.append(cleaned_analysis)

            # í”„ë ˆì„ ì‚­ì œ
            if os.path.exists(frame_path):
                os.remove(frame_path)

        result.frame_analyses = frame_analyses

        # 4. Text ë¶„ì„ (ìºì‹±ëœ ëª¨ë¸ ì‚¬ìš©)
        result.status = TaskStatus.ANALYZING_TEXT
        text_analyzer = get_text_analyzer()

        summary = text_analyzer.summarize_video(
            frame_analyses=frame_analyses,
            transcript=transcript,
            max_tokens=2048,
            temperature=0.3
        )
        result.summary = summary

        key_points = text_analyzer.extract_key_points(
            transcript if transcript != "[ìë§‰ ì—†ìŒ]" else "\n".join(frame_analyses),
            max_points=5
        )
        result.key_points = key_points

        # ì™„ë£Œ
        result.status = TaskStatus.COMPLETED
        result.completed_at = datetime.now().isoformat()

    except Exception as e:
        result.status = TaskStatus.FAILED
        result.error = str(e)
        result.completed_at = datetime.now().isoformat()

    finally:
        # ì„ì‹œ ë””ë ‰í† ë¦¬ ì •ë¦¬
        import shutil
        if os.path.exists(output_dir):
            try:
                shutil.rmtree(output_dir)
            except Exception as e:
                logger.warning(f"ì„ì‹œ ë””ë ‰í† ë¦¬ ì‚­ì œ ì‹¤íŒ¨: {e}")

    return result


async def analyze_video_stream(
    youtube_url: str,
    max_frames: Optional[int],
    proxy: Optional[str],
    user_prompt: Optional[str] = None
):
    """
    ì˜ìƒ ë¶„ì„ì„ ìˆ˜í–‰í•˜ë©´ì„œ ì‹¤ì‹œê°„ìœ¼ë¡œ ì§„í–‰ ìƒí™©ì„ ìŠ¤íŠ¸ë¦¬ë°í•©ë‹ˆë‹¤.
    """
    task_id = str(uuid.uuid4())
    output_dir = f"temp_analysis_{task_id}"

    try:
        # ì‹œì‘ ë©”ì‹œì§€
        yield f"data: {json.dumps({'status': 'started', 'task_id': task_id, 'progress': 0, 'message': 'ë¶„ì„ ì‹œì‘'})}\n\n"
        await asyncio.sleep(0.1)

        # 1. ì˜ìƒ ë‹¤ìš´ë¡œë“œ ë° í”„ë ˆì„ ì¶”ì¶œ
        yield f"data: {json.dumps({'status': 'downloading', 'progress': 10, 'message': 'ì˜ìƒ ë‹¤ìš´ë¡œë“œ ì¤‘...'})}\n\n"
        await asyncio.sleep(0.1)

        os.makedirs(output_dir, exist_ok=True)
        frame_extractor = FrameExtractor(output_dir=output_dir)

        download_result = frame_extractor.download_video(youtube_url)
        if not download_result['success']:
            error_msg = f"ì˜ìƒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {download_result['error']}"
            yield f"data: {json.dumps({'status': 'failed', 'error': error_msg})}\n\n"
            return

        video_path = download_result['path']
        video_duration = download_result['duration']
        video_info = {
            "title": download_result['title'],
            "duration": video_duration,
            "channel": download_result.get('channel', 'Unknown')
        }

        # ë™ì ìœ¼ë¡œ ìµœì  í”„ë ˆì„ ìˆ˜ ê³„ì‚° (max_framesê°€ Noneì´ë©´ ìë™ ê³„ì‚°)
        if max_frames is None:
            optimal_frames = FrameExtractor.calculate_optimal_frames(video_duration)
        else:
            optimal_frames = max_frames
            logger.info(f"ğŸ“Œ ì‚¬ìš©ì ì§€ì • í”„ë ˆì„ ìˆ˜: {optimal_frames}")

        message = f"ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {video_info['title']} (ìµœì  í”„ë ˆì„: {optimal_frames}ê°œ)"
        yield f"data: {json.dumps({'status': 'download_complete', 'progress': 20, 'message': message, 'video_info': video_info})}\n\n"
        await asyncio.sleep(0.1)

        # í”„ë ˆì„ ì¶”ì¶œ
        yield f"data: {json.dumps({'status': 'extracting_frames', 'progress': 25, 'message': f'í”„ë ˆì„ {optimal_frames}ê°œ ì¶”ì¶œ ì¤‘...'})}\n\n"
        await asyncio.sleep(0.1)

        frames_result = frame_extractor.extract_frames_scene_detect(
            video_path,
            max_frames=optimal_frames
        )

        if not frames_result['success']:
            error_msg = f"í”„ë ˆì„ ì¶”ì¶œ ì‹¤íŒ¨: {frames_result['error']}"
            yield f"data: {json.dumps({'status': 'failed', 'error': error_msg})}\n\n"
            return

        frames = [frame['path'] for frame in frames_result['frames']]

        # ì˜ìƒ íŒŒì¼ ì‚­ì œ
        if os.path.exists(video_path):
            os.remove(video_path)

        message = f"{len(frames)}ê°œ í”„ë ˆì„ ì¶”ì¶œ ì™„ë£Œ"
        yield f"data: {json.dumps({'status': 'frames_extracted', 'progress': 35, 'message': message})}\n\n"
        await asyncio.sleep(0.1)

        # 2. ìë§‰ ì¶”ì¶œ
        yield f"data: {json.dumps({'status': 'extracting_transcript', 'progress': 40, 'message': 'ìë§‰ ì¶”ì¶œ ì¤‘...'})}\n\n"
        await asyncio.sleep(0.1)

        transcript_result = TranscriptExtractor.get_transcript(
            youtube_url,
            languages=['ko', 'en']
        )

        transcript = transcript_result['full_text'] if transcript_result['success'] else "[ìë§‰ ì—†ìŒ]"

        yield f"data: {json.dumps({'status': 'transcript_extracted', 'progress': 45, 'message': 'ìë§‰ ì¶”ì¶œ ì™„ë£Œ'})}\n\n"
        await asyncio.sleep(0.1)

        # 3. Vision ë¶„ì„
        yield f"data: {json.dumps({'status': 'analyzing_vision', 'progress': 50, 'message': 'Vision ëª¨ë¸ë¡œ í”„ë ˆì„ ë¶„ì„ ì¤‘...'})}\n\n"
        await asyncio.sleep(0.1)

        vision_analyzer = get_vision_analyzer()

        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        base_prompt = "ì´ í”„ë ˆì„ì—ì„œ ë‹¤ìŒì„ ì„¤ëª…í•˜ì„¸ìš”:\n1. ì£¼ìš” ê°ì²´\n2. ì‚¬ëŒì´ë‚˜ í–‰ë™\n3. í™”ë©´ì— ë³´ì´ëŠ” í…ìŠ¤íŠ¸"

        if user_prompt:
            final_prompt = f"{user_prompt}\n\n{base_prompt}"
        else:
            final_prompt = base_prompt

        # í”„ë ˆì„ ë¶„ì„ (ìˆœì°¨ ì²˜ë¦¬)
        frame_analyses = []
        for i, frame_path in enumerate(frames):
            # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
            progress = 50 + int((i / len(frames)) * 30)  # 50% ~ 80%
            message = f"í”„ë ˆì„ {i+1}/{len(frames)} ë¶„ì„ ì¤‘..."
            yield f"data: {json.dumps({'status': 'analyzing_vision', 'progress': progress, 'message': message})}\n\n"
            await asyncio.sleep(0.1)

            if transcript and transcript != "[ìë§‰ ì—†ìŒ]":
                analysis = vision_analyzer.analyze_with_context(
                    image=frame_path,
                    prompt=final_prompt,
                    context=f"ì˜ìƒ ìë§‰ ì»¨í…ìŠ¤íŠ¸:\n{transcript[:500]}",
                    max_tokens=150,
                    temperature=0.0
                )
            else:
                analysis = vision_analyzer.analyze_image(
                    image=frame_path,
                    prompt=final_prompt,
                    max_tokens=150,
                    temperature=0.0
                )

            # ë°˜ë³µ ë¬¸ì¥ ì œê±°
            cleaned_analysis = remove_repetitive_sentences(analysis, max_repetition=1)
            frame_analyses.append(cleaned_analysis)

            # í”„ë ˆì„ ì‚­ì œ
            if os.path.exists(frame_path):
                os.remove(frame_path)

        yield f"data: {json.dumps({'status': 'vision_complete', 'progress': 80, 'message': 'Vision ë¶„ì„ ì™„ë£Œ'})}\n\n"
        await asyncio.sleep(0.1)

        # 4. ë§ˆì¸ë“œë§µ ìƒì„± (í•µì‹¬ ê¸°ëŠ¥)
        yield f"data: {json.dumps({'status': 'creating_mindmap', 'progress': 85, 'message': 'LLMìœ¼ë¡œ ë§ˆì¸ë“œë§µ ìƒì„± ì¤‘...'})}\n\n"
        await asyncio.sleep(0.1)

        mindmap = create_mindmap_from_llm(
            video_title=video_info['title'],
            frame_analyses=frame_analyses,
            transcript=transcript,
            user_query=user_prompt,  # ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ë¥¼ ë§ˆì¸ë“œë§µ ìƒì„±ì— í™œìš©
            youtube_url=youtube_url
        )

        yield f"data: {json.dumps({'status': 'mindmap_complete', 'progress': 95, 'message': 'ë§ˆì¸ë“œë§µ ìƒì„± ì™„ë£Œ'})}\n\n"
        await asyncio.sleep(0.1)

        # Summaryì™€ Key PointsëŠ” ë‚´ë¶€ì ìœ¼ë¡œ ìƒì„±í•˜ì§€ë§Œ UIì— í‘œì‹œí•˜ì§€ ì•ŠìŒ
        summary = None
        key_points = None

        # ìµœì¢… ê²°ê³¼
        result = {
            "task_id": task_id,
            "status": "completed",
            "youtube_url": youtube_url,
            "created_at": datetime.now().isoformat(),
            "completed_at": datetime.now().isoformat(),
            "video_info": video_info,
            "summary": summary,
            "key_points": key_points,
            "frame_analyses": frame_analyses,
            "transcript": transcript,
            "mindmap": mindmap.dict()  # ë§ˆì¸ë“œë§µ ë°ì´í„° (í•­ìƒ ì¡´ì¬)
        }

        yield f"data: {json.dumps({'status': 'completed', 'progress': 100, 'message': 'ë¶„ì„ ì™„ë£Œ!', 'result': result}, ensure_ascii=False)}\n\n"

    except Exception as e:
        error_msg = str(e)
        logger.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {error_msg}")
        yield f"data: {json.dumps({'status': 'failed', 'error': error_msg})}\n\n"

    finally:
        # ì„ì‹œ ë””ë ‰í† ë¦¬ ì •ë¦¬
        import shutil
        if os.path.exists(output_dir):
            try:
                shutil.rmtree(output_dir)
            except Exception as e:
                logger.warning(f"ì„ì‹œ ë””ë ‰í† ë¦¬ ì‚­ì œ ì‹¤íŒ¨: {e}")


# ============================================================================
# API ì—”ë“œí¬ì¸íŠ¸
# ============================================================================

@app.get("/")
def root():
    """API ì •ë³´"""
    return {
        "name": "AI Analysis API - Video, Image & Text",
        "version": "1.0.0",
        "description": "Llama 3.2 Vision + Llama 3.1ì„ ì‚¬ìš©í•œ ë©€í‹°ëª¨ë‹¬ ë¶„ì„ ë° ë§ˆì¸ë“œë§µ ìƒì„±",
        "endpoints": {
            "POST /analyze": "YouTube ì˜ìƒ ë¶„ì„ (ìŠ¤íŠ¸ë¦¬ë°)",
            "POST /analyze/sync": "YouTube ì˜ìƒ ë¶„ì„ (ë™ê¸°ì‹)",
            "POST /analyze/image": "ì´ë¯¸ì§€ URL ë¶„ì„ (ìŠ¤íŠ¸ë¦¬ë°)",
            "POST /analyze/text": "í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ ë¶„ì„ (ìŠ¤íŠ¸ë¦¬ë°)",
            "GET /tasks/{task_id}": "ì‘ì—… ìƒíƒœ ë° ê²°ê³¼ ì¡°íšŒ",
            "GET /tasks": "ëª¨ë“  ì‘ì—… ëª©ë¡ ì¡°íšŒ",
            "DELETE /tasks/{task_id}": "ì‘ì—… ì‚­ì œ",
            "GET /health": "í—¬ìŠ¤ ì²´í¬"
        }
    }


@app.post("/analyze")
async def analyze_video(request: AnalyzeRequest):
    """
    YouTube ì˜ìƒ ë¶„ì„ (ìŠ¤íŠ¸ë¦¬ë° - ì‹¤ì‹œê°„ ì§„í–‰ ìƒí™© + ìµœì¢… ê²°ê³¼)

    Server-Sent Events (SSE) í˜•ì‹ìœ¼ë¡œ ì‹¤ì‹œê°„ ì§„í–‰ ìƒí™©ì„ ì „ë‹¬í•©ë‹ˆë‹¤.

    - **youtube_url**: YouTube ì˜ìƒ URL
    - **max_frames**: ìµœëŒ€ ì¶”ì¶œ í”„ë ˆì„ ìˆ˜ (ê¸°ë³¸: 8)
    - **proxy**: í”„ë¡ì‹œ ì„œë²„ (ì„ íƒ)

    ### ì‘ë‹µ í˜•ì‹ (SSE)
    ê° ì´ë²¤íŠ¸ëŠ” ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì „ë‹¬ë©ë‹ˆë‹¤:
    ```
    data: {"status": "...", "progress": 0-100, "message": "...", ...}
    ```

    ### ìƒíƒœ ì¢…ë¥˜
    - `started`: ë¶„ì„ ì‹œì‘
    - `downloading`: ì˜ìƒ ë‹¤ìš´ë¡œë“œ ì¤‘
    - `download_complete`: ë‹¤ìš´ë¡œë“œ ì™„ë£Œ
    - `extracting_frames`: í”„ë ˆì„ ì¶”ì¶œ ì¤‘
    - `frames_extracted`: í”„ë ˆì„ ì¶”ì¶œ ì™„ë£Œ
    - `extracting_transcript`: ìë§‰ ì¶”ì¶œ ì¤‘
    - `transcript_extracted`: ìë§‰ ì¶”ì¶œ ì™„ë£Œ
    - `analyzing_vision`: Vision ëª¨ë¸ ë¶„ì„ ì¤‘
    - `vision_complete`: Vision ë¶„ì„ ì™„ë£Œ
    - `analyzing_text`: Text ëª¨ë¸ ë¶„ì„ ì¤‘
    - `summary_complete`: ìš”ì•½ ìƒì„± ì™„ë£Œ
    - `extracting_keypoints`: í•µì‹¬ í¬ì¸íŠ¸ ì¶”ì¶œ ì¤‘
    - `completed`: ë¶„ì„ ì™„ë£Œ (result í¬í•¨)
    - `failed`: ì˜¤ë¥˜ ë°œìƒ (error í¬í•¨)
    """
    return StreamingResponse(
        analyze_video_stream(
            youtube_url=str(request.youtube_url),
            max_frames=request.max_frames,
            proxy=request.proxy,
            user_prompt=request.user_prompt
        ),
        media_type="text/event-stream"
    )


@app.post("/analyze/sync", response_model=AnalysisResult)
def analyze_video_sync_endpoint(request: AnalyzeRequest):
    """
    YouTube ì˜ìƒ ë¶„ì„ (ë™ê¸°ì‹ - ë¶„ì„ ì™„ë£Œ í›„ ê²°ê³¼ ë°˜í™˜)

    íƒ€ì„ì•„ì›ƒì´ ë°œìƒí•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ /analyze (ìŠ¤íŠ¸ë¦¬ë°) ì‚¬ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤.

    - **youtube_url**: YouTube ì˜ìƒ URL
    - **max_frames**: ìµœëŒ€ ì¶”ì¶œ í”„ë ˆì„ ìˆ˜ (ê¸°ë³¸: 8)
    - **proxy**: í”„ë¡ì‹œ ì„œë²„ (ì„ íƒ)
    """
    result = analyze_video_sync(
        youtube_url=str(request.youtube_url),
        max_frames=request.max_frames,
        proxy=request.proxy,
        user_prompt=request.user_prompt
    )

    return result


@app.get("/tasks/{task_id}", response_model=AnalysisResult)
async def get_task(task_id: str):
    """
    ì‘ì—… ìƒíƒœ ë° ê²°ê³¼ ì¡°íšŒ

    - **task_id**: ì‘ì—… ID
    """
    if task_id not in tasks:
        raise HTTPException(status_code=404, detail="ì‘ì—…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    return tasks[task_id]


@app.get("/tasks")
async def list_tasks():
    """
    ëª¨ë“  ì‘ì—… ëª©ë¡ ì¡°íšŒ
    """
    return {
        "total": len(tasks),
        "tasks": [
            {
                "task_id": task.task_id,
                "status": task.status,
                "youtube_url": task.youtube_url,
                "created_at": task.created_at,
                "completed_at": task.completed_at
            }
            for task in tasks.values()
        ]
    }


@app.delete("/tasks/{task_id}")
async def delete_task(task_id: str):
    """
    ì‘ì—… ì‚­ì œ

    - **task_id**: ì‘ì—… ID
    """
    if task_id not in tasks:
        raise HTTPException(status_code=404, detail="ì‘ì—…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    del tasks[task_id]

    return {
        "message": f"ì‘ì—… {task_id}ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤."
    }


@app.get("/health")
async def health_check():
    """
    í—¬ìŠ¤ ì²´í¬
    """
    gpu_available = torch.cuda.is_available()

    return {
        "status": "healthy",
        "gpu_available": gpu_available,
        "gpu_name": torch.cuda.get_device_name(0) if gpu_available else None,
        "models_loaded": _models_loaded,
        "vision_model_loaded": _vision_analyzer is not None,
        "text_model_loaded": _text_analyzer is not None,
        "active_tasks": sum(1 for task in tasks.values() if task.status not in [TaskStatus.COMPLETED, TaskStatus.FAILED])
    }


# ============================================================================
# ì´ë¯¸ì§€ ë¶„ì„ API
# ============================================================================

async def analyze_image_stream(
    image_url: str,
    user_prompt: Optional[str] = None
):
    """
    ì´ë¯¸ì§€ ë¶„ì„ì„ ìˆ˜í–‰í•˜ë©´ì„œ ì‹¤ì‹œê°„ìœ¼ë¡œ ì§„í–‰ ìƒí™©ì„ ìŠ¤íŠ¸ë¦¬ë°í•©ë‹ˆë‹¤.
    """
    task_id = str(uuid.uuid4())
    output_dir = f"temp_image_analysis_{task_id}"

    try:
        # ì‹œì‘ ë©”ì‹œì§€
        yield f"data: {json.dumps({'status': 'started', 'task_id': task_id, 'progress': 0, 'message': 'ì´ë¯¸ì§€ ë¶„ì„ ì‹œì‘'})}\n\n"
        await asyncio.sleep(0.1)

        # 1. ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
        yield f"data: {json.dumps({'status': 'downloading_image', 'progress': 10, 'message': 'ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì¤‘...'})}\n\n"
        await asyncio.sleep(0.1)

        os.makedirs(output_dir, exist_ok=True)
        image_analyzer = ImageAnalyzer(output_dir=output_dir)

        image_path = image_analyzer.download_image(image_url)
        if not image_path:
            error_msg = "ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨"
            yield f"data: {json.dumps({'status': 'failed', 'error': error_msg})}\n\n"
            return

        # ì´ë¯¸ì§€ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
        from PIL import Image
        with Image.open(image_path) as img:
            image_info = {
                "format": img.format,
                "size": img.size,
                "mode": img.mode,
                "width": img.width,
                "height": img.height
            }

        message = f"ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {image_info['width']}x{image_info['height']}, {image_info['format']}"
        yield f"data: {json.dumps({'status': 'download_complete', 'progress': 30, 'message': message, 'image_info': image_info})}\n\n"
        await asyncio.sleep(0.1)

        # 2. Vision ë¶„ì„
        yield f"data: {json.dumps({'status': 'analyzing_vision', 'progress': 40, 'message': 'Vision ëª¨ë¸ë¡œ ì´ë¯¸ì§€ ë¶„ì„ ì¤‘...'})}\n\n"
        await asyncio.sleep(0.1)

        vision_analyzer = get_vision_analyzer()

        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        if user_prompt:
            final_prompt = f"""{user_prompt}

ë‹¤ìŒì„ í¬í•¨í•˜ì—¬ ìƒì„¸í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”:
1. ì´ë¯¸ì§€ì˜ ì£¼ìš” ê°ì²´ì™€ êµ¬ì„±
2. ìƒ‰ìƒê³¼ ì‹œê°ì  íŠ¹ì§•
3. í…ìŠ¤íŠ¸ê°€ ìˆë‹¤ë©´ ê·¸ ë‚´ìš©
4. ì „ì²´ì ì¸ ë¶„ìœ„ê¸°ì™€ ë§¥ë½"""
        else:
            final_prompt = """ì´ ì´ë¯¸ì§€ë¥¼ ìƒì„¸í•˜ê²Œ ë¶„ì„í•´ì£¼ì„¸ìš”:
1. ì£¼ìš” ê°ì²´ì™€ êµ¬ì„±
2. ìƒ‰ìƒê³¼ ì‹œê°ì  íŠ¹ì§•
3. í™”ë©´ì— ë³´ì´ëŠ” í…ìŠ¤íŠ¸
4. ì „ì²´ì ì¸ ë¶„ìœ„ê¸°ì™€ ë§¥ë½"""

        analysis = vision_analyzer.analyze_image(
            image=image_path,
            prompt=final_prompt,
            max_tokens=500,
            temperature=0.3
        )

        # ë°˜ë³µ ë¬¸ì¥ ì œê±°
        cleaned_analysis = remove_repetitive_sentences(analysis, max_repetition=1)

        yield f"data: {json.dumps({'status': 'vision_complete', 'progress': 70, 'message': 'Vision ë¶„ì„ ì™„ë£Œ'})}\n\n"
        await asyncio.sleep(0.1)

        # 3. ë§ˆì¸ë“œë§µ ìƒì„±
        yield f"data: {json.dumps({'status': 'creating_mindmap', 'progress': 80, 'message': 'LLMìœ¼ë¡œ ë§ˆì¸ë“œë§µ ìƒì„± ì¤‘...'})}\n\n"
        await asyncio.sleep(0.1)

        mindmap = create_mindmap_from_image_llm(
            image_url=image_url,
            image_analysis=cleaned_analysis,
            user_query=user_prompt
        )

        yield f"data: {json.dumps({'status': 'mindmap_complete', 'progress': 95, 'message': 'ë§ˆì¸ë“œë§µ ìƒì„± ì™„ë£Œ'})}\n\n"
        await asyncio.sleep(0.1)

        # ìµœì¢… ê²°ê³¼
        result = {
            "task_id": task_id,
            "status": "completed",
            "image_url": image_url,
            "created_at": datetime.now().isoformat(),
            "completed_at": datetime.now().isoformat(),
            "image_info": image_info,
            "analysis": cleaned_analysis,
            "mindmap": mindmap.dict()
        }

        yield f"data: {json.dumps({'status': 'completed', 'progress': 100, 'message': 'ì´ë¯¸ì§€ ë¶„ì„ ì™„ë£Œ!', 'result': result}, ensure_ascii=False)}\n\n"

    except Exception as e:
        error_msg = str(e)
        logger.error(f"ì´ë¯¸ì§€ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {error_msg}")
        yield f"data: {json.dumps({'status': 'failed', 'error': error_msg})}\n\n"

    finally:
        # ì„ì‹œ ë””ë ‰í† ë¦¬ ì •ë¦¬
        import shutil
        if os.path.exists(output_dir):
            try:
                shutil.rmtree(output_dir)
            except Exception as e:
                logger.warning(f"ì„ì‹œ ë””ë ‰í† ë¦¬ ì‚­ì œ ì‹¤íŒ¨: {e}")


@app.post("/analyze/image")
async def analyze_image(request: ImageAnalyzeRequest):
    """
    ì´ë¯¸ì§€ ë¶„ì„ (ìŠ¤íŠ¸ë¦¬ë° - ì‹¤ì‹œê°„ ì§„í–‰ ìƒí™© + ìµœì¢… ê²°ê³¼)

    Server-Sent Events (SSE) í˜•ì‹ìœ¼ë¡œ ì‹¤ì‹œê°„ ì§„í–‰ ìƒí™©ì„ ì „ë‹¬í•©ë‹ˆë‹¤.

    - **image_url**: ë¶„ì„í•  ì´ë¯¸ì§€ URL
    - **user_prompt**: ì‚¬ìš©ì ì§ˆë¬¸/í”„ë¡¬í”„íŠ¸ (ì„ íƒ)

    ### ì‘ë‹µ í˜•ì‹ (SSE)
    ê° ì´ë²¤íŠ¸ëŠ” ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì „ë‹¬ë©ë‹ˆë‹¤:
    ```
    data: {"status": "...", "progress": 0-100, "message": "...", ...}
    ```

    ### ìƒíƒœ ì¢…ë¥˜
    - `started`: ë¶„ì„ ì‹œì‘
    - `downloading_image`: ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì¤‘
    - `download_complete`: ë‹¤ìš´ë¡œë“œ ì™„ë£Œ
    - `analyzing_vision`: Vision ëª¨ë¸ ë¶„ì„ ì¤‘
    - `vision_complete`: Vision ë¶„ì„ ì™„ë£Œ
    - `creating_mindmap`: ë§ˆì¸ë“œë§µ ìƒì„± ì¤‘
    - `mindmap_complete`: ë§ˆì¸ë“œë§µ ìƒì„± ì™„ë£Œ
    - `completed`: ë¶„ì„ ì™„ë£Œ (result í¬í•¨)
    - `failed`: ì˜¤ë¥˜ ë°œìƒ (error í¬í•¨)
    """
    return StreamingResponse(
        analyze_image_stream(
            image_url=str(request.image_url),
            user_prompt=request.user_prompt
        ),
        media_type="text/event-stream"
    )


# ============================================================================
# í…ìŠ¤íŠ¸ ë¶„ì„ API
# ============================================================================

async def analyze_text_stream(
    text_prompt: str,
    detail_level: str = "medium"
):
    """
    í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ë§ˆì¸ë“œë§µì„ ìƒì„±í•˜ë©´ì„œ ì‹¤ì‹œê°„ìœ¼ë¡œ ì§„í–‰ ìƒí™©ì„ ìŠ¤íŠ¸ë¦¬ë°í•©ë‹ˆë‹¤.
    """
    task_id = str(uuid.uuid4())

    try:
        # ì‹œì‘ ë©”ì‹œì§€
        yield f"data: {json.dumps({'status': 'started', 'task_id': task_id, 'progress': 0, 'message': 'í…ìŠ¤íŠ¸ ë¶„ì„ ì‹œì‘'}, ensure_ascii=False)}\n\n"
        await asyncio.sleep(0.1)

        # í…ìŠ¤íŠ¸ ê²€ì¦
        yield f"data: {json.dumps({'status': 'validating', 'progress': 10, 'message': 'ì…ë ¥ í…ìŠ¤íŠ¸ ê²€ì¦ ì¤‘...'}, ensure_ascii=False)}\n\n"
        await asyncio.sleep(0.1)

        if not text_prompt or len(text_prompt.strip()) < 3:
            error_msg = "í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. ìµœì†Œ 3ì ì´ìƒ ì…ë ¥í•´ì£¼ì„¸ìš”."
            yield f"data: {json.dumps({'status': 'failed', 'error': error_msg}, ensure_ascii=False)}\n\n"
            return

        if len(text_prompt) > 10000:
            error_msg = "í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¹ë‹ˆë‹¤. ìµœëŒ€ 10,000ìê¹Œì§€ ì§€ì›í•©ë‹ˆë‹¤."
            yield f"data: {json.dumps({'status': 'failed', 'error': error_msg}, ensure_ascii=False)}\n\n"
            return

        # í…ìŠ¤íŠ¸ ì •ë³´
        text_info = {
            "length": len(text_prompt),
            "word_count": len(text_prompt.split()),
            "detail_level": detail_level
        }

        message = f"í…ìŠ¤íŠ¸ ê²€ì¦ ì™„ë£Œ: {text_info['length']}ì, {text_info['word_count']}ë‹¨ì–´, ìƒì„¸ë„={detail_level}"
        yield f"data: {json.dumps({'status': 'validation_complete', 'progress': 20, 'message': message, 'text_info': text_info}, ensure_ascii=False)}\n\n"
        await asyncio.sleep(0.1)

        # ë§ˆì¸ë“œë§µ ìƒì„±
        yield f"data: {json.dumps({'status': 'creating_mindmap', 'progress': 30, 'message': 'LLMìœ¼ë¡œ ë§ˆì¸ë“œë§µ ìƒì„± ì¤‘...'}, ensure_ascii=False)}\n\n"
        await asyncio.sleep(0.1)

        # ìƒì„¸ë„ì— ë”°ë¼ ì˜ˆìƒ ì‹œê°„ í‘œì‹œ
        if detail_level == "simple":
            yield f"data: {json.dumps({'status': 'creating_mindmap', 'progress': 40, 'message': 'ê°„ë‹¨í•œ ë§ˆì¸ë“œë§µ ìƒì„± ì¤‘... (ì˜ˆìƒ 5-10ì´ˆ)'}, ensure_ascii=False)}\n\n"
        elif detail_level == "detailed":
            yield f"data: {json.dumps({'status': 'creating_mindmap', 'progress': 40, 'message': 'ìƒì„¸í•œ ë§ˆì¸ë“œë§µ ìƒì„± ì¤‘... (ì˜ˆìƒ 15-30ì´ˆ)'}, ensure_ascii=False)}\n\n"
        else:
            yield f"data: {json.dumps({'status': 'creating_mindmap', 'progress': 40, 'message': 'í‘œì¤€ ë§ˆì¸ë“œë§µ ìƒì„± ì¤‘... (ì˜ˆìƒ 10-20ì´ˆ)'}, ensure_ascii=False)}\n\n"
        await asyncio.sleep(0.1)

        # LLMìœ¼ë¡œ ë§ˆì¸ë“œë§µ ìƒì„±
        mindmap = create_mindmap_from_text_llm(
            text_prompt=text_prompt,
            detail_level=detail_level
        )

        yield f"data: {json.dumps({'status': 'mindmap_complete', 'progress': 95, 'message': 'ë§ˆì¸ë“œë§µ ìƒì„± ì™„ë£Œ'}, ensure_ascii=False)}\n\n"
        await asyncio.sleep(0.1)

        # ìµœì¢… ê²°ê³¼
        result = {
            "task_id": task_id,
            "status": "completed",
            "text_prompt": text_prompt[:200] if len(text_prompt) > 200 else text_prompt,  # ì‘ë‹µ í¬ê¸° ì œí•œ
            "created_at": datetime.now().isoformat(),
            "completed_at": datetime.now().isoformat(),
            "mindmap": mindmap.dict()
        }

        yield f"data: {json.dumps({'status': 'completed', 'progress': 100, 'message': 'í…ìŠ¤íŠ¸ ë¶„ì„ ì™„ë£Œ!', 'result': result}, ensure_ascii=False)}\n\n"

    except Exception as e:
        error_msg = str(e)
        logger.error(f"í…ìŠ¤íŠ¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {error_msg}")
        yield f"data: {json.dumps({'status': 'failed', 'error': error_msg}, ensure_ascii=False)}\n\n"


@app.post("/analyze/text")
async def analyze_text(request: TextAnalyzeRequest):
    """
    í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ ë¶„ì„ ë° ë§ˆì¸ë“œë§µ ìƒì„± (ìŠ¤íŠ¸ë¦¬ë°)

    Server-Sent Events (SSE) í˜•ì‹ìœ¼ë¡œ ì‹¤ì‹œê°„ ì§„í–‰ ìƒí™©ì„ ì „ë‹¬í•©ë‹ˆë‹¤.

    - **text_prompt**: ë¶„ì„í•  í…ìŠ¤íŠ¸/ì£¼ì œ (ì˜ˆ: "ì¸ê³µì§€ëŠ¥ì˜ ì—­ì‚¬ì™€ ë°œì „")
    - **detail_level**: ìƒì„¸ ìˆ˜ì¤€ - "simple" (ê°„ë‹¨), "medium" (ë³´í†µ), "detailed" (ìƒì„¸)

    ### ì‘ë‹µ í˜•ì‹ (SSE)
    ê° ì´ë²¤íŠ¸ëŠ” ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì „ë‹¬ë©ë‹ˆë‹¤:
    ```
    data: {"status": "...", "progress": 0-100, "message": "...", ...}
    ```

    ### ìƒíƒœ ì¢…ë¥˜
    - `started`: ë¶„ì„ ì‹œì‘
    - `validating`: í…ìŠ¤íŠ¸ ê²€ì¦ ì¤‘
    - `validation_complete`: ê²€ì¦ ì™„ë£Œ
    - `creating_mindmap`: ë§ˆì¸ë“œë§µ ìƒì„± ì¤‘
    - `mindmap_complete`: ë§ˆì¸ë“œë§µ ìƒì„± ì™„ë£Œ
    - `completed`: ë¶„ì„ ì™„ë£Œ (result í¬í•¨)
    - `failed`: ì˜¤ë¥˜ ë°œìƒ (error í¬í•¨)

    ### ì‚¬ìš© ì˜ˆì‹œ
    ```json
    {
      "text_prompt": "ì¸ê³µì§€ëŠ¥ì˜ ì—­ì‚¬ì™€ ì£¼ìš” ë°œì „ ë‹¨ê³„",
      "detail_level": "medium"
    }
    ```

    ### ìƒì„¸ ìˆ˜ì¤€ ì„¤ëª…
    - **simple**: 2ë‹¨ê³„ ê¹Šì´, í•µì‹¬ ë‚´ìš©ë§Œ ê°„ë‹¨íˆ (~5-10ì´ˆ)
    - **medium**: 3-4ë‹¨ê³„ ê¹Šì´, ì ì ˆí•œ ìƒì„¸ë„ (~10-20ì´ˆ)
    - **detailed**: 4-5ë‹¨ê³„ ê¹Šì´, ë§¤ìš° ìƒì„¸í•œ ë‚´ìš© (~15-30ì´ˆ)
    """
    return StreamingResponse(
        analyze_text_stream(
            text_prompt=request.text_prompt,
            detail_level=request.detail_level or "medium"
        ),
        media_type="text/event-stream"
    )


if __name__ == "__main__":
    import uvicorn

    # í™˜ê²½ë³€ìˆ˜ë¡œ í¬íŠ¸ ì„¤ì • ê°€ëŠ¥
    port = int(os.getenv("PORT", 8000))

    uvicorn.run(
        "src.api.main:app",
        host="0.0.0.0",
        port=port,
        reload=False
    )
