"""
Kafka Consumer/Producer í•¸ë“¤ëŸ¬
- ai.analysis.request í† í”½ì—ì„œ ë¶„ì„ ìš”ì²­ ìˆ˜ì‹ 
- ai.analysis.result í† í”½ìœ¼ë¡œ ë¶„ì„ ê²°ê³¼ ì „ì†¡
"""
import json
import logging
import os
import threading
from typing import Dict, Any, Optional
from kafka import KafkaConsumer, KafkaProducer
from kafka.errors import KafkaError
from dotenv import load_dotenv

load_dotenv()

logger = logging.getLogger(__name__)


class KafkaHandler:
    """Kafka Consumer/Producer í•¸ë“¤ëŸ¬"""

    def __init__(self, topics: Optional[Dict[str, str]] = None):
        """
        ì´ˆê¸°í™”

        Args:
            topics: í† í”½ ì„¤ì • ë”•ì…”ë„ˆë¦¬ (Noneì´ë©´ ê¸°ë³¸ analysis í† í”½ ì‚¬ìš©)
                ì˜ˆ: {"request": "ai.analysis.request", "response": "ai.analysis.result"}
        """
        self.bootstrap_servers = os.getenv('KAFKA_BOOTSTRAP_SERVERS', 'localhost:9092')

        if topics:
            self.request_topic = topics.get('request')
            self.response_topic = topics.get('response')
        else:
            self.request_topic = os.getenv('KAFKA_REQUEST_TOPIC', 'ai.analysis.request')
            self.response_topic = os.getenv('KAFKA_RESPONSE_TOPIC', 'ai.analysis.result')

        self.group_id = os.getenv('KAFKA_GROUP_ID', 'ai-analysis-consumer')

        self.consumer: Optional[KafkaConsumer] = None
        self.producer: Optional[KafkaProducer] = None
        self.running = False
        self.consumer_thread: Optional[threading.Thread] = None

        # ë¶„ì„ ì½œë°± í•¨ìˆ˜ (ì™¸ë¶€ì—ì„œ ì„¤ì •)
        self.analysis_callback = None

        logger.info(f"Kafka Handler ì´ˆê¸°í™”: {self.bootstrap_servers}")
        logger.info(f"Request Topic: {self.request_topic}")
        logger.info(f"Response Topic: {self.response_topic}")

    def connect_producer(self):
        """Kafka Producer ì—°ê²°"""
        try:
            self.producer = KafkaProducer(
                bootstrap_servers=self.bootstrap_servers,
                value_serializer=lambda v: json.dumps(v, ensure_ascii=False).encode('utf-8'),
                acks='all',  # ëª¨ë“  replicaê°€ ë©”ì‹œì§€ë¥¼ ë°›ì„ ë•Œê¹Œì§€ ëŒ€ê¸°
                retries=3,
                max_in_flight_requests_per_connection=1
            )
            logger.info(f"âœ… Kafka Producer ì—°ê²° ì„±ê³µ: {self.bootstrap_servers}")
            return True
        except Exception as e:
            logger.error(f"âŒ Kafka Producer ì—°ê²° ì‹¤íŒ¨: {e}")
            return False

    def connect_consumer(self):
        """Kafka Consumer ì—°ê²°"""
        try:
            self.consumer = KafkaConsumer(
                self.request_topic,
                bootstrap_servers=self.bootstrap_servers,
                group_id=self.group_id,
                value_deserializer=lambda m: json.loads(m.decode('utf-8')),
                auto_offset_reset='latest',  # ìµœì‹  ë©”ì‹œì§€ë¶€í„° ì½ê¸°
                enable_auto_commit=True,
                consumer_timeout_ms=1000  # 1ì´ˆë§ˆë‹¤ íƒ€ì„ì•„ì›ƒ (ì¢…ë£Œ ì²´í¬ìš©)
            )
            logger.info(f"âœ… Kafka Consumer ì—°ê²° ì„±ê³µ: {self.request_topic}")
            return True
        except Exception as e:
            logger.error(f"âŒ Kafka Consumer ì—°ê²° ì‹¤íŒ¨: {e}")
            return False

    def set_analysis_callback(self, callback):
        """
        ë¶„ì„ ì½œë°± í•¨ìˆ˜ ì„¤ì •

        Args:
            callback: ë¶„ì„ ìš”ì²­ì„ ì²˜ë¦¬í•  í•¨ìˆ˜
                      ì‹œê·¸ë‹ˆì²˜: callback(request_data: Dict) -> Dict
        """
        self.analysis_callback = callback
        logger.info("ë¶„ì„ ì½œë°± í•¨ìˆ˜ ì„¤ì • ì™„ë£Œ")

    def send_result(self, result: Dict[str, Any]) -> bool:
        """
        ë¶„ì„ ê²°ê³¼ë¥¼ Kafkaë¡œ ì „ì†¡

        Args:
            result: ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬

        Returns:
            ì „ì†¡ ì„±ê³µ ì—¬ë¶€
        """
        if not self.producer:
            logger.error("Producerê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return False

        try:
            future = self.producer.send(self.response_topic, result)
            # ì „ì†¡ ì™„ë£Œ ëŒ€ê¸° (ìµœëŒ€ 10ì´ˆ)
            record_metadata = future.get(timeout=10)

            logger.info(f"âœ… Kafka ê²°ê³¼ ì „ì†¡ ì™„ë£Œ: topic={record_metadata.topic}, "
                       f"partition={record_metadata.partition}, offset={record_metadata.offset}")
            return True

        except KafkaError as e:
            logger.error(f"âŒ Kafka ì „ì†¡ ì‹¤íŒ¨: {e}")
            return False
        except Exception as e:
            logger.error(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
            return False

    def _process_message(self, message_value: Dict[str, Any]):
        """
        Kafka ë©”ì‹œì§€ ì²˜ë¦¬

        Args:
            message_value: Kafka ë©”ì‹œì§€ ë‚´ìš©
        """
        try:
            # workspaceIdë¥¼ intë¡œ ë³€í™˜ (Java longê³¼ í˜¸í™˜)
            raw_workspace_id = message_value.get('workspaceId')
            if raw_workspace_id is None:
                raise ValueError("workspaceId is required")

            try:
                workspace_id = int(raw_workspace_id)
            except (ValueError, TypeError) as e:
                raise ValueError(f"workspaceId must be a valid integer, got: {raw_workspace_id}")

            node_id = message_value.get('nodeId')
            analysis_type = message_value.get('analysisType')

            logger.info(f"ğŸ“¨ Kafka ë©”ì‹œì§€ ìˆ˜ì‹ : workspaceId={workspace_id}, "
                       f"nodeId={node_id}, type={analysis_type}")

            if not self.analysis_callback:
                logger.error("ë¶„ì„ ì½œë°± í•¨ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                # ì‹¤íŒ¨ ì‘ë‹µ ì „ì†¡
                error_result = {
                    "workspaceId": workspace_id,
                    "status": "FAILED",
                    "error": "Analysis callback not configured"
                }
                self.send_result(error_result)
                return

            # ë¶„ì„ ìˆ˜í–‰
            result = self.analysis_callback(message_value)

            # ê²°ê³¼ ì „ì†¡
            if result:
                self.send_result(result)
            else:
                # ì‹¤íŒ¨ ì‘ë‹µ ì „ì†¡
                error_result = {
                    "workspaceId": workspace_id,
                    "status": "FAILED",
                    "error": "Analysis failed"
                }
                self.send_result(error_result)

        except Exception as e:
            logger.error(f"âŒ ë©”ì‹œì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)
            # ì‹¤íŒ¨ ì‘ë‹µ ì „ì†¡
            error_result = {
                "workspaceId": message_value.get('workspaceId'),
                "status": "FAILED",
                "error": str(e)
            }
            self.send_result(error_result)

    def _consume_loop(self):
        """Consumer ë©”ì¸ ë£¨í”„"""
        logger.info("ğŸ”„ Kafka Consumer ì‹œì‘")

        while self.running:
            try:
                # ë©”ì‹œì§€ polling (timeout 1ì´ˆ)
                for message in self.consumer:
                    if not self.running:
                        break

                    logger.debug(f"ë©”ì‹œì§€ ìˆ˜ì‹ : offset={message.offset}, "
                                f"partition={message.partition}")

                    # ë©”ì‹œì§€ ì²˜ë¦¬
                    self._process_message(message.value)

            except Exception as e:
                if self.running:
                    logger.error(f"âŒ Consumer ë£¨í”„ ì˜¤ë¥˜: {e}", exc_info=True)
                    # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì ì‹œ ëŒ€ê¸° í›„ ì¬ì‹œë„
                    import time
                    time.sleep(5)

        logger.info("ğŸ›‘ Kafka Consumer ì¢…ë£Œ")

    def start(self):
        """Kafka Consumer ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œ ì‹œì‘"""
        if self.running:
            logger.warning("Kafka Consumerê°€ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤.")
            return False

        # Producer ì—°ê²°
        if not self.connect_producer():
            return False

        # Consumer ì—°ê²°
        if not self.connect_consumer():
            return False

        # Consumer ìŠ¤ë ˆë“œ ì‹œì‘
        self.running = True
        self.consumer_thread = threading.Thread(target=self._consume_loop, daemon=True)
        self.consumer_thread.start()

        logger.info("âœ… Kafka Handler ì‹œì‘ ì™„ë£Œ")
        return True

    def stop(self):
        """Kafka Consumer/Producer ì¢…ë£Œ"""
        logger.info("Kafka Handler ì¢…ë£Œ ì¤‘...")

        self.running = False

        # Consumer ì¢…ë£Œ
        if self.consumer:
            try:
                self.consumer.close()
                logger.info("Consumer ì¢…ë£Œ ì™„ë£Œ")
            except Exception as e:
                logger.error(f"Consumer ì¢…ë£Œ ì˜¤ë¥˜: {e}")

        # Producer ì¢…ë£Œ
        if self.producer:
            try:
                self.producer.flush()
                self.producer.close()
                logger.info("Producer ì¢…ë£Œ ì™„ë£Œ")
            except Exception as e:
                logger.error(f"Producer ì¢…ë£Œ ì˜¤ë¥˜: {e}")

        # ìŠ¤ë ˆë“œ ì¢…ë£Œ ëŒ€ê¸°
        if self.consumer_thread and self.consumer_thread.is_alive():
            self.consumer_thread.join(timeout=10)

        logger.info("âœ… Kafka Handler ì¢…ë£Œ ì™„ë£Œ")


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
kafka_handler = KafkaHandler()
