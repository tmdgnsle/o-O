"""
Llama 3.1 8B Text Analyzer
í…ìŠ¤íŠ¸ ìš”ì•½ ë° í•©ì„±ì„ ìœ„í•œ Llama 3.1 8B ëª¨ë¸ ë˜í¼
"""
import torch
import logging
from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig
from typing import List, Dict, Optional
import os
from dotenv import load_dotenv

load_dotenv()

logger = logging.getLogger(__name__)


class LlamaTextAnalyzer:
    """Llama 3.1 8Bë¥¼ ì‚¬ìš©í•œ í…ìŠ¤íŠ¸ ë¶„ì„ ë° ìš”ì•½ê¸°"""

    def __init__(
        self,
        model_name: str = "meta-llama/Llama-3.1-8B-Instruct",
        quantization: Optional[str] = "int4"
    ):
        """
        Llama Text Analyzer ì´ˆê¸°í™”

        Args:
            model_name: HuggingFace ëª¨ë¸ ì´ë¦„
            quantization: "int4", "int8", "fp16", None
        """
        self.model_name = model_name
        logger.info(f"ğŸš€ Llama Text ëª¨ë¸ ë¡œë”© ì¤‘: {model_name}")
        logger.info(f"ğŸ“Š ì–‘ìí™”: {quantization if quantization else 'FP16'}")
        logger.info(f"ğŸ’¾ GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\n")

        # í† í¬ë‚˜ì´ì € ë¡œë“œ
        self.tokenizer = AutoTokenizer.from_pretrained(
            model_name,
            token=os.getenv("HUGGINGFACE_TOKEN")
        )

        # ì–‘ìí™” ì„¤ì •ì— ë”°ë¥¸ ëª¨ë¸ ë¡œë“œ
        if quantization == "int4" and torch.cuda.is_available():
            logger.info("âš™ï¸  INT4 ì–‘ìí™” ì„¤ì • (VRAM ~4GB)")
            quantization_config = BitsAndBytesConfig(
                load_in_4bit=True,
                bnb_4bit_compute_dtype=torch.bfloat16,
                bnb_4bit_use_double_quant=True,
                bnb_4bit_quant_type="nf4"
            )
            self.model = AutoModelForCausalLM.from_pretrained(
                model_name,
                quantization_config=quantization_config,
                device_map="auto",
                token=os.getenv("HUGGINGFACE_TOKEN")
            )
        elif quantization == "int8" and torch.cuda.is_available():
            logger.info("âš™ï¸  INT8 ì–‘ìí™” ì„¤ì • (VRAM ~8GB)")
            quantization_config = BitsAndBytesConfig(load_in_8bit=True)
            self.model = AutoModelForCausalLM.from_pretrained(
                model_name,
                quantization_config=quantization_config,
                device_map="auto",
                token=os.getenv("HUGGINGFACE_TOKEN")
            )
        else:
            logger.info("âš™ï¸  FP16 ì„¤ì • (VRAM ~16GB)")
            self.model = AutoModelForCausalLM.from_pretrained(
                model_name,
                torch_dtype=torch.float16,
                device_map="auto",
                token=os.getenv("HUGGINGFACE_TOKEN")
            )

        # VRAM ì‚¬ìš©ëŸ‰ ì¶œë ¥
        if torch.cuda.is_available():
            logger.info(f"âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")
            logger.info(f"ğŸ“Š VRAM ì‚¬ìš©ëŸ‰: {torch.cuda.memory_allocated() / 1024**3:.2f} GB")
            logger.info(f"ğŸ“Š VRAM ì˜ˆì•½: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\n")
        else:
            logger.info("âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ! (CPU ëª¨ë“œ)\n")

    def generate(
        self,
        prompt: str,
        system_prompt: Optional[str] = None,
        max_tokens: int = 1024,
        temperature: float = 0.7
    ) -> str:
        """
        í…ìŠ¤íŠ¸ ìƒì„±

        Args:
            prompt: ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸
            system_prompt: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ì„ íƒ)
            max_tokens: ìµœëŒ€ ìƒì„± í† í° ìˆ˜
            temperature: ìƒ˜í”Œë§ ì˜¨ë„

        Returns:
            ìƒì„±ëœ í…ìŠ¤íŠ¸
        """
        # ë©”ì‹œì§€ êµ¬ì„±
        messages = []
        if system_prompt:
            messages.append({"role": "system", "content": system_prompt})
        messages.append({"role": "user", "content": prompt})

        # ì±„íŒ… í…œí”Œë¦¿ ì ìš©
        formatted_prompt = self.tokenizer.apply_chat_template(
            messages,
            tokenize=False,
            add_generation_prompt=True
        )

        # í† í°í™”
        inputs = self.tokenizer(
            formatted_prompt,
            return_tensors="pt"
        ).to(self.model.device)

        # ìƒì„±
        with torch.no_grad():
            outputs = self.model.generate(
                **inputs,
                max_new_tokens=max_tokens,
                temperature=temperature,
                top_p=0.9,
                do_sample=True if temperature > 0 else False,
                pad_token_id=self.tokenizer.eos_token_id,
                eos_token_id=self.tokenizer.eos_token_id
            )

        # ë””ì½”ë”© (ì…ë ¥ ì œê±°í•˜ê³  ìƒì„±ëœ ë¶€ë¶„ë§Œ)
        generated_text = self.tokenizer.decode(
            outputs[0][inputs['input_ids'].shape[1]:],
            skip_special_tokens=True
        )

        return generated_text.strip()

    def summarize_video(
        self,
        frame_analyses: List[str],
        transcript: str,
        max_tokens: int = 2048,
        temperature: float = 0.3
    ) -> str:
        """
        ì˜ìƒ í”„ë ˆì„ ë¶„ì„ ê²°ê³¼ì™€ ìë§‰ì„ ì¢…í•©í•˜ì—¬ ìš”ì•½

        Args:
            frame_analyses: ê° í”„ë ˆì„ì˜ ì‹œê° ë¶„ì„ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
            transcript: ì˜ìƒ ìë§‰/ìŒì„± í…ìŠ¤íŠ¸
            max_tokens: ìµœëŒ€ ìƒì„± í† í° ìˆ˜
            temperature: ìƒ˜í”Œë§ ì˜¨ë„ (ë‚®ì„ìˆ˜ë¡ ì¼ê´€ì„± ë†’ìŒ)

        Returns:
            ì¢…í•© ìš”ì•½ ê²°ê³¼
        """
        # í”„ë ˆì„ ë¶„ì„ ê²°ê³¼ í¬ë§¤íŒ…
        frame_summary = "\n\n".join([
            f"[í”„ë ˆì„ {i+1}]\n{analysis}"
            for i, analysis in enumerate(frame_analyses)
        ])

        system_prompt = """ë‹¹ì‹ ì€ ì˜ìƒ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì˜ìƒì˜ ì£¼ìš” í”„ë ˆì„ ë¶„ì„ ê²°ê³¼ì™€ ìŒì„±/ìë§‰ ë‚´ìš©ì„ ì¢…í•©í•˜ì—¬
ì˜ìƒ ì „ì²´ë¥¼ ì´í•´í•˜ê¸° ì‰½ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”."""

        user_prompt = f"""ë‹¤ìŒì€ YouTube ì˜ìƒ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤:

## ì‹œê° ì •ë³´ (ì£¼ìš” í”„ë ˆì„ ë¶„ì„)
{frame_summary}

## ìŒì„±/ìë§‰ ë‚´ìš©
{transcript}

---

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì˜ìƒì„ ì¢…í•© ìš”ì•½í•´ì£¼ì„¸ìš”:

1. ì˜ìƒ ì£¼ì œ ë° ê°œìš”
2. ì£¼ìš” ë‚´ìš© (ë¶ˆë¦¿ í¬ì¸íŠ¸)
3. í•µì‹¬ ë©”ì‹œì§€
4. ì£¼ëª©í•  ë§Œí•œ ì‹œê°ì  ìš”ì†Œ
"""

        return self.generate(
            user_prompt,
            system_prompt=system_prompt,
            max_tokens=max_tokens,
            temperature=temperature
        )

    def synthesize_analysis(
        self,
        vision_results: List[Dict],
        transcript: str,
        additional_context: Optional[str] = None,
        max_tokens: int = 2048,
        temperature: float = 0.3
    ) -> str:
        """
        ë¹„ì „ ë¶„ì„ ê²°ê³¼ (ê°ì²´ ê°ì§€, ì¥ë©´ ë¶„ë¥˜, OCR ë“±)ì™€ í…ìŠ¤íŠ¸ë¥¼ ì¢…í•©

        Args:
            vision_results: ë¹„ì „ ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸
                ì˜ˆ: [{"frame": 1, "objects": [...], "scene": "...", "text": "..."}]
            transcript: ì˜ìƒ ìë§‰/ìŒì„± í…ìŠ¤íŠ¸
            additional_context: ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ ì •ë³´
            max_tokens: ìµœëŒ€ ìƒì„± í† í° ìˆ˜
            temperature: ìƒ˜í”Œë§ ì˜¨ë„

        Returns:
            ì¢…í•© ë¶„ì„ ê²°ê³¼
        """
        # ë¹„ì „ ê²°ê³¼ í¬ë§¤íŒ…
        vision_summary = ""
        for result in vision_results:
            frame_num = result.get("frame", "?")
            vision_summary += f"\n[í”„ë ˆì„ {frame_num}]\n"

            if "objects" in result:
                vision_summary += f"- ê°ì§€ëœ ê°ì²´: {', '.join(result['objects'])}\n"
            if "scene" in result:
                vision_summary += f"- ì¥ë©´ ë¶„ë¥˜: {result['scene']}\n"
            if "text" in result and result["text"]:
                vision_summary += f"- í…ìŠ¤íŠ¸(OCR): {result['text']}\n"
            if "description" in result:
                vision_summary += f"- ì„¤ëª…: {result['description']}\n"

        system_prompt = """ë‹¹ì‹ ì€ ë©€í‹°ëª¨ë‹¬ ì˜ìƒ ë¶„ì„ AIì…ë‹ˆë‹¤.
ì»´í“¨í„° ë¹„ì „ ë¶„ì„ ê²°ê³¼ì™€ ìŒì„±/ìë§‰ì„ ì¢…í•©í•˜ì—¬
ì‚¬ìš©ìê°€ ì´í•´í•˜ê¸° ì‰¬ìš´ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•˜ì„¸ìš”."""

        user_prompt = f"""ë‹¤ìŒì€ ì˜ìƒ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤:

## ì»´í“¨í„° ë¹„ì „ ë¶„ì„
{vision_summary}

## ìŒì„±/ìë§‰
{transcript}
"""

        if additional_context:
            user_prompt += f"\n## ì¶”ê°€ ì •ë³´\n{additional_context}\n"

        user_prompt += """
---

ìœ„ ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ ë‹¤ìŒ í˜•ì‹ì˜ ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•˜ì„¸ìš”:

# ì˜ìƒ ë¶„ì„ ë¦¬í¬íŠ¸

## ìš”ì•½

## ì‹œê°ì  í•˜ì´ë¼ì´íŠ¸

## ì£¼ìš” ë‚´ìš©

## í•µì‹¬ ì¸ì‚¬ì´íŠ¸
"""

        return self.generate(
            user_prompt,
            system_prompt=system_prompt,
            max_tokens=max_tokens,
            temperature=temperature
        )

    def extract_key_points(
        self,
        text: str,
        max_points: int = 5,
        max_tokens: int = 512,
        temperature: float = 0.3
    ) -> List[str]:
        """
        í…ìŠ¤íŠ¸ì—ì„œ í•µì‹¬ í¬ì¸íŠ¸ ì¶”ì¶œ

        Args:
            text: ì…ë ¥ í…ìŠ¤íŠ¸
            max_points: ìµœëŒ€ í¬ì¸íŠ¸ ê°œìˆ˜
            max_tokens: ìµœëŒ€ ìƒì„± í† í° ìˆ˜
            temperature: ìƒ˜í”Œë§ ì˜¨ë„

        Returns:
            í•µì‹¬ í¬ì¸íŠ¸ ë¦¬ìŠ¤íŠ¸
        """
        prompt = f"""ë‹¤ìŒ í…ìŠ¤íŠ¸ì—ì„œ í•µì‹¬ í¬ì¸íŠ¸ {max_points}ê°œë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.
ê° í¬ì¸íŠ¸ëŠ” í•œ ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ê³ , ë²ˆí˜¸ ì—†ì´ "-"ë¡œ ì‹œì‘í•˜ì„¸ìš”.

í…ìŠ¤íŠ¸:
{text}

í•µì‹¬ í¬ì¸íŠ¸:"""

        result = self.generate(
            prompt,
            max_tokens=max_tokens,
            temperature=temperature
        )

        # ê²°ê³¼ íŒŒì‹±
        points = []
        for line in result.split("\n"):
            line = line.strip()
            if line.startswith("-") or line.startswith("â€¢"):
                points.append(line.lstrip("-â€¢").strip())
            elif line and len(points) < max_points:
                points.append(line)

        return points[:max_points]

    def generate_mindmap(
        self,
        video_title: str,
        frame_analyses: List[str],
        transcript: str,
        user_query: Optional[str] = None,
        max_tokens: int = 4096,
        temperature: float = 0.7
    ) -> str:
        """
        ì˜ìƒ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë§ˆì¸ë“œë§µ êµ¬ì¡°ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ìƒì„±

        Args:
            video_title: ì˜ìƒ ì œëª©
            frame_analyses: í”„ë ˆì„ ë¶„ì„ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
            transcript: ì˜ìƒ ìë§‰
            user_query: ì‚¬ìš©ì ì§ˆë¬¸/í”„ë¡¬í”„íŠ¸ (ì˜ˆ: "ì´ ê¸°ìˆ ë¡œ ì–´ë–¤ í”„ë¡œì íŠ¸ë¥¼ ë§Œë“¤ ìˆ˜ ìˆì„ê¹Œ?")
            max_tokens: ìµœëŒ€ ìƒì„± í† í° ìˆ˜
            temperature: ìƒ˜í”Œë§ ì˜¨ë„

        Returns:
            ë§ˆì¸ë“œë§µ JSON ë¬¸ìì—´
        """
        # í”„ë ˆì„ ë¶„ì„ ìš”ì•½
        frame_summary = "\n\n".join([
            f"[í”„ë ˆì„ {i+1}] {analysis}"
            for i, analysis in enumerate(frame_analyses)
        ])

        # ê¸°ë³¸ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        system_prompt = """You are an expert at structuring information into mindmaps.
Analyze the given video content and convert it into a mindmap structure.
You can create hierarchies of unlimited depth.

**CRITICAL: You MUST respond ONLY with valid JSON. Do NOT include any explanatory text, backticks, or comments.**"""

        # ì‚¬ìš©ì ì¿¼ë¦¬ì— ë”°ë¥¸ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        if user_query:
            analysis_instruction = f"""
ğŸ¯ **USER'S SPECIFIC REQUEST (THIS IS THE PRIMARY GOAL):**
"{user_query}"

**CRITICAL INSTRUCTIONS:**
- Your ENTIRE mindmap MUST be focused on answering/explaining this user request
- The root keyword should reflect this topic (NOT just the video title)
- ALL children nodes must be directly relevant to this user question
- Extract ONLY the parts of the video that relate to this topic
- Ignore unrelated video content

**If user asks to "ì •ë¦¬" (organize/list):**
- Create systematic categorization of items mentioned in video
- Each item should be a separate child node with specific details

**If user asks to "ì•„ì´ë””ì–´ í™•ì¥" (expand ideas) or "ì–´ë–»ê²Œ í™œìš©" (how to use):**
- You MUST create a separate child node called "í™œìš© ì•„ì´ë””ì–´" or "í™•ì¥ ë°©ì•ˆ"
- Include minimum 3-5 CONCRETE, ACTIONABLE ideas with SPECIFIC DETAILS
- Each idea should include:
  * What to build/create (êµ¬ì²´ì  ì œí’ˆ/ì„œë¹„ìŠ¤ëª…)
  * How it works (ê¸°ìˆ ì  êµ¬í˜„ ë°©ë²•)
  * Target users/market (íƒ€ê²Ÿ ì‚¬ìš©ì)
  * Expected benefits (ì˜ˆìƒ íš¨ê³¼ - ìˆ˜ì¹˜ í¬í•¨)
  * Optional: estimated cost, timeline, technical requirements
- Be creative but PRACTICAL - avoid vague statements like "AI ë„êµ¬ ê²°í•©"

âŒ BAD Idea Examples (TOO VAGUE):
- "AI ë„êµ¬ë¥¼ ê²°í•©í•´ì„œ ì‚¬ìš©"
- "ì—…ë¬´ íš¨ìœ¨ì„± í–¥ìƒ"
- "ë‹¤ì–‘í•œ ë¶„ì•¼ì— í™œìš© ê°€ëŠ¥"

âœ… GOOD Idea Examples (CONCRETE & SPECIFIC):
- "Claude Skills + Haiku 4.5 ê²°í•© â†’ 'ìë™ ì½”ë“œ ë¦¬ë·° ì‹œìŠ¤í…œ': GitHub PR ë¶„ì„ í›„ ë²„ê·¸ ë¦¬í¬íŠ¸ ìë™ ìƒì„±, ì˜ˆìƒ ë¹„ìš© ì›” $50, ê°œë°œ ê¸°ê°„ 2ì£¼, íŒ€ ì½”ë“œ í’ˆì§ˆ 30% í–¥ìƒ ì˜ˆìƒ"
- "Veo 3.1 ì˜ìƒ ìƒì„± + ìŒì„± AI â†’ '5ë¶„ ìë™ ë‰´ìŠ¤ ì œì‘ ì‹œìŠ¤í…œ': ê¸°ì‚¬ í…ìŠ¤íŠ¸ ì…ë ¥í•˜ë©´ ì˜ìƒ+ë‚´ë ˆì´ì…˜ ìë™ ìƒì„±, ìœ íŠœë¸Œ ì±„ë„ ìš´ì˜ì ëŒ€ìƒ, ì œì‘ ì‹œê°„ 2ì‹œê°„â†’10ë¶„ìœ¼ë¡œ ë‹¨ì¶•"
- "Haiku 4.5 ì €ë¹„ìš© íŠ¹ì„± í™œìš© â†’ 'ì‹¤ì‹œê°„ ê³ ê° ìƒë‹´ ì±—ë´‡': 1000ê±´ ìƒë‹´ ë¹„ìš© $0.5, ê¸°ì¡´ GPT ëŒ€ë¹„ 90% ì ˆê°, 24ì‹œê°„ ìë™ ì‘ë‹µìœ¼ë¡œ ê³ ê° ë§Œì¡±ë„ í–¥ìƒ"

**Examples:**

Example 1 - "ìºë‚˜ë‹¤ ê´€ì„¸ ì¸ìƒ ì´ìŠˆì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜":
- Root: "ìºë‚˜ë‹¤ ê´€ì„¸ ì¸ìƒ ì´ìŠˆ"
- Children: Only Canada tariff content (ignore Argentina, Nike)

Example 2 - "ì˜ìƒì—ì„œ ë‚˜ì˜¨ AIë“¤ì„ ì •ë¦¬í•´ì£¼ê³  ì•„ì´ë””ì–´ë¥¼ ì–´ë–»ê²Œ í™•ì¥í•  ìˆ˜ ìˆëŠ”ì§€ ìƒê°í•´ì¤˜":
- Root: "ì˜ìƒ ì† AI ë„êµ¬ ë° í™œìš© ì•„ì´ë””ì–´"
- Children:
  - "AI ë„êµ¬ ëª©ë¡" node with children:
    * "Claude Skills" â†’ "ììœ¨ ì—ì´ì „íŠ¸ í”„ë ˆì„ì›Œí¬, ë„êµ¬ í†µí•© ê¸°ëŠ¥ ì œê³µ, 2025ë…„ ì¶œì‹œ"
    * "Haiku 4.5" â†’ "Sonnet 3.5 ìˆ˜ì¤€ ì„±ëŠ¥, ë¹„ìš©ì€ 1/10 ìˆ˜ì¤€ ($0.4/1M), ì†ë„ 50% í–¥ìƒ"
    * "Veo 3.1" â†’ "Googleì˜ AI ì˜ìƒ ìƒì„± ëª¨ë¸, í…ìŠ¤íŠ¸â†’ì˜ìƒ ë³€í™˜, ì‹¤ì‚¬ í’ˆì§ˆ"
  - "í™œìš© ì•„ì´ë””ì–´" node with CONCRETE children:
    * "ìë™ ì½”ë“œ ë¦¬ë·° ì‹œìŠ¤í…œ" â†’ "Claude Skillsë¡œ GitHub PR ë¶„ì„ + Haiku 4.5ë¡œ ë¦¬ë·° ìƒì„±. ì›” $50 ë¹„ìš©, 2ì£¼ ê°œë°œ, ì½”ë“œ í’ˆì§ˆ 30% í–¥ìƒ"
    * "5ë¶„ ìë™ ë‰´ìŠ¤ ì œì‘" â†’ "Veo 3.1ë¡œ ì˜ìƒ ìƒì„± + ìŒì„± AI ê²°í•©. ìœ íŠœë²„ ëŒ€ìƒ, ì œì‘ ì‹œê°„ 2ì‹œê°„â†’10ë¶„ ë‹¨ì¶•"
    * "ì‹¤ì‹œê°„ ìƒë‹´ ì±—ë´‡" â†’ "Haiku 4.5 ì €ë¹„ìš© íŠ¹ì„± í™œìš©. 1000ê±´ $0.5, GPT ëŒ€ë¹„ 90% ì ˆê°, 24ì‹œê°„ ìë™ ì‘ë‹µ"
"""
        else:
            analysis_instruction = """
Organize the main content of the video hierarchically into a mindmap.
Structure main topics, subtopics, and details freely.
"""

        user_prompt = f"""Here is the YouTube video analysis:

**Video Title:** {video_title}

**Visual Information (Key Frames):**
{frame_summary}

**Audio/Transcript Content:**
{transcript}

---

{analysis_instruction}

**OUTPUT LANGUAGE: You MUST write all "keyword" and "description" fields in KOREAN (í•œêµ­ì–´).**

**MANDATORY RULES:**
1. Root node keyword:
   - If user query exists: Use the TOPIC from user's question (e.g., "ìºë‚˜ë‹¤ ê´€ì„¸ ì¸ìƒ ì´ìŠˆ")
   - If no user query: Use the video title
   - Root description should always include the YouTube URL
2. Each node MUST have "keyword" and "description" fields
   - **keyword**: Short, clear key phrase (3-5 words)
   - **description**: SPECIFIC FACTS from the video - numbers, dates, quotes, names, concrete details (NO abstract explanations!)
3. Use "children" array for child nodes (null if no children)
4. No depth limit - create as many levels as needed
5. **Output ONLY valid JSON. NO backticks (```), explanations, or comments**

**DO NOT use keywords as JSON keys! ALWAYS use "keyword" field!**

**Description Writing Rules - THIS IS CRITICAL:**
âŒ BAD Examples (NEVER do this):
- "íŠ¸ëŸ¼í”„ì˜ ê´€ì„¸ ì¸ìƒì— ëŒ€í•´ ì„¤ëª…" (too abstract, no facts)
- "ë¬´ì—­ ê´€ê³„ì— ëŒ€í•´ ì„¤ëª…" (vague, no specifics)
- "ìºë‚˜ë‹¤ì™€ ë¯¸êµ­ì˜ ë¬´ì—­ì´ ì–´ë–»ê²Œ ìºë‚˜ë‹¤ì™€ ë¯¸êµ­ì˜ ê²½ì œì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ”ì§€ ì„¤ëª…" (just says "explain", no actual content)

âœ… GOOD Examples (ALWAYS do this):
- "íŠ¸ëŸ¼í”„ê°€ ìºë‚˜ë‹¤ì— ì¶”ê°€ 10% ê´€ì„¸ ë¶€ê³¼. ë ˆì´ê±´ ê´‘ê³ ë¥¼ ì˜¤ë„ì ì´ë¼ ë¹„íŒ. 11ì›” 5ì¼ ëŒ€ë²•ì› ì‹¬ë¦¬ ì˜ˆì •"
- "ë¯¸-ìº ë¬´ì—­ ê·œëª¨ $762B, ìºë‚˜ë‹¤ëŠ” ë¯¸êµ­ì˜ 2ìœ„ ë¬´ì—­ íŒŒíŠ¸ë„ˆ. USMCAê°€ $650B ì»¤ë²„"
- "Ontarioê°€ World Series ì¤‘ ê´‘ê³  ë°©ì˜ ($53M ì§€ì¶œ), Reaganì˜ 1987ë…„ ë°˜ê´€ì„¸ ì—°ì„¤ ì¸ìš©"
- "Argentina ì„ ê±°ì—ì„œ Milei 41% ë“í‘œë¡œ ìŠ¹ë¦¬. ì¸í”Œë ˆì´ì…˜ 200%â†’32% ê°ì†Œ, ë¹ˆê³¤ìœ¨ ì—¬ì „íˆ 33%"
- "Nikeì˜ ìƒˆ ì „ë™ ì‹ ë°œ 2028ë…„ ì¶œì‹œ ì˜ˆì •, 10-12ë¶„ ë§ˆì¼ ì£¼ì ëŒ€ìƒ"

**KEY PRINCIPLE: Extract WHO, WHAT, WHEN, WHERE, WHY, HOW with actual data from the video!**
- Include numbers, percentages, dollar amounts
- Include dates and timeframes
- Include names of people, companies, places
- Include direct quotes or paraphrases
- Include specific events and outcomes
- NO vague phrases like "ì— ëŒ€í•´ ì„¤ëª…", "ì— ë¯¸ì¹˜ëŠ” ì˜í–¥", "ëŒ€í•´ ë‹¤ë£¸"

Correct format (NO user query):
{{
  "keyword": "Video Title Here",
  "description": "https://www.youtube.com/watch?v=...",
  "children": [
    {{
      "keyword": "Main Topic 1",
      "description": "SPECIFIC DETAILS: names, numbers, dates, quotes from this topic",
      "children": [
        {{
          "keyword": "Subtopic 1-1",
          "description": "MORE CONCRETE FACTS: what actually happened, who said what, exact figures",
          "children": null
        }}
      ]
    }}
  ]
}}

Correct format (WITH user query like "ìºë‚˜ë‹¤ ê´€ì„¸ ì¸ìƒ ì´ìŠˆì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜"):
{{
  "keyword": "ìºë‚˜ë‹¤ ê´€ì„¸ ì¸ìƒ ì´ìŠˆ",
  "description": "íŠ¸ëŸ¼í”„ê°€ Ontarioì˜ Reagan ê´‘ê³ ì— ë°˜ë°œí•˜ì—¬ ìºë‚˜ë‹¤ì— ì¶”ê°€ 10% ê´€ì„¸ ë¶€ê³¼. ë¯¸-ìº ë¬´ì—­ $762B, 11ì›” 5ì¼ ëŒ€ë²•ì› ì‹¬ë¦¬ ì˜ˆì •. https://www.youtube.com/watch?v=...",
  "children": [
    {{
      "keyword": "ê´€ì„¸ ì¸ìƒ ë°°ê²½",
      "description": "Ontarioê°€ World Series ì¤‘ $53M ê·œëª¨ Reagan ë°˜ê´€ì„¸ ê´‘ê³  ë°©ì˜. 1987ë…„ ì—°ì„¤ ì¸ìš©. Reagan Foundationì´ ì˜¤ë„ ì£¼ì¥, íŠ¸ëŸ¼í”„ ë¬´ì—­í˜‘ìƒ ì¤‘ë‹¨ í›„ ì¶”ê°€ ê´€ì„¸",
      "children": [
        {{
          "keyword": "Reagan ê´‘ê³  ë…¼ë€",
          "description": "1987ë…„ Reagan ë¼ë””ì˜¤ ì—°ì„¤ ì¸ìš© (ì¼ë³¸ ë°˜ë„ì²´ ê´€ì„¸ ì–¸ê¸‰í•˜ë©° ì „ë°˜ì  ë°˜ëŒ€ í‘œëª…). Reagan Foundationì€ ì˜¤ë„ë¼ ì£¼ì¥í•˜ë‚˜ êµ¬ì²´ì  ê·¼ê±° ì œì‹œ ì•ˆ í•¨",
          "children": null
        }}
      ]
    }},
    {{
      "keyword": "ë¬´ì—­ ê·œëª¨ì™€ ì˜í–¥",
      "description": "ë¯¸-ìº ë¬´ì—­ $762B (ìºë‚˜ë‹¤ëŠ” ë¯¸êµ­ 2ìœ„ íŒŒíŠ¸ë„ˆ). USMCAê°€ $650B ì»¤ë²„ (85%). ì¶”ê°€ 10% ê´€ì„¸ëŠ” non-USMCA í’ˆëª© ëŒ€ìƒ. ì² ê°•/ì•Œë£¨ë¯¸ëŠ„ì€ 50% ê´€ì„¸",
      "children": null
    }},
    {{
      "keyword": "í–¥í›„ ì „ë§",
      "description": "11ì›” 5ì¼ ëŒ€ë²•ì›ì´ Trump ê´€ì„¸ í•©ë²•ì„± ì‹¬ë¦¬. 1977ë…„ ë²• ê¸°ë°˜ 'ë¹„ìƒì‚¬íƒœ' ì£¼ì¥ ì—¬ë¶€ íŒë‹¨. ìœ„í—Œ ì‹œ ë¯¸êµ­ ê¸°ì—…ë“¤ì— ëŒ€ê·œëª¨ í™˜ê¸‰ ë°œìƒ",
      "children": null
    }}
  ]
}}

Wrong format (NEVER use):
{{
  "Video Title": {{
    "description": "...",
    "children": [...]
  }}
}}

Now output ONLY valid JSON following the correct format above:"""

        result = self.generate(
            user_prompt,
            system_prompt=system_prompt,
            max_tokens=max_tokens,
            temperature=temperature
        )

        return result.strip()

    def get_vram_usage(self) -> Dict[str, float]:
        """í˜„ì¬ VRAM ì‚¬ìš©ëŸ‰ ë°˜í™˜"""
        if torch.cuda.is_available():
            return {
                "allocated_gb": torch.cuda.memory_allocated() / 1024**3,
                "reserved_gb": torch.cuda.memory_reserved() / 1024**3
            }
        return {"allocated_gb": 0.0, "reserved_gb": 0.0}

    def cleanup(self):
        """ë©”ëª¨ë¦¬ ì •ë¦¬"""
        if hasattr(self, 'model'):
            del self.model
        if hasattr(self, 'tokenizer'):
            del self.tokenizer

        if torch.cuda.is_available():
            torch.cuda.empty_cache()

        logger.info("ğŸ§¹ ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ")


def main():
    """í…ŒìŠ¤íŠ¸ ì˜ˆì œ"""
    logger.info("=" * 60)
    logger.info("ğŸ¦™ Llama 3.1 8B Text Analyzer í…ŒìŠ¤íŠ¸")
    logger.info("=" * 60)

    # Analyzer ì´ˆê¸°í™”
    analyzer = LlamaTextAnalyzer(quantization="int4")

    # ê°„ë‹¨í•œ ìƒì„± í…ŒìŠ¤íŠ¸
    logger.info("\nğŸ“ í…ìŠ¤íŠ¸ ìƒì„± í…ŒìŠ¤íŠ¸...")
    result = analyzer.generate(
        "ì¸ê³µì§€ëŠ¥ì˜ ë¯¸ë˜ì— ëŒ€í•´ 3ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
        temperature=0.7
    )
    logger.info(f"\nğŸ¤– ìƒì„± ê²°ê³¼:\n{result}\n")

    # VRAM ì‚¬ìš©ëŸ‰ í™•ì¸
    vram = analyzer.get_vram_usage()
    logger.info(f"ğŸ“Š VRAM ì‚¬ìš©ëŸ‰: {vram['allocated_gb']:.2f} GB")

    # í•µì‹¬ í¬ì¸íŠ¸ ì¶”ì¶œ í…ŒìŠ¤íŠ¸
    logger.info("\nğŸ“Œ í•µì‹¬ í¬ì¸íŠ¸ ì¶”ì¶œ í…ŒìŠ¤íŠ¸...")
    sample_text = """
    ì¸ê³µì§€ëŠ¥ì€ í˜„ëŒ€ ì‚¬íšŒì—ì„œ ì ì  ë” ì¤‘ìš”í•œ ì—­í• ì„ í•˜ê³  ìˆìŠµë‹ˆë‹¤.
    ì˜ë£Œ, êµìœ¡, ê¸ˆìœµ, ì œì¡°ì—… ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ AIê°€ í™œìš©ë˜ê³  ìˆìœ¼ë©°,
    íŠ¹íˆ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì˜ ë°œì „ìœ¼ë¡œ ìì—°ì–´ ì²˜ë¦¬ ëŠ¥ë ¥ì´ í¬ê²Œ í–¥ìƒë˜ì—ˆìŠµë‹ˆë‹¤.
    í•˜ì§€ë§Œ AI ìœ¤ë¦¬ì™€ ê°œì¸ì •ë³´ ë³´í˜¸ ë¬¸ì œë„ í•¨ê»˜ ê³ ë ¤í•´ì•¼ í•©ë‹ˆë‹¤.
    """
    points = analyzer.extract_key_points(sample_text, max_points=3)
    logger.info("í•µì‹¬ í¬ì¸íŠ¸:")
    for i, point in enumerate(points, 1):
        logger.info(f"{i}. {point}")

    # ë©”ëª¨ë¦¬ ì •ë¦¬
    analyzer.cleanup()


if __name__ == "__main__":
    main()
